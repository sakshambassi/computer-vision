{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV 1.2 97% valid on epoch 17",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vN5lM2csj9v7"
      },
      "source": [
        "# Computer Vision CSCI-GA.2272-001 Assignment 1, part 2.\n",
        "\n",
        "Fall 2021 semester.\n",
        "\n",
        "Due date: **September 30th 2021.**\n",
        "\n",
        "## Introduction\n",
        "This assignment requires you to participate in a Kaggle competition with the rest of the class on the The German Traffic Sign Recognition Benchmark [http://benchmark.ini.rub.de/?section=gtsrb&subsection=news]. The objective is to produce a model that gives the highest possible accuracy on the test portion of this dataset. You can register for the competition using the private link: https://www.kaggle.com/c/nyu-computer-vision-csci-ga2271-2021/overview.\n",
        "\n",
        "Skeleton code is provided in the colab below. This contains code for training a simple default model and evaluating it on the test set. The evaluation script produces a file gtsrb_kaggle.csv that lists the IDs of the test set images, along with their predicted label. This file should be uploaded to the Kaggle webpage, which will then produce a test accuracy score. \n",
        "\n",
        "Your goal is to implement a new model architecture that improves upon the baseline performance. You are free to implement any approach covered in class or from research papers. This part will count for 50% of the overall grade for assignment 1. This Grading will depend on your Kaggle performance and rank, as well as novelty of the architecture.  \n",
        "\n",
        "## Rules\n",
        "You should make a copy of this Colab (File->Save a copy in Drive). Please start the assignment early and don’t be afraid to ask for help from either the TAs or myself. You are allowed to collaborate with other students in terms discussing ideas and possible solutions. However you code up the solution yourself, i.e. you must write your own code. Copying your friends code and just changing all the names of the variables is not allowed! You are not allowed to use solutions from similar assignments in courses from other institutions, or those found elsewhere on the web.\n",
        "Your solutions should be submitted via the Brightspace system. This should include a brief description (in the Colab) explaining the model architectures you explored, citing any relevant papers or techniques that you used. You should also include convergence plots of training accuracy vs epoch for relevant models. \n",
        "\n",
        "### Important Details\n",
        "• You are only allowed eight (8) submissions to the Kaggle evaluation server per day. This is to prevent over-fitting on the test dataset. So be sure to start the assignment early!\n",
        "\n",
        "• You are NOT ALLOWED to use the test set labels during training in any way. Doing so will be regarded as cheating and penalized accordingly.\n",
        "\n",
        "• The evaluation metric is accuracy, i.e. the fraction of test set examples where the predicted label agrees with the ground truth label.\n",
        "\n",
        "• You should be able to achieve a test accuracy of at least 0.95. \n",
        "\n",
        "• *Extra important:* Please use your NYU NetID as your Kaggle username, so the TAs can figure out which user you are on the leaderboard. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pghx7ngowha0"
      },
      "source": [
        "# Dataset Preparation\n",
        "\n",
        "\n",
        "1.  Download `dataset.zip` from to your local machine.\n",
        "2.  Unzip the file. You should see a `dataset` directory with three subfolders (`training,validation,testing`). \n",
        "3.  Go to Google Drive (on your NYU account) and make a directory `assign2_dataset` (New button --> New Folder).\n",
        "4.  Upload each of the three subfolders to it (New button --> Folder upload). \n",
        "5.  Run the code block below. It will ask for permission to mount your Google Drive (NYU account) so this colab can access it. Paste the authorization code into the box as requested. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0aPnIKXpWbN",
        "outputId": "c6e548d0-b95f-4166-d698-743adbb23c02"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd  /content/drive/'My Drive'/assign2_dataset/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/assign2_dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6jVfIVtrn5u"
      },
      "source": [
        "# Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z21UKj_bT--_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db28aee7-e6ae-42db-ebf7-4e38c2d85b19"
      },
      "source": [
        "!pip install torchsummary\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "from torchsummary import summary\n",
        "\n",
        "batch_size = 32\n",
        "momentum = 0.9\n",
        "lr = 0.001\n",
        "epochs = 30\n",
        "log_interval = 10\n",
        "min_valid_loss = np.inf\n",
        "seed = 1\n",
        "\n",
        "kwargs = {'num_workers': 2, 'pin_memory': True}\n",
        "torch.manual_seed(seed)\n",
        "class MyDataset(Dataset):\n",
        "\n",
        "    def __init__(self, X_path=\"X.pt\", y_path=\"y.pt\"):\n",
        "\n",
        "        self.X = torch.load(X_path).squeeze(1)\n",
        "        self.y = torch.load(y_path).squeeze(1)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.X.size(0)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_dataset = MyDataset(X_path=\"train/X.pt\", y_path=\"train/y.pt\")\n",
        "val_dataset = MyDataset(X_path=\"validation/X.pt\", y_path=\"validation/y.pt\")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset, batch_size=batch_size, shuffle=True, **kwargs)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5K5WOF8fogvH",
        "outputId": "585f8fc6-1f07-42a5-d6d8-6c21b4014994"
      },
      "source": [
        "train_dataset.y.unique(return_counts=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
              "         36, 37, 38, 39, 40, 41, 42]),\n",
              " tensor([ 120, 2130, 2160, 1320, 1890, 1770,  330, 1350, 1320, 1380, 1920, 1230,\n",
              "         2010, 2070,  690,  540,  330, 1020, 1110,  120,  270,  240,  300,  420,\n",
              "          180, 1410,  510,  150,  450,  180,  360,  690,  150,  599,  330, 1110,\n",
              "          300,  120, 1980,  210,  270,  150,  150]))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qd6W0pQRvZKO"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imoBfqK1HrXL"
      },
      "source": [
        "**Model story**\n",
        "\n",
        "Model architecture inspired by Lecture 3 where we discussed how more Convolution layers are helpful compared to adding linear(dense) layers. I kept only one linear layer and 4 convolution layers.\n",
        "\n",
        "**Dropout** after every conv layer didn't help here. Without dropout, the model was overfitting on train set with 0.0 loss but on the validation set the loss wasn't decreasing. This created a requirement of adding **Batch Normalisation** to the convolution layers which acts as a regularizer and eliminates the need of Dropout. [ref. arXiv:1502.03167 [Batch Normalization](https://arxiv.org/abs/1502.03167) ]\n",
        "\n",
        "**Optimizer**:\n",
        "[AdamW](https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html) (Modified Adam optimizer) with weight decay worked out better compared to SGD and Adam optimizer. I am using Leaky ReLU as activation function for each convolution layer which works better compared to Vanilla ReLU.\n",
        "\n",
        "**Model parameters:**\n",
        "\n",
        "I tried to keep the model neurons smaller in terms of amount as the image dataset has only ~35k images. This keeps the total trainable parameters lower and avoids overfitting the model. Overfitting the trainset will result in high variance and inconsistency in the test/real world results.\n",
        "\n",
        "I am saving models after each epoch and saving the model separately which has the lowest validation loss. Turns out the last epoch model (i.e. Epoch 30) works out the best on the Test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeev4SoMvazV"
      },
      "source": [
        "nclasses = 43 # GTSRB has 43 classes\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.fc1 = nn.LazyLinear(128)\n",
        "        self.fc2 = nn.LazyLinear(nclasses)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn1(F.leaky_relu(self.conv1(x)))\n",
        "        x = self.bn2(F.max_pool2d(F.leaky_relu(self.conv2(x)),2))\n",
        "        x = self.bn3(F.leaky_relu(self.conv3(x)))\n",
        "        x = self.bn4(F.max_pool2d(F.leaky_relu(self.conv4(x)),2))\n",
        "        x = x.view(-1, int(4096))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty9TAvrdvf8C"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4sP0pLwmKEB",
        "outputId": "0aa0dd4f-9fcc-4b82-c20d-4d5e27daca5e"
      },
      "source": [
        "model = Net()\n",
        "summary(model, (3, 32, 32))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 28, 28]           2,432\n",
            "       BatchNorm2d-2           [-1, 32, 28, 28]              64\n",
            "            Conv2d-3           [-1, 64, 26, 26]          18,496\n",
            "       BatchNorm2d-4           [-1, 64, 13, 13]             128\n",
            "            Conv2d-5          [-1, 128, 11, 11]          73,856\n",
            "       BatchNorm2d-6          [-1, 128, 11, 11]             256\n",
            "            Conv2d-7            [-1, 256, 9, 9]         295,168\n",
            "       BatchNorm2d-8            [-1, 256, 4, 4]             512\n",
            "            Linear-9                  [-1, 128]         524,416\n",
            "           Linear-10                   [-1, 43]           5,547\n",
            "================================================================\n",
            "Total params: 920,875\n",
            "Trainable params: 920,875\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.22\n",
            "Params size (MB): 3.51\n",
            "Estimated Total Size (MB): 4.75\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_A5-OCgBvhXv",
        "outputId": "7462dbf1-d208-4c0f-a5eb-94f90f551e33"
      },
      "source": [
        "\"\"\"next steps\"\"\"\n",
        "# print average f1 score after every epoch\n",
        "# Normalize the input variables (zero mean, unit variance)\n",
        "\n",
        "# Later on\n",
        "# ensemble\n",
        "\n",
        "\"\"\"::changes\"\"\"\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "valid_losses = []\n",
        "valid_accuracies = []\n",
        "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-2)\n",
        "\n",
        "# optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=1e-2)\n",
        "# optimizer = optim.Adam(model.parameters(), weight_decay=1e-2)\n",
        "def train(epoch):\n",
        "    model.train() # train mode, \n",
        "    correct = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad() # reset old gradients of previous epoch\n",
        "        output = model(data) # this calls __call__ of the nn.Module class which has forward function called\n",
        "        pred = output.argmax(dim=1, keepdim=True)\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        accuracy = 100. * correct / len(train_loader.dataset)\n",
        "\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step() # notifies the optimizer of one step\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "    train_losses.append(loss.item())\n",
        "    train_accuracies.append(accuracy)\n",
        "\n",
        "def validation():\n",
        "    model.eval()\n",
        "    validation_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in val_loader:\n",
        "        output = model(data)\n",
        "        validation_loss += F.nll_loss(output, target, reduction=\"sum\").item() # sum up batch loss\n",
        "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    validation_loss /= len(val_loader.dataset)\n",
        "    accuracy = 100. * correct / len(val_loader.dataset)\n",
        "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        validation_loss, correct, len(val_loader.dataset),\n",
        "        100. * correct / len(val_loader.dataset)))\n",
        "    return validation_loss, accuracy\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train(epoch)\n",
        "    valid_loss, valid_accuracy = validation()\n",
        "    valid_losses.append(valid_loss)\n",
        "    valid_accuracies.append(valid_accuracy)\n",
        "    # start\n",
        "    if min_valid_loss > valid_loss:\n",
        "        min_valid_loss = valid_loss\n",
        "         \n",
        "        # Saving State Dict\n",
        "        torch.save(model.state_dict(), 'saved_model.pth')\n",
        "    # end \n",
        "    model_file = 'model_' + str(epoch) + '.pth'\n",
        "    torch.save(model.state_dict(), model_file)\n",
        "    print('\\nSaved model to ' + model_file + '.')\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/35339 (0%)]\tLoss: 3.763604\n",
            "Train Epoch: 1 [320/35339 (1%)]\tLoss: 3.200487\n",
            "Train Epoch: 1 [640/35339 (2%)]\tLoss: 2.217439\n",
            "Train Epoch: 1 [960/35339 (3%)]\tLoss: 1.805235\n",
            "Train Epoch: 1 [1280/35339 (4%)]\tLoss: 1.552564\n",
            "Train Epoch: 1 [1600/35339 (5%)]\tLoss: 1.457412\n",
            "Train Epoch: 1 [1920/35339 (5%)]\tLoss: 2.028428\n",
            "Train Epoch: 1 [2240/35339 (6%)]\tLoss: 0.809759\n",
            "Train Epoch: 1 [2560/35339 (7%)]\tLoss: 0.491325\n",
            "Train Epoch: 1 [2880/35339 (8%)]\tLoss: 0.826764\n",
            "Train Epoch: 1 [3200/35339 (9%)]\tLoss: 0.574027\n",
            "Train Epoch: 1 [3520/35339 (10%)]\tLoss: 0.447092\n",
            "Train Epoch: 1 [3840/35339 (11%)]\tLoss: 0.545261\n",
            "Train Epoch: 1 [4160/35339 (12%)]\tLoss: 0.437120\n",
            "Train Epoch: 1 [4480/35339 (13%)]\tLoss: 0.638161\n",
            "Train Epoch: 1 [4800/35339 (14%)]\tLoss: 0.671957\n",
            "Train Epoch: 1 [5120/35339 (14%)]\tLoss: 0.277508\n",
            "Train Epoch: 1 [5440/35339 (15%)]\tLoss: 0.374621\n",
            "Train Epoch: 1 [5760/35339 (16%)]\tLoss: 0.270916\n",
            "Train Epoch: 1 [6080/35339 (17%)]\tLoss: 0.237715\n",
            "Train Epoch: 1 [6400/35339 (18%)]\tLoss: 0.189044\n",
            "Train Epoch: 1 [6720/35339 (19%)]\tLoss: 0.581723\n",
            "Train Epoch: 1 [7040/35339 (20%)]\tLoss: 0.581914\n",
            "Train Epoch: 1 [7360/35339 (21%)]\tLoss: 0.129673\n",
            "Train Epoch: 1 [7680/35339 (22%)]\tLoss: 0.528976\n",
            "Train Epoch: 1 [8000/35339 (23%)]\tLoss: 0.243697\n",
            "Train Epoch: 1 [8320/35339 (24%)]\tLoss: 0.486738\n",
            "Train Epoch: 1 [8640/35339 (24%)]\tLoss: 0.271584\n",
            "Train Epoch: 1 [8960/35339 (25%)]\tLoss: 0.334350\n",
            "Train Epoch: 1 [9280/35339 (26%)]\tLoss: 0.269184\n",
            "Train Epoch: 1 [9600/35339 (27%)]\tLoss: 0.071560\n",
            "Train Epoch: 1 [9920/35339 (28%)]\tLoss: 0.232932\n",
            "Train Epoch: 1 [10240/35339 (29%)]\tLoss: 0.294095\n",
            "Train Epoch: 1 [10560/35339 (30%)]\tLoss: 0.262485\n",
            "Train Epoch: 1 [10880/35339 (31%)]\tLoss: 0.107778\n",
            "Train Epoch: 1 [11200/35339 (32%)]\tLoss: 0.402873\n",
            "Train Epoch: 1 [11520/35339 (33%)]\tLoss: 0.103334\n",
            "Train Epoch: 1 [11840/35339 (33%)]\tLoss: 0.067891\n",
            "Train Epoch: 1 [12160/35339 (34%)]\tLoss: 0.214569\n",
            "Train Epoch: 1 [12480/35339 (35%)]\tLoss: 0.046801\n",
            "Train Epoch: 1 [12800/35339 (36%)]\tLoss: 0.203422\n",
            "Train Epoch: 1 [13120/35339 (37%)]\tLoss: 0.122787\n",
            "Train Epoch: 1 [13440/35339 (38%)]\tLoss: 0.059013\n",
            "Train Epoch: 1 [13760/35339 (39%)]\tLoss: 0.086539\n",
            "Train Epoch: 1 [14080/35339 (40%)]\tLoss: 0.041593\n",
            "Train Epoch: 1 [14400/35339 (41%)]\tLoss: 0.069524\n",
            "Train Epoch: 1 [14720/35339 (42%)]\tLoss: 0.040447\n",
            "Train Epoch: 1 [15040/35339 (43%)]\tLoss: 0.048050\n",
            "Train Epoch: 1 [15360/35339 (43%)]\tLoss: 0.050037\n",
            "Train Epoch: 1 [15680/35339 (44%)]\tLoss: 0.122020\n",
            "Train Epoch: 1 [16000/35339 (45%)]\tLoss: 0.270768\n",
            "Train Epoch: 1 [16320/35339 (46%)]\tLoss: 0.036060\n",
            "Train Epoch: 1 [16640/35339 (47%)]\tLoss: 0.246560\n",
            "Train Epoch: 1 [16960/35339 (48%)]\tLoss: 0.176448\n",
            "Train Epoch: 1 [17280/35339 (49%)]\tLoss: 0.089706\n",
            "Train Epoch: 1 [17600/35339 (50%)]\tLoss: 0.053969\n",
            "Train Epoch: 1 [17920/35339 (51%)]\tLoss: 0.269566\n",
            "Train Epoch: 1 [18240/35339 (52%)]\tLoss: 0.056043\n",
            "Train Epoch: 1 [18560/35339 (52%)]\tLoss: 0.090500\n",
            "Train Epoch: 1 [18880/35339 (53%)]\tLoss: 0.008822\n",
            "Train Epoch: 1 [19200/35339 (54%)]\tLoss: 0.501091\n",
            "Train Epoch: 1 [19520/35339 (55%)]\tLoss: 0.087884\n",
            "Train Epoch: 1 [19840/35339 (56%)]\tLoss: 0.033179\n",
            "Train Epoch: 1 [20160/35339 (57%)]\tLoss: 0.102496\n",
            "Train Epoch: 1 [20480/35339 (58%)]\tLoss: 0.432802\n",
            "Train Epoch: 1 [20800/35339 (59%)]\tLoss: 0.041463\n",
            "Train Epoch: 1 [21120/35339 (60%)]\tLoss: 0.088329\n",
            "Train Epoch: 1 [21440/35339 (61%)]\tLoss: 0.050842\n",
            "Train Epoch: 1 [21760/35339 (62%)]\tLoss: 0.012119\n",
            "Train Epoch: 1 [22080/35339 (62%)]\tLoss: 0.163284\n",
            "Train Epoch: 1 [22400/35339 (63%)]\tLoss: 0.015908\n",
            "Train Epoch: 1 [22720/35339 (64%)]\tLoss: 0.417426\n",
            "Train Epoch: 1 [23040/35339 (65%)]\tLoss: 0.008211\n",
            "Train Epoch: 1 [23360/35339 (66%)]\tLoss: 0.139487\n",
            "Train Epoch: 1 [23680/35339 (67%)]\tLoss: 0.060266\n",
            "Train Epoch: 1 [24000/35339 (68%)]\tLoss: 0.014482\n",
            "Train Epoch: 1 [24320/35339 (69%)]\tLoss: 0.020766\n",
            "Train Epoch: 1 [24640/35339 (70%)]\tLoss: 0.126874\n",
            "Train Epoch: 1 [24960/35339 (71%)]\tLoss: 0.142507\n",
            "Train Epoch: 1 [25280/35339 (71%)]\tLoss: 0.009729\n",
            "Train Epoch: 1 [25600/35339 (72%)]\tLoss: 0.026620\n",
            "Train Epoch: 1 [25920/35339 (73%)]\tLoss: 0.064922\n",
            "Train Epoch: 1 [26240/35339 (74%)]\tLoss: 0.005439\n",
            "Train Epoch: 1 [26560/35339 (75%)]\tLoss: 0.081236\n",
            "Train Epoch: 1 [26880/35339 (76%)]\tLoss: 0.188727\n",
            "Train Epoch: 1 [27200/35339 (77%)]\tLoss: 0.272240\n",
            "Train Epoch: 1 [27520/35339 (78%)]\tLoss: 0.129245\n",
            "Train Epoch: 1 [27840/35339 (79%)]\tLoss: 0.006864\n",
            "Train Epoch: 1 [28160/35339 (80%)]\tLoss: 0.120536\n",
            "Train Epoch: 1 [28480/35339 (81%)]\tLoss: 0.354437\n",
            "Train Epoch: 1 [28800/35339 (81%)]\tLoss: 0.049319\n",
            "Train Epoch: 1 [29120/35339 (82%)]\tLoss: 0.156556\n",
            "Train Epoch: 1 [29440/35339 (83%)]\tLoss: 0.109793\n",
            "Train Epoch: 1 [29760/35339 (84%)]\tLoss: 0.067571\n",
            "Train Epoch: 1 [30080/35339 (85%)]\tLoss: 0.016390\n",
            "Train Epoch: 1 [30400/35339 (86%)]\tLoss: 0.033366\n",
            "Train Epoch: 1 [30720/35339 (87%)]\tLoss: 0.002975\n",
            "Train Epoch: 1 [31040/35339 (88%)]\tLoss: 0.024691\n",
            "Train Epoch: 1 [31360/35339 (89%)]\tLoss: 0.035513\n",
            "Train Epoch: 1 [31680/35339 (90%)]\tLoss: 0.014406\n",
            "Train Epoch: 1 [32000/35339 (90%)]\tLoss: 0.191586\n",
            "Train Epoch: 1 [32320/35339 (91%)]\tLoss: 0.074163\n",
            "Train Epoch: 1 [32640/35339 (92%)]\tLoss: 0.125026\n",
            "Train Epoch: 1 [32960/35339 (93%)]\tLoss: 0.037209\n",
            "Train Epoch: 1 [33280/35339 (94%)]\tLoss: 0.298890\n",
            "Train Epoch: 1 [33600/35339 (95%)]\tLoss: 0.050616\n",
            "Train Epoch: 1 [33920/35339 (96%)]\tLoss: 0.015509\n",
            "Train Epoch: 1 [34240/35339 (97%)]\tLoss: 0.058819\n",
            "Train Epoch: 1 [34560/35339 (98%)]\tLoss: 0.044727\n",
            "Train Epoch: 1 [34880/35339 (99%)]\tLoss: 0.221346\n",
            "Train Epoch: 1 [35200/35339 (100%)]\tLoss: 0.078921\n",
            "\n",
            "Validation set: Average loss: 0.1761, Accuracy: 3661/3870 (95%)\n",
            "\n",
            "\n",
            "Saved model to model_1.pth.\n",
            "Train Epoch: 2 [0/35339 (0%)]\tLoss: 0.286234\n",
            "Train Epoch: 2 [320/35339 (1%)]\tLoss: 0.398418\n",
            "Train Epoch: 2 [640/35339 (2%)]\tLoss: 0.005802\n",
            "Train Epoch: 2 [960/35339 (3%)]\tLoss: 0.022600\n",
            "Train Epoch: 2 [1280/35339 (4%)]\tLoss: 0.086565\n",
            "Train Epoch: 2 [1600/35339 (5%)]\tLoss: 0.108609\n",
            "Train Epoch: 2 [1920/35339 (5%)]\tLoss: 0.102419\n",
            "Train Epoch: 2 [2240/35339 (6%)]\tLoss: 0.033332\n",
            "Train Epoch: 2 [2560/35339 (7%)]\tLoss: 0.038088\n",
            "Train Epoch: 2 [2880/35339 (8%)]\tLoss: 0.192429\n",
            "Train Epoch: 2 [3200/35339 (9%)]\tLoss: 0.138600\n",
            "Train Epoch: 2 [3520/35339 (10%)]\tLoss: 0.018902\n",
            "Train Epoch: 2 [3840/35339 (11%)]\tLoss: 0.000812\n",
            "Train Epoch: 2 [4160/35339 (12%)]\tLoss: 0.060091\n",
            "Train Epoch: 2 [4480/35339 (13%)]\tLoss: 0.029290\n",
            "Train Epoch: 2 [4800/35339 (14%)]\tLoss: 0.042521\n",
            "Train Epoch: 2 [5120/35339 (14%)]\tLoss: 0.096860\n",
            "Train Epoch: 2 [5440/35339 (15%)]\tLoss: 0.081670\n",
            "Train Epoch: 2 [5760/35339 (16%)]\tLoss: 0.115689\n",
            "Train Epoch: 2 [6080/35339 (17%)]\tLoss: 0.019956\n",
            "Train Epoch: 2 [6400/35339 (18%)]\tLoss: 0.012017\n",
            "Train Epoch: 2 [6720/35339 (19%)]\tLoss: 0.016013\n",
            "Train Epoch: 2 [7040/35339 (20%)]\tLoss: 0.111664\n",
            "Train Epoch: 2 [7360/35339 (21%)]\tLoss: 0.046599\n",
            "Train Epoch: 2 [7680/35339 (22%)]\tLoss: 0.011775\n",
            "Train Epoch: 2 [8000/35339 (23%)]\tLoss: 0.172145\n",
            "Train Epoch: 2 [8320/35339 (24%)]\tLoss: 0.189472\n",
            "Train Epoch: 2 [8640/35339 (24%)]\tLoss: 0.101872\n",
            "Train Epoch: 2 [8960/35339 (25%)]\tLoss: 0.072454\n",
            "Train Epoch: 2 [9280/35339 (26%)]\tLoss: 0.010073\n",
            "Train Epoch: 2 [9600/35339 (27%)]\tLoss: 0.011557\n",
            "Train Epoch: 2 [9920/35339 (28%)]\tLoss: 0.025831\n",
            "Train Epoch: 2 [10240/35339 (29%)]\tLoss: 0.007134\n",
            "Train Epoch: 2 [10560/35339 (30%)]\tLoss: 0.036129\n",
            "Train Epoch: 2 [10880/35339 (31%)]\tLoss: 0.084490\n",
            "Train Epoch: 2 [11200/35339 (32%)]\tLoss: 0.138394\n",
            "Train Epoch: 2 [11520/35339 (33%)]\tLoss: 0.010354\n",
            "Train Epoch: 2 [11840/35339 (33%)]\tLoss: 0.028985\n",
            "Train Epoch: 2 [12160/35339 (34%)]\tLoss: 0.000986\n",
            "Train Epoch: 2 [12480/35339 (35%)]\tLoss: 0.244861\n",
            "Train Epoch: 2 [12800/35339 (36%)]\tLoss: 0.077529\n",
            "Train Epoch: 2 [13120/35339 (37%)]\tLoss: 0.108880\n",
            "Train Epoch: 2 [13440/35339 (38%)]\tLoss: 0.012535\n",
            "Train Epoch: 2 [13760/35339 (39%)]\tLoss: 0.000956\n",
            "Train Epoch: 2 [14080/35339 (40%)]\tLoss: 0.011530\n",
            "Train Epoch: 2 [14400/35339 (41%)]\tLoss: 0.037688\n",
            "Train Epoch: 2 [14720/35339 (42%)]\tLoss: 0.005797\n",
            "Train Epoch: 2 [15040/35339 (43%)]\tLoss: 0.101769\n",
            "Train Epoch: 2 [15360/35339 (43%)]\tLoss: 0.009666\n",
            "Train Epoch: 2 [15680/35339 (44%)]\tLoss: 0.045086\n",
            "Train Epoch: 2 [16000/35339 (45%)]\tLoss: 0.029351\n",
            "Train Epoch: 2 [16320/35339 (46%)]\tLoss: 0.022897\n",
            "Train Epoch: 2 [16640/35339 (47%)]\tLoss: 0.000308\n",
            "Train Epoch: 2 [16960/35339 (48%)]\tLoss: 0.018565\n",
            "Train Epoch: 2 [17280/35339 (49%)]\tLoss: 0.072229\n",
            "Train Epoch: 2 [17600/35339 (50%)]\tLoss: 0.009932\n",
            "Train Epoch: 2 [17920/35339 (51%)]\tLoss: 0.077870\n",
            "Train Epoch: 2 [18240/35339 (52%)]\tLoss: 0.033018\n",
            "Train Epoch: 2 [18560/35339 (52%)]\tLoss: 0.047307\n",
            "Train Epoch: 2 [18880/35339 (53%)]\tLoss: 0.038663\n",
            "Train Epoch: 2 [19200/35339 (54%)]\tLoss: 0.178898\n",
            "Train Epoch: 2 [19520/35339 (55%)]\tLoss: 0.023145\n",
            "Train Epoch: 2 [19840/35339 (56%)]\tLoss: 0.012283\n",
            "Train Epoch: 2 [20160/35339 (57%)]\tLoss: 0.010040\n",
            "Train Epoch: 2 [20480/35339 (58%)]\tLoss: 0.045065\n",
            "Train Epoch: 2 [20800/35339 (59%)]\tLoss: 0.157341\n",
            "Train Epoch: 2 [21120/35339 (60%)]\tLoss: 0.069076\n",
            "Train Epoch: 2 [21440/35339 (61%)]\tLoss: 0.022418\n",
            "Train Epoch: 2 [21760/35339 (62%)]\tLoss: 0.001310\n",
            "Train Epoch: 2 [22080/35339 (62%)]\tLoss: 0.039171\n",
            "Train Epoch: 2 [22400/35339 (63%)]\tLoss: 0.020223\n",
            "Train Epoch: 2 [22720/35339 (64%)]\tLoss: 0.180579\n",
            "Train Epoch: 2 [23040/35339 (65%)]\tLoss: 0.004479\n",
            "Train Epoch: 2 [23360/35339 (66%)]\tLoss: 0.013206\n",
            "Train Epoch: 2 [23680/35339 (67%)]\tLoss: 0.066018\n",
            "Train Epoch: 2 [24000/35339 (68%)]\tLoss: 0.007197\n",
            "Train Epoch: 2 [24320/35339 (69%)]\tLoss: 0.020051\n",
            "Train Epoch: 2 [24640/35339 (70%)]\tLoss: 0.073640\n",
            "Train Epoch: 2 [24960/35339 (71%)]\tLoss: 0.060394\n",
            "Train Epoch: 2 [25280/35339 (71%)]\tLoss: 0.085406\n",
            "Train Epoch: 2 [25600/35339 (72%)]\tLoss: 0.220835\n",
            "Train Epoch: 2 [25920/35339 (73%)]\tLoss: 0.010617\n",
            "Train Epoch: 2 [26240/35339 (74%)]\tLoss: 0.111762\n",
            "Train Epoch: 2 [26560/35339 (75%)]\tLoss: 0.007032\n",
            "Train Epoch: 2 [26880/35339 (76%)]\tLoss: 0.025391\n",
            "Train Epoch: 2 [27200/35339 (77%)]\tLoss: 0.001494\n",
            "Train Epoch: 2 [27520/35339 (78%)]\tLoss: 0.004854\n",
            "Train Epoch: 2 [27840/35339 (79%)]\tLoss: 0.005048\n",
            "Train Epoch: 2 [28160/35339 (80%)]\tLoss: 0.015606\n",
            "Train Epoch: 2 [28480/35339 (81%)]\tLoss: 0.057351\n",
            "Train Epoch: 2 [28800/35339 (81%)]\tLoss: 0.085152\n",
            "Train Epoch: 2 [29120/35339 (82%)]\tLoss: 0.055444\n",
            "Train Epoch: 2 [29440/35339 (83%)]\tLoss: 0.096001\n",
            "Train Epoch: 2 [29760/35339 (84%)]\tLoss: 0.004792\n",
            "Train Epoch: 2 [30080/35339 (85%)]\tLoss: 0.022316\n",
            "Train Epoch: 2 [30400/35339 (86%)]\tLoss: 0.008806\n",
            "Train Epoch: 2 [30720/35339 (87%)]\tLoss: 0.020108\n",
            "Train Epoch: 2 [31040/35339 (88%)]\tLoss: 0.000255\n",
            "Train Epoch: 2 [31360/35339 (89%)]\tLoss: 0.011923\n",
            "Train Epoch: 2 [31680/35339 (90%)]\tLoss: 0.060923\n",
            "Train Epoch: 2 [32000/35339 (90%)]\tLoss: 0.018642\n",
            "Train Epoch: 2 [32320/35339 (91%)]\tLoss: 0.007569\n",
            "Train Epoch: 2 [32640/35339 (92%)]\tLoss: 0.196909\n",
            "Train Epoch: 2 [32960/35339 (93%)]\tLoss: 0.076285\n",
            "Train Epoch: 2 [33280/35339 (94%)]\tLoss: 0.000545\n",
            "Train Epoch: 2 [33600/35339 (95%)]\tLoss: 0.033507\n",
            "Train Epoch: 2 [33920/35339 (96%)]\tLoss: 0.018290\n",
            "Train Epoch: 2 [34240/35339 (97%)]\tLoss: 0.029162\n",
            "Train Epoch: 2 [34560/35339 (98%)]\tLoss: 0.101596\n",
            "Train Epoch: 2 [34880/35339 (99%)]\tLoss: 0.040092\n",
            "Train Epoch: 2 [35200/35339 (100%)]\tLoss: 0.035075\n",
            "\n",
            "Validation set: Average loss: 0.2129, Accuracy: 3680/3870 (95%)\n",
            "\n",
            "\n",
            "Saved model to model_2.pth.\n",
            "Train Epoch: 3 [0/35339 (0%)]\tLoss: 0.000290\n",
            "Train Epoch: 3 [320/35339 (1%)]\tLoss: 0.219123\n",
            "Train Epoch: 3 [640/35339 (2%)]\tLoss: 0.000915\n",
            "Train Epoch: 3 [960/35339 (3%)]\tLoss: 0.058514\n",
            "Train Epoch: 3 [1280/35339 (4%)]\tLoss: 0.000205\n",
            "Train Epoch: 3 [1600/35339 (5%)]\tLoss: 0.005273\n",
            "Train Epoch: 3 [1920/35339 (5%)]\tLoss: 0.004583\n",
            "Train Epoch: 3 [2240/35339 (6%)]\tLoss: 0.000963\n",
            "Train Epoch: 3 [2560/35339 (7%)]\tLoss: 0.001108\n",
            "Train Epoch: 3 [2880/35339 (8%)]\tLoss: 0.021529\n",
            "Train Epoch: 3 [3200/35339 (9%)]\tLoss: 0.071458\n",
            "Train Epoch: 3 [3520/35339 (10%)]\tLoss: 0.000111\n",
            "Train Epoch: 3 [3840/35339 (11%)]\tLoss: 0.127986\n",
            "Train Epoch: 3 [4160/35339 (12%)]\tLoss: 0.041511\n",
            "Train Epoch: 3 [4480/35339 (13%)]\tLoss: 0.065035\n",
            "Train Epoch: 3 [4800/35339 (14%)]\tLoss: 0.007700\n",
            "Train Epoch: 3 [5120/35339 (14%)]\tLoss: 0.009765\n",
            "Train Epoch: 3 [5440/35339 (15%)]\tLoss: 0.041869\n",
            "Train Epoch: 3 [5760/35339 (16%)]\tLoss: 0.000536\n",
            "Train Epoch: 3 [6080/35339 (17%)]\tLoss: 0.008385\n",
            "Train Epoch: 3 [6400/35339 (18%)]\tLoss: 0.057909\n",
            "Train Epoch: 3 [6720/35339 (19%)]\tLoss: 0.002141\n",
            "Train Epoch: 3 [7040/35339 (20%)]\tLoss: 0.001105\n",
            "Train Epoch: 3 [7360/35339 (21%)]\tLoss: 0.016283\n",
            "Train Epoch: 3 [7680/35339 (22%)]\tLoss: 0.093649\n",
            "Train Epoch: 3 [8000/35339 (23%)]\tLoss: 0.011721\n",
            "Train Epoch: 3 [8320/35339 (24%)]\tLoss: 0.013202\n",
            "Train Epoch: 3 [8640/35339 (24%)]\tLoss: 0.001631\n",
            "Train Epoch: 3 [8960/35339 (25%)]\tLoss: 0.028171\n",
            "Train Epoch: 3 [9280/35339 (26%)]\tLoss: 0.007336\n",
            "Train Epoch: 3 [9600/35339 (27%)]\tLoss: 0.001726\n",
            "Train Epoch: 3 [9920/35339 (28%)]\tLoss: 0.075679\n",
            "Train Epoch: 3 [10240/35339 (29%)]\tLoss: 0.116649\n",
            "Train Epoch: 3 [10560/35339 (30%)]\tLoss: 0.010486\n",
            "Train Epoch: 3 [10880/35339 (31%)]\tLoss: 0.000437\n",
            "Train Epoch: 3 [11200/35339 (32%)]\tLoss: 0.012573\n",
            "Train Epoch: 3 [11520/35339 (33%)]\tLoss: 0.012361\n",
            "Train Epoch: 3 [11840/35339 (33%)]\tLoss: 0.009490\n",
            "Train Epoch: 3 [12160/35339 (34%)]\tLoss: 0.029268\n",
            "Train Epoch: 3 [12480/35339 (35%)]\tLoss: 0.045882\n",
            "Train Epoch: 3 [12800/35339 (36%)]\tLoss: 0.006871\n",
            "Train Epoch: 3 [13120/35339 (37%)]\tLoss: 0.001060\n",
            "Train Epoch: 3 [13440/35339 (38%)]\tLoss: 0.003159\n",
            "Train Epoch: 3 [13760/35339 (39%)]\tLoss: 0.243968\n",
            "Train Epoch: 3 [14080/35339 (40%)]\tLoss: 0.111099\n",
            "Train Epoch: 3 [14400/35339 (41%)]\tLoss: 0.057425\n",
            "Train Epoch: 3 [14720/35339 (42%)]\tLoss: 0.053603\n",
            "Train Epoch: 3 [15040/35339 (43%)]\tLoss: 0.004035\n",
            "Train Epoch: 3 [15360/35339 (43%)]\tLoss: 0.068685\n",
            "Train Epoch: 3 [15680/35339 (44%)]\tLoss: 0.050248\n",
            "Train Epoch: 3 [16000/35339 (45%)]\tLoss: 0.046699\n",
            "Train Epoch: 3 [16320/35339 (46%)]\tLoss: 0.007036\n",
            "Train Epoch: 3 [16640/35339 (47%)]\tLoss: 0.000739\n",
            "Train Epoch: 3 [16960/35339 (48%)]\tLoss: 0.018613\n",
            "Train Epoch: 3 [17280/35339 (49%)]\tLoss: 0.018167\n",
            "Train Epoch: 3 [17600/35339 (50%)]\tLoss: 0.075527\n",
            "Train Epoch: 3 [17920/35339 (51%)]\tLoss: 0.183801\n",
            "Train Epoch: 3 [18240/35339 (52%)]\tLoss: 0.206114\n",
            "Train Epoch: 3 [18560/35339 (52%)]\tLoss: 0.169132\n",
            "Train Epoch: 3 [18880/35339 (53%)]\tLoss: 0.000329\n",
            "Train Epoch: 3 [19200/35339 (54%)]\tLoss: 0.044117\n",
            "Train Epoch: 3 [19520/35339 (55%)]\tLoss: 0.086857\n",
            "Train Epoch: 3 [19840/35339 (56%)]\tLoss: 0.053076\n",
            "Train Epoch: 3 [20160/35339 (57%)]\tLoss: 0.014739\n",
            "Train Epoch: 3 [20480/35339 (58%)]\tLoss: 0.038666\n",
            "Train Epoch: 3 [20800/35339 (59%)]\tLoss: 0.032775\n",
            "Train Epoch: 3 [21120/35339 (60%)]\tLoss: 0.062141\n",
            "Train Epoch: 3 [21440/35339 (61%)]\tLoss: 0.001605\n",
            "Train Epoch: 3 [21760/35339 (62%)]\tLoss: 0.009828\n",
            "Train Epoch: 3 [22080/35339 (62%)]\tLoss: 0.000551\n",
            "Train Epoch: 3 [22400/35339 (63%)]\tLoss: 0.025249\n",
            "Train Epoch: 3 [22720/35339 (64%)]\tLoss: 0.034068\n",
            "Train Epoch: 3 [23040/35339 (65%)]\tLoss: 0.187602\n",
            "Train Epoch: 3 [23360/35339 (66%)]\tLoss: 0.001528\n",
            "Train Epoch: 3 [23680/35339 (67%)]\tLoss: 0.088082\n",
            "Train Epoch: 3 [24000/35339 (68%)]\tLoss: 0.015705\n",
            "Train Epoch: 3 [24320/35339 (69%)]\tLoss: 0.003910\n",
            "Train Epoch: 3 [24640/35339 (70%)]\tLoss: 0.001598\n",
            "Train Epoch: 3 [24960/35339 (71%)]\tLoss: 0.002394\n",
            "Train Epoch: 3 [25280/35339 (71%)]\tLoss: 0.004758\n",
            "Train Epoch: 3 [25600/35339 (72%)]\tLoss: 0.087542\n",
            "Train Epoch: 3 [25920/35339 (73%)]\tLoss: 0.002475\n",
            "Train Epoch: 3 [26240/35339 (74%)]\tLoss: 0.000197\n",
            "Train Epoch: 3 [26560/35339 (75%)]\tLoss: 0.006416\n",
            "Train Epoch: 3 [26880/35339 (76%)]\tLoss: 0.004483\n",
            "Train Epoch: 3 [27200/35339 (77%)]\tLoss: 0.163301\n",
            "Train Epoch: 3 [27520/35339 (78%)]\tLoss: 0.002840\n",
            "Train Epoch: 3 [27840/35339 (79%)]\tLoss: 0.008457\n",
            "Train Epoch: 3 [28160/35339 (80%)]\tLoss: 0.137823\n",
            "Train Epoch: 3 [28480/35339 (81%)]\tLoss: 0.138264\n",
            "Train Epoch: 3 [28800/35339 (81%)]\tLoss: 0.150724\n",
            "Train Epoch: 3 [29120/35339 (82%)]\tLoss: 0.067908\n",
            "Train Epoch: 3 [29440/35339 (83%)]\tLoss: 0.013873\n",
            "Train Epoch: 3 [29760/35339 (84%)]\tLoss: 0.039380\n",
            "Train Epoch: 3 [30080/35339 (85%)]\tLoss: 0.005383\n",
            "Train Epoch: 3 [30400/35339 (86%)]\tLoss: 0.132787\n",
            "Train Epoch: 3 [30720/35339 (87%)]\tLoss: 0.014562\n",
            "Train Epoch: 3 [31040/35339 (88%)]\tLoss: 0.322971\n",
            "Train Epoch: 3 [31360/35339 (89%)]\tLoss: 0.001265\n",
            "Train Epoch: 3 [31680/35339 (90%)]\tLoss: 0.010736\n",
            "Train Epoch: 3 [32000/35339 (90%)]\tLoss: 0.138338\n",
            "Train Epoch: 3 [32320/35339 (91%)]\tLoss: 0.156018\n",
            "Train Epoch: 3 [32640/35339 (92%)]\tLoss: 0.040691\n",
            "Train Epoch: 3 [32960/35339 (93%)]\tLoss: 0.003135\n",
            "Train Epoch: 3 [33280/35339 (94%)]\tLoss: 0.000293\n",
            "Train Epoch: 3 [33600/35339 (95%)]\tLoss: 0.077889\n",
            "Train Epoch: 3 [33920/35339 (96%)]\tLoss: 0.006062\n",
            "Train Epoch: 3 [34240/35339 (97%)]\tLoss: 0.000705\n",
            "Train Epoch: 3 [34560/35339 (98%)]\tLoss: 0.002469\n",
            "Train Epoch: 3 [34880/35339 (99%)]\tLoss: 0.016340\n",
            "Train Epoch: 3 [35200/35339 (100%)]\tLoss: 0.083287\n",
            "\n",
            "Validation set: Average loss: 0.2352, Accuracy: 3680/3870 (95%)\n",
            "\n",
            "\n",
            "Saved model to model_3.pth.\n",
            "Train Epoch: 4 [0/35339 (0%)]\tLoss: 0.149576\n",
            "Train Epoch: 4 [320/35339 (1%)]\tLoss: 0.031824\n",
            "Train Epoch: 4 [640/35339 (2%)]\tLoss: 0.135223\n",
            "Train Epoch: 4 [960/35339 (3%)]\tLoss: 0.021850\n",
            "Train Epoch: 4 [1280/35339 (4%)]\tLoss: 0.012671\n",
            "Train Epoch: 4 [1600/35339 (5%)]\tLoss: 0.002285\n",
            "Train Epoch: 4 [1920/35339 (5%)]\tLoss: 0.189389\n",
            "Train Epoch: 4 [2240/35339 (6%)]\tLoss: 0.097154\n",
            "Train Epoch: 4 [2560/35339 (7%)]\tLoss: 0.155498\n",
            "Train Epoch: 4 [2880/35339 (8%)]\tLoss: 0.064912\n",
            "Train Epoch: 4 [3200/35339 (9%)]\tLoss: 0.000155\n",
            "Train Epoch: 4 [3520/35339 (10%)]\tLoss: 0.012514\n",
            "Train Epoch: 4 [3840/35339 (11%)]\tLoss: 0.007691\n",
            "Train Epoch: 4 [4160/35339 (12%)]\tLoss: 0.005236\n",
            "Train Epoch: 4 [4480/35339 (13%)]\tLoss: 0.033715\n",
            "Train Epoch: 4 [4800/35339 (14%)]\tLoss: 0.036246\n",
            "Train Epoch: 4 [5120/35339 (14%)]\tLoss: 0.012550\n",
            "Train Epoch: 4 [5440/35339 (15%)]\tLoss: 0.003420\n",
            "Train Epoch: 4 [5760/35339 (16%)]\tLoss: 0.000079\n",
            "Train Epoch: 4 [6080/35339 (17%)]\tLoss: 0.063128\n",
            "Train Epoch: 4 [6400/35339 (18%)]\tLoss: 0.047568\n",
            "Train Epoch: 4 [6720/35339 (19%)]\tLoss: 0.000233\n",
            "Train Epoch: 4 [7040/35339 (20%)]\tLoss: 0.218121\n",
            "Train Epoch: 4 [7360/35339 (21%)]\tLoss: 0.063437\n",
            "Train Epoch: 4 [7680/35339 (22%)]\tLoss: 0.004052\n",
            "Train Epoch: 4 [8000/35339 (23%)]\tLoss: 0.007665\n",
            "Train Epoch: 4 [8320/35339 (24%)]\tLoss: 0.077800\n",
            "Train Epoch: 4 [8640/35339 (24%)]\tLoss: 0.010642\n",
            "Train Epoch: 4 [8960/35339 (25%)]\tLoss: 0.001073\n",
            "Train Epoch: 4 [9280/35339 (26%)]\tLoss: 0.002585\n",
            "Train Epoch: 4 [9600/35339 (27%)]\tLoss: 0.003762\n",
            "Train Epoch: 4 [9920/35339 (28%)]\tLoss: 0.000365\n",
            "Train Epoch: 4 [10240/35339 (29%)]\tLoss: 0.050006\n",
            "Train Epoch: 4 [10560/35339 (30%)]\tLoss: 0.001236\n",
            "Train Epoch: 4 [10880/35339 (31%)]\tLoss: 0.043468\n",
            "Train Epoch: 4 [11200/35339 (32%)]\tLoss: 0.004895\n",
            "Train Epoch: 4 [11520/35339 (33%)]\tLoss: 0.527593\n",
            "Train Epoch: 4 [11840/35339 (33%)]\tLoss: 0.053124\n",
            "Train Epoch: 4 [12160/35339 (34%)]\tLoss: 0.019747\n",
            "Train Epoch: 4 [12480/35339 (35%)]\tLoss: 0.010775\n",
            "Train Epoch: 4 [12800/35339 (36%)]\tLoss: 0.001731\n",
            "Train Epoch: 4 [13120/35339 (37%)]\tLoss: 0.087792\n",
            "Train Epoch: 4 [13440/35339 (38%)]\tLoss: 0.024549\n",
            "Train Epoch: 4 [13760/35339 (39%)]\tLoss: 0.064919\n",
            "Train Epoch: 4 [14080/35339 (40%)]\tLoss: 0.002873\n",
            "Train Epoch: 4 [14400/35339 (41%)]\tLoss: 0.042174\n",
            "Train Epoch: 4 [14720/35339 (42%)]\tLoss: 0.002698\n",
            "Train Epoch: 4 [15040/35339 (43%)]\tLoss: 0.008669\n",
            "Train Epoch: 4 [15360/35339 (43%)]\tLoss: 0.000113\n",
            "Train Epoch: 4 [15680/35339 (44%)]\tLoss: 0.106102\n",
            "Train Epoch: 4 [16000/35339 (45%)]\tLoss: 0.041644\n",
            "Train Epoch: 4 [16320/35339 (46%)]\tLoss: 0.005051\n",
            "Train Epoch: 4 [16640/35339 (47%)]\tLoss: 0.083829\n",
            "Train Epoch: 4 [16960/35339 (48%)]\tLoss: 0.092324\n",
            "Train Epoch: 4 [17280/35339 (49%)]\tLoss: 0.008667\n",
            "Train Epoch: 4 [17600/35339 (50%)]\tLoss: 0.223453\n",
            "Train Epoch: 4 [17920/35339 (51%)]\tLoss: 0.005232\n",
            "Train Epoch: 4 [18240/35339 (52%)]\tLoss: 0.000819\n",
            "Train Epoch: 4 [18560/35339 (52%)]\tLoss: 0.000040\n",
            "Train Epoch: 4 [18880/35339 (53%)]\tLoss: 0.016444\n",
            "Train Epoch: 4 [19200/35339 (54%)]\tLoss: 0.017076\n",
            "Train Epoch: 4 [19520/35339 (55%)]\tLoss: 0.000242\n",
            "Train Epoch: 4 [19840/35339 (56%)]\tLoss: 0.001718\n",
            "Train Epoch: 4 [20160/35339 (57%)]\tLoss: 0.023111\n",
            "Train Epoch: 4 [20480/35339 (58%)]\tLoss: 0.027896\n",
            "Train Epoch: 4 [20800/35339 (59%)]\tLoss: 0.009841\n",
            "Train Epoch: 4 [21120/35339 (60%)]\tLoss: 0.071198\n",
            "Train Epoch: 4 [21440/35339 (61%)]\tLoss: 0.000394\n",
            "Train Epoch: 4 [21760/35339 (62%)]\tLoss: 0.128041\n",
            "Train Epoch: 4 [22080/35339 (62%)]\tLoss: 0.027130\n",
            "Train Epoch: 4 [22400/35339 (63%)]\tLoss: 0.014785\n",
            "Train Epoch: 4 [22720/35339 (64%)]\tLoss: 0.001321\n",
            "Train Epoch: 4 [23040/35339 (65%)]\tLoss: 0.000010\n",
            "Train Epoch: 4 [23360/35339 (66%)]\tLoss: 0.000117\n",
            "Train Epoch: 4 [23680/35339 (67%)]\tLoss: 0.000412\n",
            "Train Epoch: 4 [24000/35339 (68%)]\tLoss: 0.021157\n",
            "Train Epoch: 4 [24320/35339 (69%)]\tLoss: 0.001540\n",
            "Train Epoch: 4 [24640/35339 (70%)]\tLoss: 0.001099\n",
            "Train Epoch: 4 [24960/35339 (71%)]\tLoss: 0.006780\n",
            "Train Epoch: 4 [25280/35339 (71%)]\tLoss: 0.000228\n",
            "Train Epoch: 4 [25600/35339 (72%)]\tLoss: 0.004938\n",
            "Train Epoch: 4 [25920/35339 (73%)]\tLoss: 0.000428\n",
            "Train Epoch: 4 [26240/35339 (74%)]\tLoss: 0.013208\n",
            "Train Epoch: 4 [26560/35339 (75%)]\tLoss: 0.338880\n",
            "Train Epoch: 4 [26880/35339 (76%)]\tLoss: 0.076063\n",
            "Train Epoch: 4 [27200/35339 (77%)]\tLoss: 0.017280\n",
            "Train Epoch: 4 [27520/35339 (78%)]\tLoss: 0.009609\n",
            "Train Epoch: 4 [27840/35339 (79%)]\tLoss: 0.001668\n",
            "Train Epoch: 4 [28160/35339 (80%)]\tLoss: 0.002308\n",
            "Train Epoch: 4 [28480/35339 (81%)]\tLoss: 0.074884\n",
            "Train Epoch: 4 [28800/35339 (81%)]\tLoss: 0.026794\n",
            "Train Epoch: 4 [29120/35339 (82%)]\tLoss: 0.030044\n",
            "Train Epoch: 4 [29440/35339 (83%)]\tLoss: 0.000650\n",
            "Train Epoch: 4 [29760/35339 (84%)]\tLoss: 0.000348\n",
            "Train Epoch: 4 [30080/35339 (85%)]\tLoss: 0.287555\n",
            "Train Epoch: 4 [30400/35339 (86%)]\tLoss: 0.000794\n",
            "Train Epoch: 4 [30720/35339 (87%)]\tLoss: 0.006039\n",
            "Train Epoch: 4 [31040/35339 (88%)]\tLoss: 0.106379\n",
            "Train Epoch: 4 [31360/35339 (89%)]\tLoss: 0.002097\n",
            "Train Epoch: 4 [31680/35339 (90%)]\tLoss: 0.180602\n",
            "Train Epoch: 4 [32000/35339 (90%)]\tLoss: 0.095382\n",
            "Train Epoch: 4 [32320/35339 (91%)]\tLoss: 0.001432\n",
            "Train Epoch: 4 [32640/35339 (92%)]\tLoss: 0.000106\n",
            "Train Epoch: 4 [32960/35339 (93%)]\tLoss: 0.029122\n",
            "Train Epoch: 4 [33280/35339 (94%)]\tLoss: 0.000277\n",
            "Train Epoch: 4 [33600/35339 (95%)]\tLoss: 0.003796\n",
            "Train Epoch: 4 [33920/35339 (96%)]\tLoss: 0.006149\n",
            "Train Epoch: 4 [34240/35339 (97%)]\tLoss: 0.000861\n",
            "Train Epoch: 4 [34560/35339 (98%)]\tLoss: 0.031161\n",
            "Train Epoch: 4 [34880/35339 (99%)]\tLoss: 0.000587\n",
            "Train Epoch: 4 [35200/35339 (100%)]\tLoss: 0.357438\n",
            "\n",
            "Validation set: Average loss: 0.2115, Accuracy: 3691/3870 (95%)\n",
            "\n",
            "\n",
            "Saved model to model_4.pth.\n",
            "Train Epoch: 5 [0/35339 (0%)]\tLoss: 0.005647\n",
            "Train Epoch: 5 [320/35339 (1%)]\tLoss: 0.000679\n",
            "Train Epoch: 5 [640/35339 (2%)]\tLoss: 0.007976\n",
            "Train Epoch: 5 [960/35339 (3%)]\tLoss: 0.007242\n",
            "Train Epoch: 5 [1280/35339 (4%)]\tLoss: 0.393851\n",
            "Train Epoch: 5 [1600/35339 (5%)]\tLoss: 0.163500\n",
            "Train Epoch: 5 [1920/35339 (5%)]\tLoss: 0.106060\n",
            "Train Epoch: 5 [2240/35339 (6%)]\tLoss: 0.005471\n",
            "Train Epoch: 5 [2560/35339 (7%)]\tLoss: 0.023926\n",
            "Train Epoch: 5 [2880/35339 (8%)]\tLoss: 0.001657\n",
            "Train Epoch: 5 [3200/35339 (9%)]\tLoss: 0.000607\n",
            "Train Epoch: 5 [3520/35339 (10%)]\tLoss: 0.000175\n",
            "Train Epoch: 5 [3840/35339 (11%)]\tLoss: 0.012842\n",
            "Train Epoch: 5 [4160/35339 (12%)]\tLoss: 0.063563\n",
            "Train Epoch: 5 [4480/35339 (13%)]\tLoss: 0.068855\n",
            "Train Epoch: 5 [4800/35339 (14%)]\tLoss: 0.004554\n",
            "Train Epoch: 5 [5120/35339 (14%)]\tLoss: 0.029552\n",
            "Train Epoch: 5 [5440/35339 (15%)]\tLoss: 0.000501\n",
            "Train Epoch: 5 [5760/35339 (16%)]\tLoss: 0.000604\n",
            "Train Epoch: 5 [6080/35339 (17%)]\tLoss: 0.216778\n",
            "Train Epoch: 5 [6400/35339 (18%)]\tLoss: 0.004855\n",
            "Train Epoch: 5 [6720/35339 (19%)]\tLoss: 0.008268\n",
            "Train Epoch: 5 [7040/35339 (20%)]\tLoss: 0.001062\n",
            "Train Epoch: 5 [7360/35339 (21%)]\tLoss: 0.000055\n",
            "Train Epoch: 5 [7680/35339 (22%)]\tLoss: 0.020315\n",
            "Train Epoch: 5 [8000/35339 (23%)]\tLoss: 0.005125\n",
            "Train Epoch: 5 [8320/35339 (24%)]\tLoss: 0.000318\n",
            "Train Epoch: 5 [8640/35339 (24%)]\tLoss: 0.000159\n",
            "Train Epoch: 5 [8960/35339 (25%)]\tLoss: 0.000477\n",
            "Train Epoch: 5 [9280/35339 (26%)]\tLoss: 0.009603\n",
            "Train Epoch: 5 [9600/35339 (27%)]\tLoss: 0.005092\n",
            "Train Epoch: 5 [9920/35339 (28%)]\tLoss: 0.061037\n",
            "Train Epoch: 5 [10240/35339 (29%)]\tLoss: 0.001142\n",
            "Train Epoch: 5 [10560/35339 (30%)]\tLoss: 0.000070\n",
            "Train Epoch: 5 [10880/35339 (31%)]\tLoss: 0.001781\n",
            "Train Epoch: 5 [11200/35339 (32%)]\tLoss: 0.010939\n",
            "Train Epoch: 5 [11520/35339 (33%)]\tLoss: 0.004491\n",
            "Train Epoch: 5 [11840/35339 (33%)]\tLoss: 0.000005\n",
            "Train Epoch: 5 [12160/35339 (34%)]\tLoss: 0.018470\n",
            "Train Epoch: 5 [12480/35339 (35%)]\tLoss: 0.147856\n",
            "Train Epoch: 5 [12800/35339 (36%)]\tLoss: 0.000067\n",
            "Train Epoch: 5 [13120/35339 (37%)]\tLoss: 0.000199\n",
            "Train Epoch: 5 [13440/35339 (38%)]\tLoss: 0.022391\n",
            "Train Epoch: 5 [13760/35339 (39%)]\tLoss: 0.109556\n",
            "Train Epoch: 5 [14080/35339 (40%)]\tLoss: 0.000078\n",
            "Train Epoch: 5 [14400/35339 (41%)]\tLoss: 0.004321\n",
            "Train Epoch: 5 [14720/35339 (42%)]\tLoss: 0.065336\n",
            "Train Epoch: 5 [15040/35339 (43%)]\tLoss: 0.020240\n",
            "Train Epoch: 5 [15360/35339 (43%)]\tLoss: 0.062551\n",
            "Train Epoch: 5 [15680/35339 (44%)]\tLoss: 0.000929\n",
            "Train Epoch: 5 [16000/35339 (45%)]\tLoss: 0.012112\n",
            "Train Epoch: 5 [16320/35339 (46%)]\tLoss: 0.150758\n",
            "Train Epoch: 5 [16640/35339 (47%)]\tLoss: 0.000344\n",
            "Train Epoch: 5 [16960/35339 (48%)]\tLoss: 0.037116\n",
            "Train Epoch: 5 [17280/35339 (49%)]\tLoss: 0.005003\n",
            "Train Epoch: 5 [17600/35339 (50%)]\tLoss: 0.013290\n",
            "Train Epoch: 5 [17920/35339 (51%)]\tLoss: 0.005820\n",
            "Train Epoch: 5 [18240/35339 (52%)]\tLoss: 0.001625\n",
            "Train Epoch: 5 [18560/35339 (52%)]\tLoss: 0.011386\n",
            "Train Epoch: 5 [18880/35339 (53%)]\tLoss: 0.033661\n",
            "Train Epoch: 5 [19200/35339 (54%)]\tLoss: 0.109483\n",
            "Train Epoch: 5 [19520/35339 (55%)]\tLoss: 0.023158\n",
            "Train Epoch: 5 [19840/35339 (56%)]\tLoss: 0.123316\n",
            "Train Epoch: 5 [20160/35339 (57%)]\tLoss: 0.000732\n",
            "Train Epoch: 5 [20480/35339 (58%)]\tLoss: 0.000109\n",
            "Train Epoch: 5 [20800/35339 (59%)]\tLoss: 0.001500\n",
            "Train Epoch: 5 [21120/35339 (60%)]\tLoss: 0.027398\n",
            "Train Epoch: 5 [21440/35339 (61%)]\tLoss: 0.000465\n",
            "Train Epoch: 5 [21760/35339 (62%)]\tLoss: 0.001539\n",
            "Train Epoch: 5 [22080/35339 (62%)]\tLoss: 0.009352\n",
            "Train Epoch: 5 [22400/35339 (63%)]\tLoss: 0.022570\n",
            "Train Epoch: 5 [22720/35339 (64%)]\tLoss: 0.001077\n",
            "Train Epoch: 5 [23040/35339 (65%)]\tLoss: 0.116360\n",
            "Train Epoch: 5 [23360/35339 (66%)]\tLoss: 0.001278\n",
            "Train Epoch: 5 [23680/35339 (67%)]\tLoss: 0.024959\n",
            "Train Epoch: 5 [24000/35339 (68%)]\tLoss: 0.000246\n",
            "Train Epoch: 5 [24320/35339 (69%)]\tLoss: 0.000076\n",
            "Train Epoch: 5 [24640/35339 (70%)]\tLoss: 0.047999\n",
            "Train Epoch: 5 [24960/35339 (71%)]\tLoss: 0.004866\n",
            "Train Epoch: 5 [25280/35339 (71%)]\tLoss: 0.096547\n",
            "Train Epoch: 5 [25600/35339 (72%)]\tLoss: 0.001422\n",
            "Train Epoch: 5 [25920/35339 (73%)]\tLoss: 0.070663\n",
            "Train Epoch: 5 [26240/35339 (74%)]\tLoss: 0.312953\n",
            "Train Epoch: 5 [26560/35339 (75%)]\tLoss: 0.052315\n",
            "Train Epoch: 5 [26880/35339 (76%)]\tLoss: 0.007902\n",
            "Train Epoch: 5 [27200/35339 (77%)]\tLoss: 0.113037\n",
            "Train Epoch: 5 [27520/35339 (78%)]\tLoss: 0.499571\n",
            "Train Epoch: 5 [27840/35339 (79%)]\tLoss: 0.089144\n",
            "Train Epoch: 5 [28160/35339 (80%)]\tLoss: 0.005882\n",
            "Train Epoch: 5 [28480/35339 (81%)]\tLoss: 0.021106\n",
            "Train Epoch: 5 [28800/35339 (81%)]\tLoss: 0.028277\n",
            "Train Epoch: 5 [29120/35339 (82%)]\tLoss: 0.002961\n",
            "Train Epoch: 5 [29440/35339 (83%)]\tLoss: 0.111688\n",
            "Train Epoch: 5 [29760/35339 (84%)]\tLoss: 0.014287\n",
            "Train Epoch: 5 [30080/35339 (85%)]\tLoss: 0.000178\n",
            "Train Epoch: 5 [30400/35339 (86%)]\tLoss: 0.110835\n",
            "Train Epoch: 5 [30720/35339 (87%)]\tLoss: 0.001417\n",
            "Train Epoch: 5 [31040/35339 (88%)]\tLoss: 0.027793\n",
            "Train Epoch: 5 [31360/35339 (89%)]\tLoss: 0.000159\n",
            "Train Epoch: 5 [31680/35339 (90%)]\tLoss: 0.007410\n",
            "Train Epoch: 5 [32000/35339 (90%)]\tLoss: 0.072915\n",
            "Train Epoch: 5 [32320/35339 (91%)]\tLoss: 0.000008\n",
            "Train Epoch: 5 [32640/35339 (92%)]\tLoss: 0.024550\n",
            "Train Epoch: 5 [32960/35339 (93%)]\tLoss: 0.003884\n",
            "Train Epoch: 5 [33280/35339 (94%)]\tLoss: 0.156264\n",
            "Train Epoch: 5 [33600/35339 (95%)]\tLoss: 0.067206\n",
            "Train Epoch: 5 [33920/35339 (96%)]\tLoss: 0.000836\n",
            "Train Epoch: 5 [34240/35339 (97%)]\tLoss: 0.286240\n",
            "Train Epoch: 5 [34560/35339 (98%)]\tLoss: 0.000723\n",
            "Train Epoch: 5 [34880/35339 (99%)]\tLoss: 0.002210\n",
            "Train Epoch: 5 [35200/35339 (100%)]\tLoss: 0.020880\n",
            "\n",
            "Validation set: Average loss: 0.1413, Accuracy: 3748/3870 (97%)\n",
            "\n",
            "\n",
            "Saved model to model_5.pth.\n",
            "Train Epoch: 6 [0/35339 (0%)]\tLoss: 0.001299\n",
            "Train Epoch: 6 [320/35339 (1%)]\tLoss: 0.000206\n",
            "Train Epoch: 6 [640/35339 (2%)]\tLoss: 0.029085\n",
            "Train Epoch: 6 [960/35339 (3%)]\tLoss: 0.000141\n",
            "Train Epoch: 6 [1280/35339 (4%)]\tLoss: 0.002549\n",
            "Train Epoch: 6 [1600/35339 (5%)]\tLoss: 0.029819\n",
            "Train Epoch: 6 [1920/35339 (5%)]\tLoss: 0.000000\n",
            "Train Epoch: 6 [2240/35339 (6%)]\tLoss: 0.002242\n",
            "Train Epoch: 6 [2560/35339 (7%)]\tLoss: 0.096634\n",
            "Train Epoch: 6 [2880/35339 (8%)]\tLoss: 0.001396\n",
            "Train Epoch: 6 [3200/35339 (9%)]\tLoss: 0.003837\n",
            "Train Epoch: 6 [3520/35339 (10%)]\tLoss: 0.022748\n",
            "Train Epoch: 6 [3840/35339 (11%)]\tLoss: 0.000124\n",
            "Train Epoch: 6 [4160/35339 (12%)]\tLoss: 0.012883\n",
            "Train Epoch: 6 [4480/35339 (13%)]\tLoss: 0.021761\n",
            "Train Epoch: 6 [4800/35339 (14%)]\tLoss: 0.010571\n",
            "Train Epoch: 6 [5120/35339 (14%)]\tLoss: 0.008657\n",
            "Train Epoch: 6 [5440/35339 (15%)]\tLoss: 0.025095\n",
            "Train Epoch: 6 [5760/35339 (16%)]\tLoss: 0.001383\n",
            "Train Epoch: 6 [6080/35339 (17%)]\tLoss: 0.002636\n",
            "Train Epoch: 6 [6400/35339 (18%)]\tLoss: 0.003357\n",
            "Train Epoch: 6 [6720/35339 (19%)]\tLoss: 0.000729\n",
            "Train Epoch: 6 [7040/35339 (20%)]\tLoss: 0.000620\n",
            "Train Epoch: 6 [7360/35339 (21%)]\tLoss: 0.005482\n",
            "Train Epoch: 6 [7680/35339 (22%)]\tLoss: 0.061019\n",
            "Train Epoch: 6 [8000/35339 (23%)]\tLoss: 0.000236\n",
            "Train Epoch: 6 [8320/35339 (24%)]\tLoss: 0.001956\n",
            "Train Epoch: 6 [8640/35339 (24%)]\tLoss: 0.000752\n",
            "Train Epoch: 6 [8960/35339 (25%)]\tLoss: 0.000024\n",
            "Train Epoch: 6 [9280/35339 (26%)]\tLoss: 0.000096\n",
            "Train Epoch: 6 [9600/35339 (27%)]\tLoss: 0.001353\n",
            "Train Epoch: 6 [9920/35339 (28%)]\tLoss: 0.000123\n",
            "Train Epoch: 6 [10240/35339 (29%)]\tLoss: 0.000228\n",
            "Train Epoch: 6 [10560/35339 (30%)]\tLoss: 0.000113\n",
            "Train Epoch: 6 [10880/35339 (31%)]\tLoss: 0.000176\n",
            "Train Epoch: 6 [11200/35339 (32%)]\tLoss: 0.000088\n",
            "Train Epoch: 6 [11520/35339 (33%)]\tLoss: 0.169375\n",
            "Train Epoch: 6 [11840/35339 (33%)]\tLoss: 0.000824\n",
            "Train Epoch: 6 [12160/35339 (34%)]\tLoss: 0.004715\n",
            "Train Epoch: 6 [12480/35339 (35%)]\tLoss: 0.084841\n",
            "Train Epoch: 6 [12800/35339 (36%)]\tLoss: 0.068917\n",
            "Train Epoch: 6 [13120/35339 (37%)]\tLoss: 0.006167\n",
            "Train Epoch: 6 [13440/35339 (38%)]\tLoss: 0.001218\n",
            "Train Epoch: 6 [13760/35339 (39%)]\tLoss: 0.035015\n",
            "Train Epoch: 6 [14080/35339 (40%)]\tLoss: 0.000492\n",
            "Train Epoch: 6 [14400/35339 (41%)]\tLoss: 0.002584\n",
            "Train Epoch: 6 [14720/35339 (42%)]\tLoss: 0.000115\n",
            "Train Epoch: 6 [15040/35339 (43%)]\tLoss: 0.065105\n",
            "Train Epoch: 6 [15360/35339 (43%)]\tLoss: 0.000028\n",
            "Train Epoch: 6 [15680/35339 (44%)]\tLoss: 0.048527\n",
            "Train Epoch: 6 [16000/35339 (45%)]\tLoss: 0.000368\n",
            "Train Epoch: 6 [16320/35339 (46%)]\tLoss: 0.000209\n",
            "Train Epoch: 6 [16640/35339 (47%)]\tLoss: 0.020854\n",
            "Train Epoch: 6 [16960/35339 (48%)]\tLoss: 0.000051\n",
            "Train Epoch: 6 [17280/35339 (49%)]\tLoss: 0.004381\n",
            "Train Epoch: 6 [17600/35339 (50%)]\tLoss: 0.000025\n",
            "Train Epoch: 6 [17920/35339 (51%)]\tLoss: 0.008698\n",
            "Train Epoch: 6 [18240/35339 (52%)]\tLoss: 0.030016\n",
            "Train Epoch: 6 [18560/35339 (52%)]\tLoss: 0.035212\n",
            "Train Epoch: 6 [18880/35339 (53%)]\tLoss: 0.009938\n",
            "Train Epoch: 6 [19200/35339 (54%)]\tLoss: 0.004425\n",
            "Train Epoch: 6 [19520/35339 (55%)]\tLoss: 0.000023\n",
            "Train Epoch: 6 [19840/35339 (56%)]\tLoss: 0.014172\n",
            "Train Epoch: 6 [20160/35339 (57%)]\tLoss: 0.004265\n",
            "Train Epoch: 6 [20480/35339 (58%)]\tLoss: 0.019889\n",
            "Train Epoch: 6 [20800/35339 (59%)]\tLoss: 0.001797\n",
            "Train Epoch: 6 [21120/35339 (60%)]\tLoss: 0.000848\n",
            "Train Epoch: 6 [21440/35339 (61%)]\tLoss: 0.002990\n",
            "Train Epoch: 6 [21760/35339 (62%)]\tLoss: 0.006736\n",
            "Train Epoch: 6 [22080/35339 (62%)]\tLoss: 0.009385\n",
            "Train Epoch: 6 [22400/35339 (63%)]\tLoss: 0.129586\n",
            "Train Epoch: 6 [22720/35339 (64%)]\tLoss: 0.000003\n",
            "Train Epoch: 6 [23040/35339 (65%)]\tLoss: 0.087257\n",
            "Train Epoch: 6 [23360/35339 (66%)]\tLoss: 0.164495\n",
            "Train Epoch: 6 [23680/35339 (67%)]\tLoss: 0.007203\n",
            "Train Epoch: 6 [24000/35339 (68%)]\tLoss: 0.273046\n",
            "Train Epoch: 6 [24320/35339 (69%)]\tLoss: 0.000712\n",
            "Train Epoch: 6 [24640/35339 (70%)]\tLoss: 0.003660\n",
            "Train Epoch: 6 [24960/35339 (71%)]\tLoss: 0.000131\n",
            "Train Epoch: 6 [25280/35339 (71%)]\tLoss: 0.000035\n",
            "Train Epoch: 6 [25600/35339 (72%)]\tLoss: 0.000005\n",
            "Train Epoch: 6 [25920/35339 (73%)]\tLoss: 0.004450\n",
            "Train Epoch: 6 [26240/35339 (74%)]\tLoss: 0.000009\n",
            "Train Epoch: 6 [26560/35339 (75%)]\tLoss: 0.000208\n",
            "Train Epoch: 6 [26880/35339 (76%)]\tLoss: 0.004440\n",
            "Train Epoch: 6 [27200/35339 (77%)]\tLoss: 0.022913\n",
            "Train Epoch: 6 [27520/35339 (78%)]\tLoss: 0.199221\n",
            "Train Epoch: 6 [27840/35339 (79%)]\tLoss: 0.005563\n",
            "Train Epoch: 6 [28160/35339 (80%)]\tLoss: 0.003093\n",
            "Train Epoch: 6 [28480/35339 (81%)]\tLoss: 0.069637\n",
            "Train Epoch: 6 [28800/35339 (81%)]\tLoss: 0.000003\n",
            "Train Epoch: 6 [29120/35339 (82%)]\tLoss: 0.022064\n",
            "Train Epoch: 6 [29440/35339 (83%)]\tLoss: 0.014533\n",
            "Train Epoch: 6 [29760/35339 (84%)]\tLoss: 0.038817\n",
            "Train Epoch: 6 [30080/35339 (85%)]\tLoss: 0.000882\n",
            "Train Epoch: 6 [30400/35339 (86%)]\tLoss: 0.027374\n",
            "Train Epoch: 6 [30720/35339 (87%)]\tLoss: 0.016002\n",
            "Train Epoch: 6 [31040/35339 (88%)]\tLoss: 0.210315\n",
            "Train Epoch: 6 [31360/35339 (89%)]\tLoss: 0.000251\n",
            "Train Epoch: 6 [31680/35339 (90%)]\tLoss: 0.000050\n",
            "Train Epoch: 6 [32000/35339 (90%)]\tLoss: 0.007038\n",
            "Train Epoch: 6 [32320/35339 (91%)]\tLoss: 0.000176\n",
            "Train Epoch: 6 [32640/35339 (92%)]\tLoss: 0.245728\n",
            "Train Epoch: 6 [32960/35339 (93%)]\tLoss: 0.001286\n",
            "Train Epoch: 6 [33280/35339 (94%)]\tLoss: 0.000075\n",
            "Train Epoch: 6 [33600/35339 (95%)]\tLoss: 0.002159\n",
            "Train Epoch: 6 [33920/35339 (96%)]\tLoss: 0.000002\n",
            "Train Epoch: 6 [34240/35339 (97%)]\tLoss: 0.043871\n",
            "Train Epoch: 6 [34560/35339 (98%)]\tLoss: 0.000198\n",
            "Train Epoch: 6 [34880/35339 (99%)]\tLoss: 0.002013\n",
            "Train Epoch: 6 [35200/35339 (100%)]\tLoss: 0.002079\n",
            "\n",
            "Validation set: Average loss: 0.1683, Accuracy: 3736/3870 (97%)\n",
            "\n",
            "\n",
            "Saved model to model_6.pth.\n",
            "Train Epoch: 7 [0/35339 (0%)]\tLoss: 0.002328\n",
            "Train Epoch: 7 [320/35339 (1%)]\tLoss: 0.006923\n",
            "Train Epoch: 7 [640/35339 (2%)]\tLoss: 0.034257\n",
            "Train Epoch: 7 [960/35339 (3%)]\tLoss: 0.000079\n",
            "Train Epoch: 7 [1280/35339 (4%)]\tLoss: 0.000017\n",
            "Train Epoch: 7 [1600/35339 (5%)]\tLoss: 0.112898\n",
            "Train Epoch: 7 [1920/35339 (5%)]\tLoss: 0.001494\n",
            "Train Epoch: 7 [2240/35339 (6%)]\tLoss: 0.041425\n",
            "Train Epoch: 7 [2560/35339 (7%)]\tLoss: 0.000033\n",
            "Train Epoch: 7 [2880/35339 (8%)]\tLoss: 0.000011\n",
            "Train Epoch: 7 [3200/35339 (9%)]\tLoss: 0.001491\n",
            "Train Epoch: 7 [3520/35339 (10%)]\tLoss: 0.000022\n",
            "Train Epoch: 7 [3840/35339 (11%)]\tLoss: 0.003849\n",
            "Train Epoch: 7 [4160/35339 (12%)]\tLoss: 0.030326\n",
            "Train Epoch: 7 [4480/35339 (13%)]\tLoss: 0.085180\n",
            "Train Epoch: 7 [4800/35339 (14%)]\tLoss: 0.096078\n",
            "Train Epoch: 7 [5120/35339 (14%)]\tLoss: 0.126468\n",
            "Train Epoch: 7 [5440/35339 (15%)]\tLoss: 0.000327\n",
            "Train Epoch: 7 [5760/35339 (16%)]\tLoss: 0.000203\n",
            "Train Epoch: 7 [6080/35339 (17%)]\tLoss: 0.036204\n",
            "Train Epoch: 7 [6400/35339 (18%)]\tLoss: 0.001479\n",
            "Train Epoch: 7 [6720/35339 (19%)]\tLoss: 0.114287\n",
            "Train Epoch: 7 [7040/35339 (20%)]\tLoss: 0.011327\n",
            "Train Epoch: 7 [7360/35339 (21%)]\tLoss: 0.000186\n",
            "Train Epoch: 7 [7680/35339 (22%)]\tLoss: 0.015246\n",
            "Train Epoch: 7 [8000/35339 (23%)]\tLoss: 0.017714\n",
            "Train Epoch: 7 [8320/35339 (24%)]\tLoss: 0.027224\n",
            "Train Epoch: 7 [8640/35339 (24%)]\tLoss: 0.045536\n",
            "Train Epoch: 7 [8960/35339 (25%)]\tLoss: 0.003251\n",
            "Train Epoch: 7 [9280/35339 (26%)]\tLoss: 0.173647\n",
            "Train Epoch: 7 [9600/35339 (27%)]\tLoss: 0.258780\n",
            "Train Epoch: 7 [9920/35339 (28%)]\tLoss: 0.021427\n",
            "Train Epoch: 7 [10240/35339 (29%)]\tLoss: 0.001249\n",
            "Train Epoch: 7 [10560/35339 (30%)]\tLoss: 0.018239\n",
            "Train Epoch: 7 [10880/35339 (31%)]\tLoss: 0.003671\n",
            "Train Epoch: 7 [11200/35339 (32%)]\tLoss: 0.000031\n",
            "Train Epoch: 7 [11520/35339 (33%)]\tLoss: 0.006883\n",
            "Train Epoch: 7 [11840/35339 (33%)]\tLoss: 0.038622\n",
            "Train Epoch: 7 [12160/35339 (34%)]\tLoss: 0.000003\n",
            "Train Epoch: 7 [12480/35339 (35%)]\tLoss: 0.063854\n",
            "Train Epoch: 7 [12800/35339 (36%)]\tLoss: 0.051196\n",
            "Train Epoch: 7 [13120/35339 (37%)]\tLoss: 0.015186\n",
            "Train Epoch: 7 [13440/35339 (38%)]\tLoss: 0.134993\n",
            "Train Epoch: 7 [13760/35339 (39%)]\tLoss: 0.000287\n",
            "Train Epoch: 7 [14080/35339 (40%)]\tLoss: 0.204852\n",
            "Train Epoch: 7 [14400/35339 (41%)]\tLoss: 0.000844\n",
            "Train Epoch: 7 [14720/35339 (42%)]\tLoss: 0.001659\n",
            "Train Epoch: 7 [15040/35339 (43%)]\tLoss: 0.000170\n",
            "Train Epoch: 7 [15360/35339 (43%)]\tLoss: 0.644864\n",
            "Train Epoch: 7 [15680/35339 (44%)]\tLoss: 0.001161\n",
            "Train Epoch: 7 [16000/35339 (45%)]\tLoss: 0.004109\n",
            "Train Epoch: 7 [16320/35339 (46%)]\tLoss: 0.005983\n",
            "Train Epoch: 7 [16640/35339 (47%)]\tLoss: 0.003134\n",
            "Train Epoch: 7 [16960/35339 (48%)]\tLoss: 0.003881\n",
            "Train Epoch: 7 [17280/35339 (49%)]\tLoss: 0.002784\n",
            "Train Epoch: 7 [17600/35339 (50%)]\tLoss: 0.000050\n",
            "Train Epoch: 7 [17920/35339 (51%)]\tLoss: 0.017226\n",
            "Train Epoch: 7 [18240/35339 (52%)]\tLoss: 0.000134\n",
            "Train Epoch: 7 [18560/35339 (52%)]\tLoss: 0.010674\n",
            "Train Epoch: 7 [18880/35339 (53%)]\tLoss: 0.000032\n",
            "Train Epoch: 7 [19200/35339 (54%)]\tLoss: 0.000621\n",
            "Train Epoch: 7 [19520/35339 (55%)]\tLoss: 0.000124\n",
            "Train Epoch: 7 [19840/35339 (56%)]\tLoss: 0.004326\n",
            "Train Epoch: 7 [20160/35339 (57%)]\tLoss: 0.000180\n",
            "Train Epoch: 7 [20480/35339 (58%)]\tLoss: 0.000352\n",
            "Train Epoch: 7 [20800/35339 (59%)]\tLoss: 0.002284\n",
            "Train Epoch: 7 [21120/35339 (60%)]\tLoss: 0.000130\n",
            "Train Epoch: 7 [21440/35339 (61%)]\tLoss: 0.006246\n",
            "Train Epoch: 7 [21760/35339 (62%)]\tLoss: 0.030628\n",
            "Train Epoch: 7 [22080/35339 (62%)]\tLoss: 0.218200\n",
            "Train Epoch: 7 [22400/35339 (63%)]\tLoss: 0.001643\n",
            "Train Epoch: 7 [22720/35339 (64%)]\tLoss: 0.000482\n",
            "Train Epoch: 7 [23040/35339 (65%)]\tLoss: 0.001583\n",
            "Train Epoch: 7 [23360/35339 (66%)]\tLoss: 0.000332\n",
            "Train Epoch: 7 [23680/35339 (67%)]\tLoss: 0.000011\n",
            "Train Epoch: 7 [24000/35339 (68%)]\tLoss: 0.001294\n",
            "Train Epoch: 7 [24320/35339 (69%)]\tLoss: 0.000001\n",
            "Train Epoch: 7 [24640/35339 (70%)]\tLoss: 0.056443\n",
            "Train Epoch: 7 [24960/35339 (71%)]\tLoss: 0.000351\n",
            "Train Epoch: 7 [25280/35339 (71%)]\tLoss: 0.019156\n",
            "Train Epoch: 7 [25600/35339 (72%)]\tLoss: 0.001226\n",
            "Train Epoch: 7 [25920/35339 (73%)]\tLoss: 0.000007\n",
            "Train Epoch: 7 [26240/35339 (74%)]\tLoss: 0.000001\n",
            "Train Epoch: 7 [26560/35339 (75%)]\tLoss: 0.007812\n",
            "Train Epoch: 7 [26880/35339 (76%)]\tLoss: 0.000085\n",
            "Train Epoch: 7 [27200/35339 (77%)]\tLoss: 0.000049\n",
            "Train Epoch: 7 [27520/35339 (78%)]\tLoss: 0.004321\n",
            "Train Epoch: 7 [27840/35339 (79%)]\tLoss: 0.252699\n",
            "Train Epoch: 7 [28160/35339 (80%)]\tLoss: 0.031618\n",
            "Train Epoch: 7 [28480/35339 (81%)]\tLoss: 0.000368\n",
            "Train Epoch: 7 [28800/35339 (81%)]\tLoss: 0.013654\n",
            "Train Epoch: 7 [29120/35339 (82%)]\tLoss: 0.000567\n",
            "Train Epoch: 7 [29440/35339 (83%)]\tLoss: 0.001100\n",
            "Train Epoch: 7 [29760/35339 (84%)]\tLoss: 0.171286\n",
            "Train Epoch: 7 [30080/35339 (85%)]\tLoss: 0.004248\n",
            "Train Epoch: 7 [30400/35339 (86%)]\tLoss: 0.001676\n",
            "Train Epoch: 7 [30720/35339 (87%)]\tLoss: 0.005304\n",
            "Train Epoch: 7 [31040/35339 (88%)]\tLoss: 0.422397\n",
            "Train Epoch: 7 [31360/35339 (89%)]\tLoss: 0.017415\n",
            "Train Epoch: 7 [31680/35339 (90%)]\tLoss: 0.017545\n",
            "Train Epoch: 7 [32000/35339 (90%)]\tLoss: 0.000031\n",
            "Train Epoch: 7 [32320/35339 (91%)]\tLoss: 0.000007\n",
            "Train Epoch: 7 [32640/35339 (92%)]\tLoss: 0.105373\n",
            "Train Epoch: 7 [32960/35339 (93%)]\tLoss: 0.000002\n",
            "Train Epoch: 7 [33280/35339 (94%)]\tLoss: 0.070325\n",
            "Train Epoch: 7 [33600/35339 (95%)]\tLoss: 0.002528\n",
            "Train Epoch: 7 [33920/35339 (96%)]\tLoss: 0.000002\n",
            "Train Epoch: 7 [34240/35339 (97%)]\tLoss: 0.037861\n",
            "Train Epoch: 7 [34560/35339 (98%)]\tLoss: 0.121470\n",
            "Train Epoch: 7 [34880/35339 (99%)]\tLoss: 0.004506\n",
            "Train Epoch: 7 [35200/35339 (100%)]\tLoss: 0.076201\n",
            "\n",
            "Validation set: Average loss: 0.2206, Accuracy: 3701/3870 (96%)\n",
            "\n",
            "\n",
            "Saved model to model_7.pth.\n",
            "Train Epoch: 8 [0/35339 (0%)]\tLoss: 0.018433\n",
            "Train Epoch: 8 [320/35339 (1%)]\tLoss: 0.200999\n",
            "Train Epoch: 8 [640/35339 (2%)]\tLoss: 0.000097\n",
            "Train Epoch: 8 [960/35339 (3%)]\tLoss: 0.306154\n",
            "Train Epoch: 8 [1280/35339 (4%)]\tLoss: 0.027063\n",
            "Train Epoch: 8 [1600/35339 (5%)]\tLoss: 0.000022\n",
            "Train Epoch: 8 [1920/35339 (5%)]\tLoss: 0.000012\n",
            "Train Epoch: 8 [2240/35339 (6%)]\tLoss: 0.033891\n",
            "Train Epoch: 8 [2560/35339 (7%)]\tLoss: 0.008532\n",
            "Train Epoch: 8 [2880/35339 (8%)]\tLoss: 0.025767\n",
            "Train Epoch: 8 [3200/35339 (9%)]\tLoss: 0.000203\n",
            "Train Epoch: 8 [3520/35339 (10%)]\tLoss: 0.007162\n",
            "Train Epoch: 8 [3840/35339 (11%)]\tLoss: 0.000240\n",
            "Train Epoch: 8 [4160/35339 (12%)]\tLoss: 0.000028\n",
            "Train Epoch: 8 [4480/35339 (13%)]\tLoss: 0.015076\n",
            "Train Epoch: 8 [4800/35339 (14%)]\tLoss: 0.000021\n",
            "Train Epoch: 8 [5120/35339 (14%)]\tLoss: 0.023141\n",
            "Train Epoch: 8 [5440/35339 (15%)]\tLoss: 0.000123\n",
            "Train Epoch: 8 [5760/35339 (16%)]\tLoss: 0.006352\n",
            "Train Epoch: 8 [6080/35339 (17%)]\tLoss: 0.012271\n",
            "Train Epoch: 8 [6400/35339 (18%)]\tLoss: 0.005988\n",
            "Train Epoch: 8 [6720/35339 (19%)]\tLoss: 0.002132\n",
            "Train Epoch: 8 [7040/35339 (20%)]\tLoss: 0.000208\n",
            "Train Epoch: 8 [7360/35339 (21%)]\tLoss: 0.000010\n",
            "Train Epoch: 8 [7680/35339 (22%)]\tLoss: 0.049318\n",
            "Train Epoch: 8 [8000/35339 (23%)]\tLoss: 0.000035\n",
            "Train Epoch: 8 [8320/35339 (24%)]\tLoss: 0.000003\n",
            "Train Epoch: 8 [8640/35339 (24%)]\tLoss: 0.111249\n",
            "Train Epoch: 8 [8960/35339 (25%)]\tLoss: 0.035102\n",
            "Train Epoch: 8 [9280/35339 (26%)]\tLoss: 0.000187\n",
            "Train Epoch: 8 [9600/35339 (27%)]\tLoss: 0.172012\n",
            "Train Epoch: 8 [9920/35339 (28%)]\tLoss: 0.002551\n",
            "Train Epoch: 8 [10240/35339 (29%)]\tLoss: 0.000857\n",
            "Train Epoch: 8 [10560/35339 (30%)]\tLoss: 0.008713\n",
            "Train Epoch: 8 [10880/35339 (31%)]\tLoss: 0.000006\n",
            "Train Epoch: 8 [11200/35339 (32%)]\tLoss: 0.005450\n",
            "Train Epoch: 8 [11520/35339 (33%)]\tLoss: 0.000013\n",
            "Train Epoch: 8 [11840/35339 (33%)]\tLoss: 0.032272\n",
            "Train Epoch: 8 [12160/35339 (34%)]\tLoss: 0.239106\n",
            "Train Epoch: 8 [12480/35339 (35%)]\tLoss: 0.003979\n",
            "Train Epoch: 8 [12800/35339 (36%)]\tLoss: 0.000431\n",
            "Train Epoch: 8 [13120/35339 (37%)]\tLoss: 0.000302\n",
            "Train Epoch: 8 [13440/35339 (38%)]\tLoss: 0.000649\n",
            "Train Epoch: 8 [13760/35339 (39%)]\tLoss: 0.112133\n",
            "Train Epoch: 8 [14080/35339 (40%)]\tLoss: 0.001920\n",
            "Train Epoch: 8 [14400/35339 (41%)]\tLoss: 0.000006\n",
            "Train Epoch: 8 [14720/35339 (42%)]\tLoss: 0.000206\n",
            "Train Epoch: 8 [15040/35339 (43%)]\tLoss: 0.358460\n",
            "Train Epoch: 8 [15360/35339 (43%)]\tLoss: 0.165731\n",
            "Train Epoch: 8 [15680/35339 (44%)]\tLoss: 0.036006\n",
            "Train Epoch: 8 [16000/35339 (45%)]\tLoss: 0.000035\n",
            "Train Epoch: 8 [16320/35339 (46%)]\tLoss: 0.002793\n",
            "Train Epoch: 8 [16640/35339 (47%)]\tLoss: 0.011308\n",
            "Train Epoch: 8 [16960/35339 (48%)]\tLoss: 0.000254\n",
            "Train Epoch: 8 [17280/35339 (49%)]\tLoss: 0.174422\n",
            "Train Epoch: 8 [17600/35339 (50%)]\tLoss: 0.079286\n",
            "Train Epoch: 8 [17920/35339 (51%)]\tLoss: 0.001069\n",
            "Train Epoch: 8 [18240/35339 (52%)]\tLoss: 0.006860\n",
            "Train Epoch: 8 [18560/35339 (52%)]\tLoss: 0.000000\n",
            "Train Epoch: 8 [18880/35339 (53%)]\tLoss: 0.000057\n",
            "Train Epoch: 8 [19200/35339 (54%)]\tLoss: 0.000046\n",
            "Train Epoch: 8 [19520/35339 (55%)]\tLoss: 0.002612\n",
            "Train Epoch: 8 [19840/35339 (56%)]\tLoss: 0.000317\n",
            "Train Epoch: 8 [20160/35339 (57%)]\tLoss: 0.041792\n",
            "Train Epoch: 8 [20480/35339 (58%)]\tLoss: 0.000165\n",
            "Train Epoch: 8 [20800/35339 (59%)]\tLoss: 0.000539\n",
            "Train Epoch: 8 [21120/35339 (60%)]\tLoss: 0.000040\n",
            "Train Epoch: 8 [21440/35339 (61%)]\tLoss: 0.001037\n",
            "Train Epoch: 8 [21760/35339 (62%)]\tLoss: 0.000338\n",
            "Train Epoch: 8 [22080/35339 (62%)]\tLoss: 0.000001\n",
            "Train Epoch: 8 [22400/35339 (63%)]\tLoss: 0.035453\n",
            "Train Epoch: 8 [22720/35339 (64%)]\tLoss: 0.002325\n",
            "Train Epoch: 8 [23040/35339 (65%)]\tLoss: 0.000025\n",
            "Train Epoch: 8 [23360/35339 (66%)]\tLoss: 0.000125\n",
            "Train Epoch: 8 [23680/35339 (67%)]\tLoss: 0.000017\n",
            "Train Epoch: 8 [24000/35339 (68%)]\tLoss: 0.001666\n",
            "Train Epoch: 8 [24320/35339 (69%)]\tLoss: 0.040740\n",
            "Train Epoch: 8 [24640/35339 (70%)]\tLoss: 0.121523\n",
            "Train Epoch: 8 [24960/35339 (71%)]\tLoss: 0.002454\n",
            "Train Epoch: 8 [25280/35339 (71%)]\tLoss: 0.086474\n",
            "Train Epoch: 8 [25600/35339 (72%)]\tLoss: 0.000019\n",
            "Train Epoch: 8 [25920/35339 (73%)]\tLoss: 0.050532\n",
            "Train Epoch: 8 [26240/35339 (74%)]\tLoss: 0.002995\n",
            "Train Epoch: 8 [26560/35339 (75%)]\tLoss: 0.003972\n",
            "Train Epoch: 8 [26880/35339 (76%)]\tLoss: 0.000405\n",
            "Train Epoch: 8 [27200/35339 (77%)]\tLoss: 0.004446\n",
            "Train Epoch: 8 [27520/35339 (78%)]\tLoss: 0.000456\n",
            "Train Epoch: 8 [27840/35339 (79%)]\tLoss: 0.000016\n",
            "Train Epoch: 8 [28160/35339 (80%)]\tLoss: 0.000567\n",
            "Train Epoch: 8 [28480/35339 (81%)]\tLoss: 0.292160\n",
            "Train Epoch: 8 [28800/35339 (81%)]\tLoss: 0.008894\n",
            "Train Epoch: 8 [29120/35339 (82%)]\tLoss: 0.014130\n",
            "Train Epoch: 8 [29440/35339 (83%)]\tLoss: 0.000523\n",
            "Train Epoch: 8 [29760/35339 (84%)]\tLoss: 0.000320\n",
            "Train Epoch: 8 [30080/35339 (85%)]\tLoss: 0.108498\n",
            "Train Epoch: 8 [30400/35339 (86%)]\tLoss: 0.014782\n",
            "Train Epoch: 8 [30720/35339 (87%)]\tLoss: 0.000151\n",
            "Train Epoch: 8 [31040/35339 (88%)]\tLoss: 0.000552\n",
            "Train Epoch: 8 [31360/35339 (89%)]\tLoss: 0.004603\n",
            "Train Epoch: 8 [31680/35339 (90%)]\tLoss: 0.000001\n",
            "Train Epoch: 8 [32000/35339 (90%)]\tLoss: 0.001159\n",
            "Train Epoch: 8 [32320/35339 (91%)]\tLoss: 0.000250\n",
            "Train Epoch: 8 [32640/35339 (92%)]\tLoss: 0.000246\n",
            "Train Epoch: 8 [32960/35339 (93%)]\tLoss: 0.018042\n",
            "Train Epoch: 8 [33280/35339 (94%)]\tLoss: 0.000556\n",
            "Train Epoch: 8 [33600/35339 (95%)]\tLoss: 0.002839\n",
            "Train Epoch: 8 [33920/35339 (96%)]\tLoss: 0.000605\n",
            "Train Epoch: 8 [34240/35339 (97%)]\tLoss: 0.000264\n",
            "Train Epoch: 8 [34560/35339 (98%)]\tLoss: 0.001126\n",
            "Train Epoch: 8 [34880/35339 (99%)]\tLoss: 0.000390\n",
            "Train Epoch: 8 [35200/35339 (100%)]\tLoss: 0.000112\n",
            "\n",
            "Validation set: Average loss: 0.1259, Accuracy: 3770/3870 (97%)\n",
            "\n",
            "\n",
            "Saved model to model_8.pth.\n",
            "Train Epoch: 9 [0/35339 (0%)]\tLoss: 0.000022\n",
            "Train Epoch: 9 [320/35339 (1%)]\tLoss: 0.000004\n",
            "Train Epoch: 9 [640/35339 (2%)]\tLoss: 0.011676\n",
            "Train Epoch: 9 [960/35339 (3%)]\tLoss: 0.000129\n",
            "Train Epoch: 9 [1280/35339 (4%)]\tLoss: 0.000429\n",
            "Train Epoch: 9 [1600/35339 (5%)]\tLoss: 0.000004\n",
            "Train Epoch: 9 [1920/35339 (5%)]\tLoss: 0.004772\n",
            "Train Epoch: 9 [2240/35339 (6%)]\tLoss: 0.022533\n",
            "Train Epoch: 9 [2560/35339 (7%)]\tLoss: 0.229538\n",
            "Train Epoch: 9 [2880/35339 (8%)]\tLoss: 0.000328\n",
            "Train Epoch: 9 [3200/35339 (9%)]\tLoss: 0.000059\n",
            "Train Epoch: 9 [3520/35339 (10%)]\tLoss: 0.082298\n",
            "Train Epoch: 9 [3840/35339 (11%)]\tLoss: 0.000014\n",
            "Train Epoch: 9 [4160/35339 (12%)]\tLoss: 0.006216\n",
            "Train Epoch: 9 [4480/35339 (13%)]\tLoss: 0.000415\n",
            "Train Epoch: 9 [4800/35339 (14%)]\tLoss: 0.031132\n",
            "Train Epoch: 9 [5120/35339 (14%)]\tLoss: 0.000079\n",
            "Train Epoch: 9 [5440/35339 (15%)]\tLoss: 0.017115\n",
            "Train Epoch: 9 [5760/35339 (16%)]\tLoss: 0.000465\n",
            "Train Epoch: 9 [6080/35339 (17%)]\tLoss: 0.043484\n",
            "Train Epoch: 9 [6400/35339 (18%)]\tLoss: 0.000000\n",
            "Train Epoch: 9 [6720/35339 (19%)]\tLoss: 0.000000\n",
            "Train Epoch: 9 [7040/35339 (20%)]\tLoss: 0.193699\n",
            "Train Epoch: 9 [7360/35339 (21%)]\tLoss: 0.006180\n",
            "Train Epoch: 9 [7680/35339 (22%)]\tLoss: 0.000005\n",
            "Train Epoch: 9 [8000/35339 (23%)]\tLoss: 0.031799\n",
            "Train Epoch: 9 [8320/35339 (24%)]\tLoss: 0.000067\n",
            "Train Epoch: 9 [8640/35339 (24%)]\tLoss: 0.000025\n",
            "Train Epoch: 9 [8960/35339 (25%)]\tLoss: 0.001736\n",
            "Train Epoch: 9 [9280/35339 (26%)]\tLoss: 0.000021\n",
            "Train Epoch: 9 [9600/35339 (27%)]\tLoss: 0.011000\n",
            "Train Epoch: 9 [9920/35339 (28%)]\tLoss: 0.000154\n",
            "Train Epoch: 9 [10240/35339 (29%)]\tLoss: 0.000020\n",
            "Train Epoch: 9 [10560/35339 (30%)]\tLoss: 0.002442\n",
            "Train Epoch: 9 [10880/35339 (31%)]\tLoss: 0.002504\n",
            "Train Epoch: 9 [11200/35339 (32%)]\tLoss: 0.026428\n",
            "Train Epoch: 9 [11520/35339 (33%)]\tLoss: 0.000158\n",
            "Train Epoch: 9 [11840/35339 (33%)]\tLoss: 0.001744\n",
            "Train Epoch: 9 [12160/35339 (34%)]\tLoss: 0.003613\n",
            "Train Epoch: 9 [12480/35339 (35%)]\tLoss: 0.007459\n",
            "Train Epoch: 9 [12800/35339 (36%)]\tLoss: 0.000767\n",
            "Train Epoch: 9 [13120/35339 (37%)]\tLoss: 0.021742\n",
            "Train Epoch: 9 [13440/35339 (38%)]\tLoss: 0.000676\n",
            "Train Epoch: 9 [13760/35339 (39%)]\tLoss: 0.001331\n",
            "Train Epoch: 9 [14080/35339 (40%)]\tLoss: 0.142596\n",
            "Train Epoch: 9 [14400/35339 (41%)]\tLoss: 0.003435\n",
            "Train Epoch: 9 [14720/35339 (42%)]\tLoss: 0.000523\n",
            "Train Epoch: 9 [15040/35339 (43%)]\tLoss: 0.124783\n",
            "Train Epoch: 9 [15360/35339 (43%)]\tLoss: 0.000008\n",
            "Train Epoch: 9 [15680/35339 (44%)]\tLoss: 0.000025\n",
            "Train Epoch: 9 [16000/35339 (45%)]\tLoss: 0.026917\n",
            "Train Epoch: 9 [16320/35339 (46%)]\tLoss: 0.005920\n",
            "Train Epoch: 9 [16640/35339 (47%)]\tLoss: 0.003292\n",
            "Train Epoch: 9 [16960/35339 (48%)]\tLoss: 0.000002\n",
            "Train Epoch: 9 [17280/35339 (49%)]\tLoss: 0.000455\n",
            "Train Epoch: 9 [17600/35339 (50%)]\tLoss: 0.002875\n",
            "Train Epoch: 9 [17920/35339 (51%)]\tLoss: 0.000174\n",
            "Train Epoch: 9 [18240/35339 (52%)]\tLoss: 0.000026\n",
            "Train Epoch: 9 [18560/35339 (52%)]\tLoss: 0.000092\n",
            "Train Epoch: 9 [18880/35339 (53%)]\tLoss: 0.042699\n",
            "Train Epoch: 9 [19200/35339 (54%)]\tLoss: 0.000241\n",
            "Train Epoch: 9 [19520/35339 (55%)]\tLoss: 0.002595\n",
            "Train Epoch: 9 [19840/35339 (56%)]\tLoss: 0.014949\n",
            "Train Epoch: 9 [20160/35339 (57%)]\tLoss: 0.265382\n",
            "Train Epoch: 9 [20480/35339 (58%)]\tLoss: 0.072712\n",
            "Train Epoch: 9 [20800/35339 (59%)]\tLoss: 0.005699\n",
            "Train Epoch: 9 [21120/35339 (60%)]\tLoss: 0.017347\n",
            "Train Epoch: 9 [21440/35339 (61%)]\tLoss: 0.419113\n",
            "Train Epoch: 9 [21760/35339 (62%)]\tLoss: 0.024832\n",
            "Train Epoch: 9 [22080/35339 (62%)]\tLoss: 0.017900\n",
            "Train Epoch: 9 [22400/35339 (63%)]\tLoss: 0.014406\n",
            "Train Epoch: 9 [22720/35339 (64%)]\tLoss: 0.000823\n",
            "Train Epoch: 9 [23040/35339 (65%)]\tLoss: 0.000401\n",
            "Train Epoch: 9 [23360/35339 (66%)]\tLoss: 0.012759\n",
            "Train Epoch: 9 [23680/35339 (67%)]\tLoss: 0.030727\n",
            "Train Epoch: 9 [24000/35339 (68%)]\tLoss: 0.023859\n",
            "Train Epoch: 9 [24320/35339 (69%)]\tLoss: 0.000055\n",
            "Train Epoch: 9 [24640/35339 (70%)]\tLoss: 0.012802\n",
            "Train Epoch: 9 [24960/35339 (71%)]\tLoss: 0.001453\n",
            "Train Epoch: 9 [25280/35339 (71%)]\tLoss: 0.035132\n",
            "Train Epoch: 9 [25600/35339 (72%)]\tLoss: 0.003531\n",
            "Train Epoch: 9 [25920/35339 (73%)]\tLoss: 0.001043\n",
            "Train Epoch: 9 [26240/35339 (74%)]\tLoss: 0.223901\n",
            "Train Epoch: 9 [26560/35339 (75%)]\tLoss: 0.164594\n",
            "Train Epoch: 9 [26880/35339 (76%)]\tLoss: 0.001791\n",
            "Train Epoch: 9 [27200/35339 (77%)]\tLoss: 0.006605\n",
            "Train Epoch: 9 [27520/35339 (78%)]\tLoss: 0.036716\n",
            "Train Epoch: 9 [27840/35339 (79%)]\tLoss: 0.000663\n",
            "Train Epoch: 9 [28160/35339 (80%)]\tLoss: 0.006345\n",
            "Train Epoch: 9 [28480/35339 (81%)]\tLoss: 0.000528\n",
            "Train Epoch: 9 [28800/35339 (81%)]\tLoss: 0.000544\n",
            "Train Epoch: 9 [29120/35339 (82%)]\tLoss: 0.000016\n",
            "Train Epoch: 9 [29440/35339 (83%)]\tLoss: 0.005947\n",
            "Train Epoch: 9 [29760/35339 (84%)]\tLoss: 0.004551\n",
            "Train Epoch: 9 [30080/35339 (85%)]\tLoss: 0.003194\n",
            "Train Epoch: 9 [30400/35339 (86%)]\tLoss: 0.000245\n",
            "Train Epoch: 9 [30720/35339 (87%)]\tLoss: 0.021374\n",
            "Train Epoch: 9 [31040/35339 (88%)]\tLoss: 0.000497\n",
            "Train Epoch: 9 [31360/35339 (89%)]\tLoss: 0.026097\n",
            "Train Epoch: 9 [31680/35339 (90%)]\tLoss: 0.319896\n",
            "Train Epoch: 9 [32000/35339 (90%)]\tLoss: 0.001328\n",
            "Train Epoch: 9 [32320/35339 (91%)]\tLoss: 0.000013\n",
            "Train Epoch: 9 [32640/35339 (92%)]\tLoss: 0.000048\n",
            "Train Epoch: 9 [32960/35339 (93%)]\tLoss: 0.005243\n",
            "Train Epoch: 9 [33280/35339 (94%)]\tLoss: 0.000798\n",
            "Train Epoch: 9 [33600/35339 (95%)]\tLoss: 0.000126\n",
            "Train Epoch: 9 [33920/35339 (96%)]\tLoss: 0.001263\n",
            "Train Epoch: 9 [34240/35339 (97%)]\tLoss: 0.000098\n",
            "Train Epoch: 9 [34560/35339 (98%)]\tLoss: 0.012951\n",
            "Train Epoch: 9 [34880/35339 (99%)]\tLoss: 0.000250\n",
            "Train Epoch: 9 [35200/35339 (100%)]\tLoss: 0.001865\n",
            "\n",
            "Validation set: Average loss: 0.2122, Accuracy: 3762/3870 (97%)\n",
            "\n",
            "\n",
            "Saved model to model_9.pth.\n",
            "Train Epoch: 10 [0/35339 (0%)]\tLoss: 0.001075\n",
            "Train Epoch: 10 [320/35339 (1%)]\tLoss: 0.000046\n",
            "Train Epoch: 10 [640/35339 (2%)]\tLoss: 0.000001\n",
            "Train Epoch: 10 [960/35339 (3%)]\tLoss: 0.027573\n",
            "Train Epoch: 10 [1280/35339 (4%)]\tLoss: 0.000002\n",
            "Train Epoch: 10 [1600/35339 (5%)]\tLoss: 0.005502\n",
            "Train Epoch: 10 [1920/35339 (5%)]\tLoss: 0.000023\n",
            "Train Epoch: 10 [2240/35339 (6%)]\tLoss: 0.011322\n",
            "Train Epoch: 10 [2560/35339 (7%)]\tLoss: 0.000000\n",
            "Train Epoch: 10 [2880/35339 (8%)]\tLoss: 0.000004\n",
            "Train Epoch: 10 [3200/35339 (9%)]\tLoss: 0.000000\n",
            "Train Epoch: 10 [3520/35339 (10%)]\tLoss: 0.014497\n",
            "Train Epoch: 10 [3840/35339 (11%)]\tLoss: 0.305175\n",
            "Train Epoch: 10 [4160/35339 (12%)]\tLoss: 0.000002\n",
            "Train Epoch: 10 [4480/35339 (13%)]\tLoss: 0.221507\n",
            "Train Epoch: 10 [4800/35339 (14%)]\tLoss: 0.000125\n",
            "Train Epoch: 10 [5120/35339 (14%)]\tLoss: 0.044064\n",
            "Train Epoch: 10 [5440/35339 (15%)]\tLoss: 0.001593\n",
            "Train Epoch: 10 [5760/35339 (16%)]\tLoss: 0.000004\n",
            "Train Epoch: 10 [6080/35339 (17%)]\tLoss: 0.015598\n",
            "Train Epoch: 10 [6400/35339 (18%)]\tLoss: 0.000022\n",
            "Train Epoch: 10 [6720/35339 (19%)]\tLoss: 0.014192\n",
            "Train Epoch: 10 [7040/35339 (20%)]\tLoss: 0.033931\n",
            "Train Epoch: 10 [7360/35339 (21%)]\tLoss: 0.000003\n",
            "Train Epoch: 10 [7680/35339 (22%)]\tLoss: 0.161915\n",
            "Train Epoch: 10 [8000/35339 (23%)]\tLoss: 0.000009\n",
            "Train Epoch: 10 [8320/35339 (24%)]\tLoss: 0.000033\n",
            "Train Epoch: 10 [8640/35339 (24%)]\tLoss: 0.000013\n",
            "Train Epoch: 10 [8960/35339 (25%)]\tLoss: 0.019066\n",
            "Train Epoch: 10 [9280/35339 (26%)]\tLoss: 0.018001\n",
            "Train Epoch: 10 [9600/35339 (27%)]\tLoss: 0.000089\n",
            "Train Epoch: 10 [9920/35339 (28%)]\tLoss: 0.005237\n",
            "Train Epoch: 10 [10240/35339 (29%)]\tLoss: 0.066546\n",
            "Train Epoch: 10 [10560/35339 (30%)]\tLoss: 0.000018\n",
            "Train Epoch: 10 [10880/35339 (31%)]\tLoss: 0.001528\n",
            "Train Epoch: 10 [11200/35339 (32%)]\tLoss: 0.328653\n",
            "Train Epoch: 10 [11520/35339 (33%)]\tLoss: 0.065984\n",
            "Train Epoch: 10 [11840/35339 (33%)]\tLoss: 0.096744\n",
            "Train Epoch: 10 [12160/35339 (34%)]\tLoss: 0.000058\n",
            "Train Epoch: 10 [12480/35339 (35%)]\tLoss: 0.006811\n",
            "Train Epoch: 10 [12800/35339 (36%)]\tLoss: 0.034198\n",
            "Train Epoch: 10 [13120/35339 (37%)]\tLoss: 0.000016\n",
            "Train Epoch: 10 [13440/35339 (38%)]\tLoss: 0.000010\n",
            "Train Epoch: 10 [13760/35339 (39%)]\tLoss: 0.001086\n",
            "Train Epoch: 10 [14080/35339 (40%)]\tLoss: 0.000015\n",
            "Train Epoch: 10 [14400/35339 (41%)]\tLoss: 0.000001\n",
            "Train Epoch: 10 [14720/35339 (42%)]\tLoss: 0.000003\n",
            "Train Epoch: 10 [15040/35339 (43%)]\tLoss: 0.335556\n",
            "Train Epoch: 10 [15360/35339 (43%)]\tLoss: 0.000000\n",
            "Train Epoch: 10 [15680/35339 (44%)]\tLoss: 0.309340\n",
            "Train Epoch: 10 [16000/35339 (45%)]\tLoss: 0.000007\n",
            "Train Epoch: 10 [16320/35339 (46%)]\tLoss: 0.094751\n",
            "Train Epoch: 10 [16640/35339 (47%)]\tLoss: 0.000111\n",
            "Train Epoch: 10 [16960/35339 (48%)]\tLoss: 0.011095\n",
            "Train Epoch: 10 [17280/35339 (49%)]\tLoss: 0.000854\n",
            "Train Epoch: 10 [17600/35339 (50%)]\tLoss: 0.000104\n",
            "Train Epoch: 10 [17920/35339 (51%)]\tLoss: 0.000061\n",
            "Train Epoch: 10 [18240/35339 (52%)]\tLoss: 0.000249\n",
            "Train Epoch: 10 [18560/35339 (52%)]\tLoss: 0.000375\n",
            "Train Epoch: 10 [18880/35339 (53%)]\tLoss: 0.000036\n",
            "Train Epoch: 10 [19200/35339 (54%)]\tLoss: 0.000020\n",
            "Train Epoch: 10 [19520/35339 (55%)]\tLoss: 0.000947\n",
            "Train Epoch: 10 [19840/35339 (56%)]\tLoss: 0.000001\n",
            "Train Epoch: 10 [20160/35339 (57%)]\tLoss: 0.205704\n",
            "Train Epoch: 10 [20480/35339 (58%)]\tLoss: 0.001563\n",
            "Train Epoch: 10 [20800/35339 (59%)]\tLoss: 0.000001\n",
            "Train Epoch: 10 [21120/35339 (60%)]\tLoss: 0.000073\n",
            "Train Epoch: 10 [21440/35339 (61%)]\tLoss: 0.000002\n",
            "Train Epoch: 10 [21760/35339 (62%)]\tLoss: 0.000000\n",
            "Train Epoch: 10 [22080/35339 (62%)]\tLoss: 0.000038\n",
            "Train Epoch: 10 [22400/35339 (63%)]\tLoss: 0.009239\n",
            "Train Epoch: 10 [22720/35339 (64%)]\tLoss: 0.001600\n",
            "Train Epoch: 10 [23040/35339 (65%)]\tLoss: 0.000007\n",
            "Train Epoch: 10 [23360/35339 (66%)]\tLoss: 0.017378\n",
            "Train Epoch: 10 [23680/35339 (67%)]\tLoss: 0.000054\n",
            "Train Epoch: 10 [24000/35339 (68%)]\tLoss: 0.173851\n",
            "Train Epoch: 10 [24320/35339 (69%)]\tLoss: 0.014474\n",
            "Train Epoch: 10 [24640/35339 (70%)]\tLoss: 0.000049\n",
            "Train Epoch: 10 [24960/35339 (71%)]\tLoss: 0.000016\n",
            "Train Epoch: 10 [25280/35339 (71%)]\tLoss: 0.002930\n",
            "Train Epoch: 10 [25600/35339 (72%)]\tLoss: 0.097367\n",
            "Train Epoch: 10 [25920/35339 (73%)]\tLoss: 0.000005\n",
            "Train Epoch: 10 [26240/35339 (74%)]\tLoss: 0.195312\n",
            "Train Epoch: 10 [26560/35339 (75%)]\tLoss: 0.000215\n",
            "Train Epoch: 10 [26880/35339 (76%)]\tLoss: 0.000418\n",
            "Train Epoch: 10 [27200/35339 (77%)]\tLoss: 0.369613\n",
            "Train Epoch: 10 [27520/35339 (78%)]\tLoss: 0.000000\n",
            "Train Epoch: 10 [27840/35339 (79%)]\tLoss: 0.000181\n",
            "Train Epoch: 10 [28160/35339 (80%)]\tLoss: 0.003890\n",
            "Train Epoch: 10 [28480/35339 (81%)]\tLoss: 0.000150\n",
            "Train Epoch: 10 [28800/35339 (81%)]\tLoss: 0.001419\n",
            "Train Epoch: 10 [29120/35339 (82%)]\tLoss: 0.000020\n",
            "Train Epoch: 10 [29440/35339 (83%)]\tLoss: 0.005868\n",
            "Train Epoch: 10 [29760/35339 (84%)]\tLoss: 0.005889\n",
            "Train Epoch: 10 [30080/35339 (85%)]\tLoss: 0.000006\n",
            "Train Epoch: 10 [30400/35339 (86%)]\tLoss: 0.000002\n",
            "Train Epoch: 10 [30720/35339 (87%)]\tLoss: 0.000001\n",
            "Train Epoch: 10 [31040/35339 (88%)]\tLoss: 0.000361\n",
            "Train Epoch: 10 [31360/35339 (89%)]\tLoss: 0.004023\n",
            "Train Epoch: 10 [31680/35339 (90%)]\tLoss: 0.000065\n",
            "Train Epoch: 10 [32000/35339 (90%)]\tLoss: 0.001247\n",
            "Train Epoch: 10 [32320/35339 (91%)]\tLoss: 0.007551\n",
            "Train Epoch: 10 [32640/35339 (92%)]\tLoss: 0.011348\n",
            "Train Epoch: 10 [32960/35339 (93%)]\tLoss: 0.002348\n",
            "Train Epoch: 10 [33280/35339 (94%)]\tLoss: 0.008923\n",
            "Train Epoch: 10 [33600/35339 (95%)]\tLoss: 0.000011\n",
            "Train Epoch: 10 [33920/35339 (96%)]\tLoss: 0.000028\n",
            "Train Epoch: 10 [34240/35339 (97%)]\tLoss: 0.000361\n",
            "Train Epoch: 10 [34560/35339 (98%)]\tLoss: 0.007366\n",
            "Train Epoch: 10 [34880/35339 (99%)]\tLoss: 0.003419\n",
            "Train Epoch: 10 [35200/35339 (100%)]\tLoss: 0.006668\n",
            "\n",
            "Validation set: Average loss: 0.1033, Accuracy: 3796/3870 (98%)\n",
            "\n",
            "\n",
            "Saved model to model_10.pth.\n",
            "Train Epoch: 11 [0/35339 (0%)]\tLoss: 0.003689\n",
            "Train Epoch: 11 [320/35339 (1%)]\tLoss: 0.077769\n",
            "Train Epoch: 11 [640/35339 (2%)]\tLoss: 0.006226\n",
            "Train Epoch: 11 [960/35339 (3%)]\tLoss: 0.000083\n",
            "Train Epoch: 11 [1280/35339 (4%)]\tLoss: 0.000002\n",
            "Train Epoch: 11 [1600/35339 (5%)]\tLoss: 0.000127\n",
            "Train Epoch: 11 [1920/35339 (5%)]\tLoss: 0.000000\n",
            "Train Epoch: 11 [2240/35339 (6%)]\tLoss: 0.000008\n",
            "Train Epoch: 11 [2560/35339 (7%)]\tLoss: 0.000010\n",
            "Train Epoch: 11 [2880/35339 (8%)]\tLoss: 0.000097\n",
            "Train Epoch: 11 [3200/35339 (9%)]\tLoss: 0.000543\n",
            "Train Epoch: 11 [3520/35339 (10%)]\tLoss: 0.000000\n",
            "Train Epoch: 11 [3840/35339 (11%)]\tLoss: 0.000019\n",
            "Train Epoch: 11 [4160/35339 (12%)]\tLoss: 0.000000\n",
            "Train Epoch: 11 [4480/35339 (13%)]\tLoss: 0.000001\n",
            "Train Epoch: 11 [4800/35339 (14%)]\tLoss: 0.000893\n",
            "Train Epoch: 11 [5120/35339 (14%)]\tLoss: 0.000003\n",
            "Train Epoch: 11 [5440/35339 (15%)]\tLoss: 0.000027\n",
            "Train Epoch: 11 [5760/35339 (16%)]\tLoss: 0.251219\n",
            "Train Epoch: 11 [6080/35339 (17%)]\tLoss: 0.000004\n",
            "Train Epoch: 11 [6400/35339 (18%)]\tLoss: 0.007081\n",
            "Train Epoch: 11 [6720/35339 (19%)]\tLoss: 0.059921\n",
            "Train Epoch: 11 [7040/35339 (20%)]\tLoss: 0.000241\n",
            "Train Epoch: 11 [7360/35339 (21%)]\tLoss: 0.000023\n",
            "Train Epoch: 11 [7680/35339 (22%)]\tLoss: 0.000002\n",
            "Train Epoch: 11 [8000/35339 (23%)]\tLoss: 0.003595\n",
            "Train Epoch: 11 [8320/35339 (24%)]\tLoss: 0.000001\n",
            "Train Epoch: 11 [8640/35339 (24%)]\tLoss: 0.000047\n",
            "Train Epoch: 11 [8960/35339 (25%)]\tLoss: 0.000172\n",
            "Train Epoch: 11 [9280/35339 (26%)]\tLoss: 0.004459\n",
            "Train Epoch: 11 [9600/35339 (27%)]\tLoss: 0.001842\n",
            "Train Epoch: 11 [9920/35339 (28%)]\tLoss: 0.014792\n",
            "Train Epoch: 11 [10240/35339 (29%)]\tLoss: 0.000457\n",
            "Train Epoch: 11 [10560/35339 (30%)]\tLoss: 0.000970\n",
            "Train Epoch: 11 [10880/35339 (31%)]\tLoss: 0.000286\n",
            "Train Epoch: 11 [11200/35339 (32%)]\tLoss: 0.000006\n",
            "Train Epoch: 11 [11520/35339 (33%)]\tLoss: 0.000139\n",
            "Train Epoch: 11 [11840/35339 (33%)]\tLoss: 0.000144\n",
            "Train Epoch: 11 [12160/35339 (34%)]\tLoss: 0.000056\n",
            "Train Epoch: 11 [12480/35339 (35%)]\tLoss: 0.000001\n",
            "Train Epoch: 11 [12800/35339 (36%)]\tLoss: 0.001064\n",
            "Train Epoch: 11 [13120/35339 (37%)]\tLoss: 0.000438\n",
            "Train Epoch: 11 [13440/35339 (38%)]\tLoss: 0.000122\n",
            "Train Epoch: 11 [13760/35339 (39%)]\tLoss: 0.001874\n",
            "Train Epoch: 11 [14080/35339 (40%)]\tLoss: 0.000014\n",
            "Train Epoch: 11 [14400/35339 (41%)]\tLoss: 0.000008\n",
            "Train Epoch: 11 [14720/35339 (42%)]\tLoss: 0.000022\n",
            "Train Epoch: 11 [15040/35339 (43%)]\tLoss: 0.000038\n",
            "Train Epoch: 11 [15360/35339 (43%)]\tLoss: 0.000005\n",
            "Train Epoch: 11 [15680/35339 (44%)]\tLoss: 0.000074\n",
            "Train Epoch: 11 [16000/35339 (45%)]\tLoss: 0.000417\n",
            "Train Epoch: 11 [16320/35339 (46%)]\tLoss: 0.027819\n",
            "Train Epoch: 11 [16640/35339 (47%)]\tLoss: 0.083885\n",
            "Train Epoch: 11 [16960/35339 (48%)]\tLoss: 0.000003\n",
            "Train Epoch: 11 [17280/35339 (49%)]\tLoss: 0.000010\n",
            "Train Epoch: 11 [17600/35339 (50%)]\tLoss: 0.019244\n",
            "Train Epoch: 11 [17920/35339 (51%)]\tLoss: 0.000116\n",
            "Train Epoch: 11 [18240/35339 (52%)]\tLoss: 0.000468\n",
            "Train Epoch: 11 [18560/35339 (52%)]\tLoss: 0.008874\n",
            "Train Epoch: 11 [18880/35339 (53%)]\tLoss: 0.004529\n",
            "Train Epoch: 11 [19200/35339 (54%)]\tLoss: 0.000001\n",
            "Train Epoch: 11 [19520/35339 (55%)]\tLoss: 0.000000\n",
            "Train Epoch: 11 [19840/35339 (56%)]\tLoss: 0.004850\n",
            "Train Epoch: 11 [20160/35339 (57%)]\tLoss: 0.333327\n",
            "Train Epoch: 11 [20480/35339 (58%)]\tLoss: 0.000003\n",
            "Train Epoch: 11 [20800/35339 (59%)]\tLoss: 0.003081\n",
            "Train Epoch: 11 [21120/35339 (60%)]\tLoss: 0.000000\n",
            "Train Epoch: 11 [21440/35339 (61%)]\tLoss: 0.000470\n",
            "Train Epoch: 11 [21760/35339 (62%)]\tLoss: 0.000008\n",
            "Train Epoch: 11 [22080/35339 (62%)]\tLoss: 0.002337\n",
            "Train Epoch: 11 [22400/35339 (63%)]\tLoss: 0.001273\n",
            "Train Epoch: 11 [22720/35339 (64%)]\tLoss: 0.000000\n",
            "Train Epoch: 11 [23040/35339 (65%)]\tLoss: 0.001788\n",
            "Train Epoch: 11 [23360/35339 (66%)]\tLoss: 0.000378\n",
            "Train Epoch: 11 [23680/35339 (67%)]\tLoss: 0.000040\n",
            "Train Epoch: 11 [24000/35339 (68%)]\tLoss: 0.000000\n",
            "Train Epoch: 11 [24320/35339 (69%)]\tLoss: 0.000143\n",
            "Train Epoch: 11 [24640/35339 (70%)]\tLoss: 0.000067\n",
            "Train Epoch: 11 [24960/35339 (71%)]\tLoss: 0.014061\n",
            "Train Epoch: 11 [25280/35339 (71%)]\tLoss: 0.012925\n",
            "Train Epoch: 11 [25600/35339 (72%)]\tLoss: 0.000008\n",
            "Train Epoch: 11 [25920/35339 (73%)]\tLoss: 0.000243\n",
            "Train Epoch: 11 [26240/35339 (74%)]\tLoss: 0.001913\n",
            "Train Epoch: 11 [26560/35339 (75%)]\tLoss: 0.001698\n",
            "Train Epoch: 11 [26880/35339 (76%)]\tLoss: 0.000001\n",
            "Train Epoch: 11 [27200/35339 (77%)]\tLoss: 0.000221\n",
            "Train Epoch: 11 [27520/35339 (78%)]\tLoss: 0.000606\n",
            "Train Epoch: 11 [27840/35339 (79%)]\tLoss: 0.257879\n",
            "Train Epoch: 11 [28160/35339 (80%)]\tLoss: 0.038879\n",
            "Train Epoch: 11 [28480/35339 (81%)]\tLoss: 0.032758\n",
            "Train Epoch: 11 [28800/35339 (81%)]\tLoss: 0.014201\n",
            "Train Epoch: 11 [29120/35339 (82%)]\tLoss: 0.000893\n",
            "Train Epoch: 11 [29440/35339 (83%)]\tLoss: 0.000024\n",
            "Train Epoch: 11 [29760/35339 (84%)]\tLoss: 0.183306\n",
            "Train Epoch: 11 [30080/35339 (85%)]\tLoss: 0.000027\n",
            "Train Epoch: 11 [30400/35339 (86%)]\tLoss: 0.033845\n",
            "Train Epoch: 11 [30720/35339 (87%)]\tLoss: 0.000130\n",
            "Train Epoch: 11 [31040/35339 (88%)]\tLoss: 0.000004\n",
            "Train Epoch: 11 [31360/35339 (89%)]\tLoss: 0.000001\n",
            "Train Epoch: 11 [31680/35339 (90%)]\tLoss: 0.000052\n",
            "Train Epoch: 11 [32000/35339 (90%)]\tLoss: 0.000055\n",
            "Train Epoch: 11 [32320/35339 (91%)]\tLoss: 0.003527\n",
            "Train Epoch: 11 [32640/35339 (92%)]\tLoss: 0.135162\n",
            "Train Epoch: 11 [32960/35339 (93%)]\tLoss: 0.000564\n",
            "Train Epoch: 11 [33280/35339 (94%)]\tLoss: 0.264197\n",
            "Train Epoch: 11 [33600/35339 (95%)]\tLoss: 0.000737\n",
            "Train Epoch: 11 [33920/35339 (96%)]\tLoss: 0.093317\n",
            "Train Epoch: 11 [34240/35339 (97%)]\tLoss: 0.027798\n",
            "Train Epoch: 11 [34560/35339 (98%)]\tLoss: 0.000098\n",
            "Train Epoch: 11 [34880/35339 (99%)]\tLoss: 0.000202\n",
            "Train Epoch: 11 [35200/35339 (100%)]\tLoss: 0.007168\n",
            "\n",
            "Validation set: Average loss: 0.1603, Accuracy: 3751/3870 (97%)\n",
            "\n",
            "\n",
            "Saved model to model_11.pth.\n",
            "Train Epoch: 12 [0/35339 (0%)]\tLoss: 0.000010\n",
            "Train Epoch: 12 [320/35339 (1%)]\tLoss: 0.000003\n",
            "Train Epoch: 12 [640/35339 (2%)]\tLoss: 0.042774\n",
            "Train Epoch: 12 [960/35339 (3%)]\tLoss: 0.048479\n",
            "Train Epoch: 12 [1280/35339 (4%)]\tLoss: 0.002084\n",
            "Train Epoch: 12 [1600/35339 (5%)]\tLoss: 0.001221\n",
            "Train Epoch: 12 [1920/35339 (5%)]\tLoss: 0.000036\n",
            "Train Epoch: 12 [2240/35339 (6%)]\tLoss: 0.000001\n",
            "Train Epoch: 12 [2560/35339 (7%)]\tLoss: 0.000016\n",
            "Train Epoch: 12 [2880/35339 (8%)]\tLoss: 0.000005\n",
            "Train Epoch: 12 [3200/35339 (9%)]\tLoss: 0.003649\n",
            "Train Epoch: 12 [3520/35339 (10%)]\tLoss: 0.001205\n",
            "Train Epoch: 12 [3840/35339 (11%)]\tLoss: 0.000001\n",
            "Train Epoch: 12 [4160/35339 (12%)]\tLoss: 0.148184\n",
            "Train Epoch: 12 [4480/35339 (13%)]\tLoss: 0.000065\n",
            "Train Epoch: 12 [4800/35339 (14%)]\tLoss: 0.005351\n",
            "Train Epoch: 12 [5120/35339 (14%)]\tLoss: 0.000091\n",
            "Train Epoch: 12 [5440/35339 (15%)]\tLoss: 0.007381\n",
            "Train Epoch: 12 [5760/35339 (16%)]\tLoss: 0.000001\n",
            "Train Epoch: 12 [6080/35339 (17%)]\tLoss: 0.000001\n",
            "Train Epoch: 12 [6400/35339 (18%)]\tLoss: 0.000587\n",
            "Train Epoch: 12 [6720/35339 (19%)]\tLoss: 0.000004\n",
            "Train Epoch: 12 [7040/35339 (20%)]\tLoss: 0.080359\n",
            "Train Epoch: 12 [7360/35339 (21%)]\tLoss: 0.000197\n",
            "Train Epoch: 12 [7680/35339 (22%)]\tLoss: 0.099412\n",
            "Train Epoch: 12 [8000/35339 (23%)]\tLoss: 0.028922\n",
            "Train Epoch: 12 [8320/35339 (24%)]\tLoss: 0.310517\n",
            "Train Epoch: 12 [8640/35339 (24%)]\tLoss: 0.004481\n",
            "Train Epoch: 12 [8960/35339 (25%)]\tLoss: 0.000522\n",
            "Train Epoch: 12 [9280/35339 (26%)]\tLoss: 0.000007\n",
            "Train Epoch: 12 [9600/35339 (27%)]\tLoss: 0.003080\n",
            "Train Epoch: 12 [9920/35339 (28%)]\tLoss: 0.000003\n",
            "Train Epoch: 12 [10240/35339 (29%)]\tLoss: 0.004583\n",
            "Train Epoch: 12 [10560/35339 (30%)]\tLoss: 0.001754\n",
            "Train Epoch: 12 [10880/35339 (31%)]\tLoss: 0.000432\n",
            "Train Epoch: 12 [11200/35339 (32%)]\tLoss: 0.000049\n",
            "Train Epoch: 12 [11520/35339 (33%)]\tLoss: 0.000030\n",
            "Train Epoch: 12 [11840/35339 (33%)]\tLoss: 0.011992\n",
            "Train Epoch: 12 [12160/35339 (34%)]\tLoss: 0.003850\n",
            "Train Epoch: 12 [12480/35339 (35%)]\tLoss: 0.000400\n",
            "Train Epoch: 12 [12800/35339 (36%)]\tLoss: 0.000007\n",
            "Train Epoch: 12 [13120/35339 (37%)]\tLoss: 0.000067\n",
            "Train Epoch: 12 [13440/35339 (38%)]\tLoss: 0.000000\n",
            "Train Epoch: 12 [13760/35339 (39%)]\tLoss: 0.005518\n",
            "Train Epoch: 12 [14080/35339 (40%)]\tLoss: 0.000009\n",
            "Train Epoch: 12 [14400/35339 (41%)]\tLoss: 0.000000\n",
            "Train Epoch: 12 [14720/35339 (42%)]\tLoss: 0.000049\n",
            "Train Epoch: 12 [15040/35339 (43%)]\tLoss: 0.000034\n",
            "Train Epoch: 12 [15360/35339 (43%)]\tLoss: 0.005552\n",
            "Train Epoch: 12 [15680/35339 (44%)]\tLoss: 0.000621\n",
            "Train Epoch: 12 [16000/35339 (45%)]\tLoss: 0.003346\n",
            "Train Epoch: 12 [16320/35339 (46%)]\tLoss: 0.068714\n",
            "Train Epoch: 12 [16640/35339 (47%)]\tLoss: 0.000056\n",
            "Train Epoch: 12 [16960/35339 (48%)]\tLoss: 0.000189\n",
            "Train Epoch: 12 [17280/35339 (49%)]\tLoss: 0.000067\n",
            "Train Epoch: 12 [17600/35339 (50%)]\tLoss: 0.000874\n",
            "Train Epoch: 12 [17920/35339 (51%)]\tLoss: 0.000022\n",
            "Train Epoch: 12 [18240/35339 (52%)]\tLoss: 0.000067\n",
            "Train Epoch: 12 [18560/35339 (52%)]\tLoss: 0.004303\n",
            "Train Epoch: 12 [18880/35339 (53%)]\tLoss: 0.169522\n",
            "Train Epoch: 12 [19200/35339 (54%)]\tLoss: 0.000036\n",
            "Train Epoch: 12 [19520/35339 (55%)]\tLoss: 0.000040\n",
            "Train Epoch: 12 [19840/35339 (56%)]\tLoss: 0.132130\n",
            "Train Epoch: 12 [20160/35339 (57%)]\tLoss: 0.044784\n",
            "Train Epoch: 12 [20480/35339 (58%)]\tLoss: 0.090182\n",
            "Train Epoch: 12 [20800/35339 (59%)]\tLoss: 0.013549\n",
            "Train Epoch: 12 [21120/35339 (60%)]\tLoss: 0.373165\n",
            "Train Epoch: 12 [21440/35339 (61%)]\tLoss: 0.000503\n",
            "Train Epoch: 12 [21760/35339 (62%)]\tLoss: 0.025659\n",
            "Train Epoch: 12 [22080/35339 (62%)]\tLoss: 0.000037\n",
            "Train Epoch: 12 [22400/35339 (63%)]\tLoss: 0.000474\n",
            "Train Epoch: 12 [22720/35339 (64%)]\tLoss: 0.003874\n",
            "Train Epoch: 12 [23040/35339 (65%)]\tLoss: 0.127369\n",
            "Train Epoch: 12 [23360/35339 (66%)]\tLoss: 0.029034\n",
            "Train Epoch: 12 [23680/35339 (67%)]\tLoss: 0.000031\n",
            "Train Epoch: 12 [24000/35339 (68%)]\tLoss: 0.004038\n",
            "Train Epoch: 12 [24320/35339 (69%)]\tLoss: 0.000006\n",
            "Train Epoch: 12 [24640/35339 (70%)]\tLoss: 0.000002\n",
            "Train Epoch: 12 [24960/35339 (71%)]\tLoss: 0.000081\n",
            "Train Epoch: 12 [25280/35339 (71%)]\tLoss: 0.028410\n",
            "Train Epoch: 12 [25600/35339 (72%)]\tLoss: 0.002359\n",
            "Train Epoch: 12 [25920/35339 (73%)]\tLoss: 0.000047\n",
            "Train Epoch: 12 [26240/35339 (74%)]\tLoss: 0.000001\n",
            "Train Epoch: 12 [26560/35339 (75%)]\tLoss: 0.000178\n",
            "Train Epoch: 12 [26880/35339 (76%)]\tLoss: 0.001031\n",
            "Train Epoch: 12 [27200/35339 (77%)]\tLoss: 0.000232\n",
            "Train Epoch: 12 [27520/35339 (78%)]\tLoss: 0.000015\n",
            "Train Epoch: 12 [27840/35339 (79%)]\tLoss: 0.000000\n",
            "Train Epoch: 12 [28160/35339 (80%)]\tLoss: 0.000000\n",
            "Train Epoch: 12 [28480/35339 (81%)]\tLoss: 0.000630\n",
            "Train Epoch: 12 [28800/35339 (81%)]\tLoss: 0.000000\n",
            "Train Epoch: 12 [29120/35339 (82%)]\tLoss: 0.138337\n",
            "Train Epoch: 12 [29440/35339 (83%)]\tLoss: 0.000011\n",
            "Train Epoch: 12 [29760/35339 (84%)]\tLoss: 0.063444\n",
            "Train Epoch: 12 [30080/35339 (85%)]\tLoss: 0.242707\n",
            "Train Epoch: 12 [30400/35339 (86%)]\tLoss: 0.000796\n",
            "Train Epoch: 12 [30720/35339 (87%)]\tLoss: 0.063849\n",
            "Train Epoch: 12 [31040/35339 (88%)]\tLoss: 0.000000\n",
            "Train Epoch: 12 [31360/35339 (89%)]\tLoss: 0.013874\n",
            "Train Epoch: 12 [31680/35339 (90%)]\tLoss: 0.059885\n",
            "Train Epoch: 12 [32000/35339 (90%)]\tLoss: 0.000239\n",
            "Train Epoch: 12 [32320/35339 (91%)]\tLoss: 0.000031\n",
            "Train Epoch: 12 [32640/35339 (92%)]\tLoss: 0.031391\n",
            "Train Epoch: 12 [32960/35339 (93%)]\tLoss: 0.069562\n",
            "Train Epoch: 12 [33280/35339 (94%)]\tLoss: 0.000016\n",
            "Train Epoch: 12 [33600/35339 (95%)]\tLoss: 0.000000\n",
            "Train Epoch: 12 [33920/35339 (96%)]\tLoss: 0.056353\n",
            "Train Epoch: 12 [34240/35339 (97%)]\tLoss: 0.109808\n",
            "Train Epoch: 12 [34560/35339 (98%)]\tLoss: 0.000007\n",
            "Train Epoch: 12 [34880/35339 (99%)]\tLoss: 0.000025\n",
            "Train Epoch: 12 [35200/35339 (100%)]\tLoss: 0.410424\n",
            "\n",
            "Validation set: Average loss: 0.1312, Accuracy: 3797/3870 (98%)\n",
            "\n",
            "\n",
            "Saved model to model_12.pth.\n",
            "Train Epoch: 13 [0/35339 (0%)]\tLoss: 0.000016\n",
            "Train Epoch: 13 [320/35339 (1%)]\tLoss: 0.287075\n",
            "Train Epoch: 13 [640/35339 (2%)]\tLoss: 0.000151\n",
            "Train Epoch: 13 [960/35339 (3%)]\tLoss: 0.000001\n",
            "Train Epoch: 13 [1280/35339 (4%)]\tLoss: 0.000000\n",
            "Train Epoch: 13 [1600/35339 (5%)]\tLoss: 0.005631\n",
            "Train Epoch: 13 [1920/35339 (5%)]\tLoss: 0.000048\n",
            "Train Epoch: 13 [2240/35339 (6%)]\tLoss: 0.000040\n",
            "Train Epoch: 13 [2560/35339 (7%)]\tLoss: 0.000001\n",
            "Train Epoch: 13 [2880/35339 (8%)]\tLoss: 0.002029\n",
            "Train Epoch: 13 [3200/35339 (9%)]\tLoss: 0.022619\n",
            "Train Epoch: 13 [3520/35339 (10%)]\tLoss: 0.000039\n",
            "Train Epoch: 13 [3840/35339 (11%)]\tLoss: 0.164140\n",
            "Train Epoch: 13 [4160/35339 (12%)]\tLoss: 0.000054\n",
            "Train Epoch: 13 [4480/35339 (13%)]\tLoss: 0.002671\n",
            "Train Epoch: 13 [4800/35339 (14%)]\tLoss: 0.024507\n",
            "Train Epoch: 13 [5120/35339 (14%)]\tLoss: 0.000239\n",
            "Train Epoch: 13 [5440/35339 (15%)]\tLoss: 0.000407\n",
            "Train Epoch: 13 [5760/35339 (16%)]\tLoss: 0.002745\n",
            "Train Epoch: 13 [6080/35339 (17%)]\tLoss: 0.000012\n",
            "Train Epoch: 13 [6400/35339 (18%)]\tLoss: 0.452284\n",
            "Train Epoch: 13 [6720/35339 (19%)]\tLoss: 0.003276\n",
            "Train Epoch: 13 [7040/35339 (20%)]\tLoss: 0.006955\n",
            "Train Epoch: 13 [7360/35339 (21%)]\tLoss: 0.000788\n",
            "Train Epoch: 13 [7680/35339 (22%)]\tLoss: 0.059851\n",
            "Train Epoch: 13 [8000/35339 (23%)]\tLoss: 0.000764\n",
            "Train Epoch: 13 [8320/35339 (24%)]\tLoss: 0.041931\n",
            "Train Epoch: 13 [8640/35339 (24%)]\tLoss: 0.000078\n",
            "Train Epoch: 13 [8960/35339 (25%)]\tLoss: 0.118629\n",
            "Train Epoch: 13 [9280/35339 (26%)]\tLoss: 0.011918\n",
            "Train Epoch: 13 [9600/35339 (27%)]\tLoss: 0.202553\n",
            "Train Epoch: 13 [9920/35339 (28%)]\tLoss: 0.000012\n",
            "Train Epoch: 13 [10240/35339 (29%)]\tLoss: 0.000043\n",
            "Train Epoch: 13 [10560/35339 (30%)]\tLoss: 0.000102\n",
            "Train Epoch: 13 [10880/35339 (31%)]\tLoss: 0.000175\n",
            "Train Epoch: 13 [11200/35339 (32%)]\tLoss: 0.000119\n",
            "Train Epoch: 13 [11520/35339 (33%)]\tLoss: 0.002381\n",
            "Train Epoch: 13 [11840/35339 (33%)]\tLoss: 0.000054\n",
            "Train Epoch: 13 [12160/35339 (34%)]\tLoss: 0.231231\n",
            "Train Epoch: 13 [12480/35339 (35%)]\tLoss: 0.000213\n",
            "Train Epoch: 13 [12800/35339 (36%)]\tLoss: 0.007102\n",
            "Train Epoch: 13 [13120/35339 (37%)]\tLoss: 0.052960\n",
            "Train Epoch: 13 [13440/35339 (38%)]\tLoss: 0.000474\n",
            "Train Epoch: 13 [13760/35339 (39%)]\tLoss: 0.000886\n",
            "Train Epoch: 13 [14080/35339 (40%)]\tLoss: 0.014886\n",
            "Train Epoch: 13 [14400/35339 (41%)]\tLoss: 0.000005\n",
            "Train Epoch: 13 [14720/35339 (42%)]\tLoss: 0.170094\n",
            "Train Epoch: 13 [15040/35339 (43%)]\tLoss: 0.000608\n",
            "Train Epoch: 13 [15360/35339 (43%)]\tLoss: 0.000205\n",
            "Train Epoch: 13 [15680/35339 (44%)]\tLoss: 0.005679\n",
            "Train Epoch: 13 [16000/35339 (45%)]\tLoss: 0.000001\n",
            "Train Epoch: 13 [16320/35339 (46%)]\tLoss: 0.000122\n",
            "Train Epoch: 13 [16640/35339 (47%)]\tLoss: 0.000104\n",
            "Train Epoch: 13 [16960/35339 (48%)]\tLoss: 0.000703\n",
            "Train Epoch: 13 [17280/35339 (49%)]\tLoss: 0.130408\n",
            "Train Epoch: 13 [17600/35339 (50%)]\tLoss: 0.032250\n",
            "Train Epoch: 13 [17920/35339 (51%)]\tLoss: 0.000000\n",
            "Train Epoch: 13 [18240/35339 (52%)]\tLoss: 0.007050\n",
            "Train Epoch: 13 [18560/35339 (52%)]\tLoss: 0.003168\n",
            "Train Epoch: 13 [18880/35339 (53%)]\tLoss: 0.000006\n",
            "Train Epoch: 13 [19200/35339 (54%)]\tLoss: 0.000031\n",
            "Train Epoch: 13 [19520/35339 (55%)]\tLoss: 0.020869\n",
            "Train Epoch: 13 [19840/35339 (56%)]\tLoss: 0.000781\n",
            "Train Epoch: 13 [20160/35339 (57%)]\tLoss: 0.013339\n",
            "Train Epoch: 13 [20480/35339 (58%)]\tLoss: 0.018700\n",
            "Train Epoch: 13 [20800/35339 (59%)]\tLoss: 0.006555\n",
            "Train Epoch: 13 [21120/35339 (60%)]\tLoss: 0.000026\n",
            "Train Epoch: 13 [21440/35339 (61%)]\tLoss: 0.000023\n",
            "Train Epoch: 13 [21760/35339 (62%)]\tLoss: 0.000000\n",
            "Train Epoch: 13 [22080/35339 (62%)]\tLoss: 0.001905\n",
            "Train Epoch: 13 [22400/35339 (63%)]\tLoss: 0.000444\n",
            "Train Epoch: 13 [22720/35339 (64%)]\tLoss: 0.000002\n",
            "Train Epoch: 13 [23040/35339 (65%)]\tLoss: 0.094810\n",
            "Train Epoch: 13 [23360/35339 (66%)]\tLoss: 0.000001\n",
            "Train Epoch: 13 [23680/35339 (67%)]\tLoss: 0.000000\n",
            "Train Epoch: 13 [24000/35339 (68%)]\tLoss: 0.000003\n",
            "Train Epoch: 13 [24320/35339 (69%)]\tLoss: 0.000005\n",
            "Train Epoch: 13 [24640/35339 (70%)]\tLoss: 0.034030\n",
            "Train Epoch: 13 [24960/35339 (71%)]\tLoss: 0.000001\n",
            "Train Epoch: 13 [25280/35339 (71%)]\tLoss: 0.000023\n",
            "Train Epoch: 13 [25600/35339 (72%)]\tLoss: 0.003053\n",
            "Train Epoch: 13 [25920/35339 (73%)]\tLoss: 0.005048\n",
            "Train Epoch: 13 [26240/35339 (74%)]\tLoss: 0.000058\n",
            "Train Epoch: 13 [26560/35339 (75%)]\tLoss: 0.068133\n",
            "Train Epoch: 13 [26880/35339 (76%)]\tLoss: 0.000000\n",
            "Train Epoch: 13 [27200/35339 (77%)]\tLoss: 0.000001\n",
            "Train Epoch: 13 [27520/35339 (78%)]\tLoss: 0.000000\n",
            "Train Epoch: 13 [27840/35339 (79%)]\tLoss: 0.000003\n",
            "Train Epoch: 13 [28160/35339 (80%)]\tLoss: 0.000049\n",
            "Train Epoch: 13 [28480/35339 (81%)]\tLoss: 0.000005\n",
            "Train Epoch: 13 [28800/35339 (81%)]\tLoss: 0.001807\n",
            "Train Epoch: 13 [29120/35339 (82%)]\tLoss: 0.000328\n",
            "Train Epoch: 13 [29440/35339 (83%)]\tLoss: 0.002419\n",
            "Train Epoch: 13 [29760/35339 (84%)]\tLoss: 0.000404\n",
            "Train Epoch: 13 [30080/35339 (85%)]\tLoss: 0.000001\n",
            "Train Epoch: 13 [30400/35339 (86%)]\tLoss: 0.010473\n",
            "Train Epoch: 13 [30720/35339 (87%)]\tLoss: 0.011410\n",
            "Train Epoch: 13 [31040/35339 (88%)]\tLoss: 0.073234\n",
            "Train Epoch: 13 [31360/35339 (89%)]\tLoss: 0.000096\n",
            "Train Epoch: 13 [31680/35339 (90%)]\tLoss: 0.138569\n",
            "Train Epoch: 13 [32000/35339 (90%)]\tLoss: 0.028642\n",
            "Train Epoch: 13 [32320/35339 (91%)]\tLoss: 0.002234\n",
            "Train Epoch: 13 [32640/35339 (92%)]\tLoss: 0.000010\n",
            "Train Epoch: 13 [32960/35339 (93%)]\tLoss: 0.000002\n",
            "Train Epoch: 13 [33280/35339 (94%)]\tLoss: 0.000001\n",
            "Train Epoch: 13 [33600/35339 (95%)]\tLoss: 0.027164\n",
            "Train Epoch: 13 [33920/35339 (96%)]\tLoss: 0.005384\n",
            "Train Epoch: 13 [34240/35339 (97%)]\tLoss: 0.000018\n",
            "Train Epoch: 13 [34560/35339 (98%)]\tLoss: 0.000036\n",
            "Train Epoch: 13 [34880/35339 (99%)]\tLoss: 0.010233\n",
            "Train Epoch: 13 [35200/35339 (100%)]\tLoss: 0.512081\n",
            "\n",
            "Validation set: Average loss: 0.2342, Accuracy: 3711/3870 (96%)\n",
            "\n",
            "\n",
            "Saved model to model_13.pth.\n",
            "Train Epoch: 14 [0/35339 (0%)]\tLoss: 0.000055\n",
            "Train Epoch: 14 [320/35339 (1%)]\tLoss: 0.002773\n",
            "Train Epoch: 14 [640/35339 (2%)]\tLoss: 0.000004\n",
            "Train Epoch: 14 [960/35339 (3%)]\tLoss: 0.000170\n",
            "Train Epoch: 14 [1280/35339 (4%)]\tLoss: 0.030054\n",
            "Train Epoch: 14 [1600/35339 (5%)]\tLoss: 0.000503\n",
            "Train Epoch: 14 [1920/35339 (5%)]\tLoss: 0.277135\n",
            "Train Epoch: 14 [2240/35339 (6%)]\tLoss: 0.000514\n",
            "Train Epoch: 14 [2560/35339 (7%)]\tLoss: 0.055303\n",
            "Train Epoch: 14 [2880/35339 (8%)]\tLoss: 0.012194\n",
            "Train Epoch: 14 [3200/35339 (9%)]\tLoss: 0.082240\n",
            "Train Epoch: 14 [3520/35339 (10%)]\tLoss: 0.009117\n",
            "Train Epoch: 14 [3840/35339 (11%)]\tLoss: 0.000023\n",
            "Train Epoch: 14 [4160/35339 (12%)]\tLoss: 0.014529\n",
            "Train Epoch: 14 [4480/35339 (13%)]\tLoss: 0.000036\n",
            "Train Epoch: 14 [4800/35339 (14%)]\tLoss: 0.002144\n",
            "Train Epoch: 14 [5120/35339 (14%)]\tLoss: 0.099539\n",
            "Train Epoch: 14 [5440/35339 (15%)]\tLoss: 0.000030\n",
            "Train Epoch: 14 [5760/35339 (16%)]\tLoss: 0.019877\n",
            "Train Epoch: 14 [6080/35339 (17%)]\tLoss: 0.000059\n",
            "Train Epoch: 14 [6400/35339 (18%)]\tLoss: 0.000001\n",
            "Train Epoch: 14 [6720/35339 (19%)]\tLoss: 0.088162\n",
            "Train Epoch: 14 [7040/35339 (20%)]\tLoss: 0.000001\n",
            "Train Epoch: 14 [7360/35339 (21%)]\tLoss: 0.000201\n",
            "Train Epoch: 14 [7680/35339 (22%)]\tLoss: 0.000103\n",
            "Train Epoch: 14 [8000/35339 (23%)]\tLoss: 0.000509\n",
            "Train Epoch: 14 [8320/35339 (24%)]\tLoss: 0.003593\n",
            "Train Epoch: 14 [8640/35339 (24%)]\tLoss: 0.015302\n",
            "Train Epoch: 14 [8960/35339 (25%)]\tLoss: 0.031165\n",
            "Train Epoch: 14 [9280/35339 (26%)]\tLoss: 0.000007\n",
            "Train Epoch: 14 [9600/35339 (27%)]\tLoss: 0.001572\n",
            "Train Epoch: 14 [9920/35339 (28%)]\tLoss: 0.000107\n",
            "Train Epoch: 14 [10240/35339 (29%)]\tLoss: 0.001996\n",
            "Train Epoch: 14 [10560/35339 (30%)]\tLoss: 0.011040\n",
            "Train Epoch: 14 [10880/35339 (31%)]\tLoss: 0.000587\n",
            "Train Epoch: 14 [11200/35339 (32%)]\tLoss: 0.005940\n",
            "Train Epoch: 14 [11520/35339 (33%)]\tLoss: 0.000003\n",
            "Train Epoch: 14 [11840/35339 (33%)]\tLoss: 0.054368\n",
            "Train Epoch: 14 [12160/35339 (34%)]\tLoss: 0.001175\n",
            "Train Epoch: 14 [12480/35339 (35%)]\tLoss: 0.069455\n",
            "Train Epoch: 14 [12800/35339 (36%)]\tLoss: 0.008286\n",
            "Train Epoch: 14 [13120/35339 (37%)]\tLoss: 0.111556\n",
            "Train Epoch: 14 [13440/35339 (38%)]\tLoss: 0.000002\n",
            "Train Epoch: 14 [13760/35339 (39%)]\tLoss: 0.000003\n",
            "Train Epoch: 14 [14080/35339 (40%)]\tLoss: 0.000052\n",
            "Train Epoch: 14 [14400/35339 (41%)]\tLoss: 0.000064\n",
            "Train Epoch: 14 [14720/35339 (42%)]\tLoss: 0.000029\n",
            "Train Epoch: 14 [15040/35339 (43%)]\tLoss: 0.000014\n",
            "Train Epoch: 14 [15360/35339 (43%)]\tLoss: 0.000001\n",
            "Train Epoch: 14 [15680/35339 (44%)]\tLoss: 0.000326\n",
            "Train Epoch: 14 [16000/35339 (45%)]\tLoss: 0.000011\n",
            "Train Epoch: 14 [16320/35339 (46%)]\tLoss: 0.007000\n",
            "Train Epoch: 14 [16640/35339 (47%)]\tLoss: 0.000058\n",
            "Train Epoch: 14 [16960/35339 (48%)]\tLoss: 0.000000\n",
            "Train Epoch: 14 [17280/35339 (49%)]\tLoss: 0.098363\n",
            "Train Epoch: 14 [17600/35339 (50%)]\tLoss: 0.013709\n",
            "Train Epoch: 14 [17920/35339 (51%)]\tLoss: 0.000003\n",
            "Train Epoch: 14 [18240/35339 (52%)]\tLoss: 0.018134\n",
            "Train Epoch: 14 [18560/35339 (52%)]\tLoss: 0.026118\n",
            "Train Epoch: 14 [18880/35339 (53%)]\tLoss: 0.000003\n",
            "Train Epoch: 14 [19200/35339 (54%)]\tLoss: 0.000002\n",
            "Train Epoch: 14 [19520/35339 (55%)]\tLoss: 0.000002\n",
            "Train Epoch: 14 [19840/35339 (56%)]\tLoss: 0.000022\n",
            "Train Epoch: 14 [20160/35339 (57%)]\tLoss: 0.000010\n",
            "Train Epoch: 14 [20480/35339 (58%)]\tLoss: 0.000004\n",
            "Train Epoch: 14 [20800/35339 (59%)]\tLoss: 0.000012\n",
            "Train Epoch: 14 [21120/35339 (60%)]\tLoss: 0.000540\n",
            "Train Epoch: 14 [21440/35339 (61%)]\tLoss: 0.000000\n",
            "Train Epoch: 14 [21760/35339 (62%)]\tLoss: 0.000035\n",
            "Train Epoch: 14 [22080/35339 (62%)]\tLoss: 0.000000\n",
            "Train Epoch: 14 [22400/35339 (63%)]\tLoss: 0.000000\n",
            "Train Epoch: 14 [22720/35339 (64%)]\tLoss: 0.006621\n",
            "Train Epoch: 14 [23040/35339 (65%)]\tLoss: 0.000001\n",
            "Train Epoch: 14 [23360/35339 (66%)]\tLoss: 0.000036\n",
            "Train Epoch: 14 [23680/35339 (67%)]\tLoss: 0.000018\n",
            "Train Epoch: 14 [24000/35339 (68%)]\tLoss: 0.018407\n",
            "Train Epoch: 14 [24320/35339 (69%)]\tLoss: 0.000441\n",
            "Train Epoch: 14 [24640/35339 (70%)]\tLoss: 0.000116\n",
            "Train Epoch: 14 [24960/35339 (71%)]\tLoss: 0.000464\n",
            "Train Epoch: 14 [25280/35339 (71%)]\tLoss: 0.003415\n",
            "Train Epoch: 14 [25600/35339 (72%)]\tLoss: 0.000001\n",
            "Train Epoch: 14 [25920/35339 (73%)]\tLoss: 0.020646\n",
            "Train Epoch: 14 [26240/35339 (74%)]\tLoss: 0.367200\n",
            "Train Epoch: 14 [26560/35339 (75%)]\tLoss: 0.003601\n",
            "Train Epoch: 14 [26880/35339 (76%)]\tLoss: 0.062142\n",
            "Train Epoch: 14 [27200/35339 (77%)]\tLoss: 0.087055\n",
            "Train Epoch: 14 [27520/35339 (78%)]\tLoss: 0.539667\n",
            "Train Epoch: 14 [27840/35339 (79%)]\tLoss: 0.001406\n",
            "Train Epoch: 14 [28160/35339 (80%)]\tLoss: 0.000028\n",
            "Train Epoch: 14 [28480/35339 (81%)]\tLoss: 0.143939\n",
            "Train Epoch: 14 [28800/35339 (81%)]\tLoss: 0.000018\n",
            "Train Epoch: 14 [29120/35339 (82%)]\tLoss: 0.167443\n",
            "Train Epoch: 14 [29440/35339 (83%)]\tLoss: 0.000080\n",
            "Train Epoch: 14 [29760/35339 (84%)]\tLoss: 0.001165\n",
            "Train Epoch: 14 [30080/35339 (85%)]\tLoss: 0.012960\n",
            "Train Epoch: 14 [30400/35339 (86%)]\tLoss: 0.000000\n",
            "Train Epoch: 14 [30720/35339 (87%)]\tLoss: 0.001935\n",
            "Train Epoch: 14 [31040/35339 (88%)]\tLoss: 0.013295\n",
            "Train Epoch: 14 [31360/35339 (89%)]\tLoss: 0.000456\n",
            "Train Epoch: 14 [31680/35339 (90%)]\tLoss: 0.000000\n",
            "Train Epoch: 14 [32000/35339 (90%)]\tLoss: 0.051311\n",
            "Train Epoch: 14 [32320/35339 (91%)]\tLoss: 0.000217\n",
            "Train Epoch: 14 [32640/35339 (92%)]\tLoss: 0.002159\n",
            "Train Epoch: 14 [32960/35339 (93%)]\tLoss: 0.000964\n",
            "Train Epoch: 14 [33280/35339 (94%)]\tLoss: 0.000006\n",
            "Train Epoch: 14 [33600/35339 (95%)]\tLoss: 0.000002\n",
            "Train Epoch: 14 [33920/35339 (96%)]\tLoss: 0.000079\n",
            "Train Epoch: 14 [34240/35339 (97%)]\tLoss: 0.015105\n",
            "Train Epoch: 14 [34560/35339 (98%)]\tLoss: 0.000031\n",
            "Train Epoch: 14 [34880/35339 (99%)]\tLoss: 0.000002\n",
            "Train Epoch: 14 [35200/35339 (100%)]\tLoss: 0.000000\n",
            "\n",
            "Validation set: Average loss: 0.1500, Accuracy: 3754/3870 (97%)\n",
            "\n",
            "\n",
            "Saved model to model_14.pth.\n",
            "Train Epoch: 15 [0/35339 (0%)]\tLoss: 0.000823\n",
            "Train Epoch: 15 [320/35339 (1%)]\tLoss: 0.000665\n",
            "Train Epoch: 15 [640/35339 (2%)]\tLoss: 0.001977\n",
            "Train Epoch: 15 [960/35339 (3%)]\tLoss: 0.000639\n",
            "Train Epoch: 15 [1280/35339 (4%)]\tLoss: 0.000005\n",
            "Train Epoch: 15 [1600/35339 (5%)]\tLoss: 0.002985\n",
            "Train Epoch: 15 [1920/35339 (5%)]\tLoss: 0.000035\n",
            "Train Epoch: 15 [2240/35339 (6%)]\tLoss: 0.000004\n",
            "Train Epoch: 15 [2560/35339 (7%)]\tLoss: 0.000001\n",
            "Train Epoch: 15 [2880/35339 (8%)]\tLoss: 0.000080\n",
            "Train Epoch: 15 [3200/35339 (9%)]\tLoss: 0.000001\n",
            "Train Epoch: 15 [3520/35339 (10%)]\tLoss: 0.022693\n",
            "Train Epoch: 15 [3840/35339 (11%)]\tLoss: 0.000003\n",
            "Train Epoch: 15 [4160/35339 (12%)]\tLoss: 0.143135\n",
            "Train Epoch: 15 [4480/35339 (13%)]\tLoss: 0.000113\n",
            "Train Epoch: 15 [4800/35339 (14%)]\tLoss: 0.000001\n",
            "Train Epoch: 15 [5120/35339 (14%)]\tLoss: 0.000374\n",
            "Train Epoch: 15 [5440/35339 (15%)]\tLoss: 0.017985\n",
            "Train Epoch: 15 [5760/35339 (16%)]\tLoss: 0.012442\n",
            "Train Epoch: 15 [6080/35339 (17%)]\tLoss: 0.000034\n",
            "Train Epoch: 15 [6400/35339 (18%)]\tLoss: 0.000007\n",
            "Train Epoch: 15 [6720/35339 (19%)]\tLoss: 0.000000\n",
            "Train Epoch: 15 [7040/35339 (20%)]\tLoss: 0.000051\n",
            "Train Epoch: 15 [7360/35339 (21%)]\tLoss: 0.000994\n",
            "Train Epoch: 15 [7680/35339 (22%)]\tLoss: 0.000108\n",
            "Train Epoch: 15 [8000/35339 (23%)]\tLoss: 0.000000\n",
            "Train Epoch: 15 [8320/35339 (24%)]\tLoss: 0.000000\n",
            "Train Epoch: 15 [8640/35339 (24%)]\tLoss: 0.000048\n",
            "Train Epoch: 15 [8960/35339 (25%)]\tLoss: 0.000001\n",
            "Train Epoch: 15 [9280/35339 (26%)]\tLoss: 0.000026\n",
            "Train Epoch: 15 [9600/35339 (27%)]\tLoss: 0.000000\n",
            "Train Epoch: 15 [9920/35339 (28%)]\tLoss: 0.003468\n",
            "Train Epoch: 15 [10240/35339 (29%)]\tLoss: 0.000009\n",
            "Train Epoch: 15 [10560/35339 (30%)]\tLoss: 0.000000\n",
            "Train Epoch: 15 [10880/35339 (31%)]\tLoss: 0.000002\n",
            "Train Epoch: 15 [11200/35339 (32%)]\tLoss: 0.026902\n",
            "Train Epoch: 15 [11520/35339 (33%)]\tLoss: 0.000001\n",
            "Train Epoch: 15 [11840/35339 (33%)]\tLoss: 0.000131\n",
            "Train Epoch: 15 [12160/35339 (34%)]\tLoss: 0.000002\n",
            "Train Epoch: 15 [12480/35339 (35%)]\tLoss: 0.007442\n",
            "Train Epoch: 15 [12800/35339 (36%)]\tLoss: 0.000053\n",
            "Train Epoch: 15 [13120/35339 (37%)]\tLoss: 0.000005\n",
            "Train Epoch: 15 [13440/35339 (38%)]\tLoss: 0.001072\n",
            "Train Epoch: 15 [13760/35339 (39%)]\tLoss: 0.000015\n",
            "Train Epoch: 15 [14080/35339 (40%)]\tLoss: 0.000123\n",
            "Train Epoch: 15 [14400/35339 (41%)]\tLoss: 0.002616\n",
            "Train Epoch: 15 [14720/35339 (42%)]\tLoss: 0.004308\n",
            "Train Epoch: 15 [15040/35339 (43%)]\tLoss: 0.000002\n",
            "Train Epoch: 15 [15360/35339 (43%)]\tLoss: 0.000001\n",
            "Train Epoch: 15 [15680/35339 (44%)]\tLoss: 0.000040\n",
            "Train Epoch: 15 [16000/35339 (45%)]\tLoss: 0.000019\n",
            "Train Epoch: 15 [16320/35339 (46%)]\tLoss: 0.000432\n",
            "Train Epoch: 15 [16640/35339 (47%)]\tLoss: 0.000014\n",
            "Train Epoch: 15 [16960/35339 (48%)]\tLoss: 0.000450\n",
            "Train Epoch: 15 [17280/35339 (49%)]\tLoss: 0.000074\n",
            "Train Epoch: 15 [17600/35339 (50%)]\tLoss: 0.000000\n",
            "Train Epoch: 15 [17920/35339 (51%)]\tLoss: 0.004344\n",
            "Train Epoch: 15 [18240/35339 (52%)]\tLoss: 0.000003\n",
            "Train Epoch: 15 [18560/35339 (52%)]\tLoss: 0.174970\n",
            "Train Epoch: 15 [18880/35339 (53%)]\tLoss: 0.000017\n",
            "Train Epoch: 15 [19200/35339 (54%)]\tLoss: 0.002524\n",
            "Train Epoch: 15 [19520/35339 (55%)]\tLoss: 0.026769\n",
            "Train Epoch: 15 [19840/35339 (56%)]\tLoss: 0.002091\n",
            "Train Epoch: 15 [20160/35339 (57%)]\tLoss: 0.000221\n",
            "Train Epoch: 15 [20480/35339 (58%)]\tLoss: 0.014324\n",
            "Train Epoch: 15 [20800/35339 (59%)]\tLoss: 0.000289\n",
            "Train Epoch: 15 [21120/35339 (60%)]\tLoss: 0.000004\n",
            "Train Epoch: 15 [21440/35339 (61%)]\tLoss: 0.005119\n",
            "Train Epoch: 15 [21760/35339 (62%)]\tLoss: 0.000015\n",
            "Train Epoch: 15 [22080/35339 (62%)]\tLoss: 0.000015\n",
            "Train Epoch: 15 [22400/35339 (63%)]\tLoss: 0.000229\n",
            "Train Epoch: 15 [22720/35339 (64%)]\tLoss: 0.000049\n",
            "Train Epoch: 15 [23040/35339 (65%)]\tLoss: 0.003700\n",
            "Train Epoch: 15 [23360/35339 (66%)]\tLoss: 0.000023\n",
            "Train Epoch: 15 [23680/35339 (67%)]\tLoss: 0.000088\n",
            "Train Epoch: 15 [24000/35339 (68%)]\tLoss: 0.000066\n",
            "Train Epoch: 15 [24320/35339 (69%)]\tLoss: 0.000003\n",
            "Train Epoch: 15 [24640/35339 (70%)]\tLoss: 0.000088\n",
            "Train Epoch: 15 [24960/35339 (71%)]\tLoss: 0.007096\n",
            "Train Epoch: 15 [25280/35339 (71%)]\tLoss: 0.000936\n",
            "Train Epoch: 15 [25600/35339 (72%)]\tLoss: 0.000607\n",
            "Train Epoch: 15 [25920/35339 (73%)]\tLoss: 0.000005\n",
            "Train Epoch: 15 [26240/35339 (74%)]\tLoss: 0.000247\n",
            "Train Epoch: 15 [26560/35339 (75%)]\tLoss: 0.001492\n",
            "Train Epoch: 15 [26880/35339 (76%)]\tLoss: 0.002036\n",
            "Train Epoch: 15 [27200/35339 (77%)]\tLoss: 0.002156\n",
            "Train Epoch: 15 [27520/35339 (78%)]\tLoss: 0.000033\n",
            "Train Epoch: 15 [27840/35339 (79%)]\tLoss: 0.000143\n",
            "Train Epoch: 15 [28160/35339 (80%)]\tLoss: 0.000000\n",
            "Train Epoch: 15 [28480/35339 (81%)]\tLoss: 0.000075\n",
            "Train Epoch: 15 [28800/35339 (81%)]\tLoss: 0.000100\n",
            "Train Epoch: 15 [29120/35339 (82%)]\tLoss: 0.000686\n",
            "Train Epoch: 15 [29440/35339 (83%)]\tLoss: 0.001035\n",
            "Train Epoch: 15 [29760/35339 (84%)]\tLoss: 0.000013\n",
            "Train Epoch: 15 [30080/35339 (85%)]\tLoss: 0.003638\n",
            "Train Epoch: 15 [30400/35339 (86%)]\tLoss: 0.000056\n",
            "Train Epoch: 15 [30720/35339 (87%)]\tLoss: 0.000053\n",
            "Train Epoch: 15 [31040/35339 (88%)]\tLoss: 0.002681\n",
            "Train Epoch: 15 [31360/35339 (89%)]\tLoss: 0.000565\n",
            "Train Epoch: 15 [31680/35339 (90%)]\tLoss: 0.000427\n",
            "Train Epoch: 15 [32000/35339 (90%)]\tLoss: 0.000006\n",
            "Train Epoch: 15 [32320/35339 (91%)]\tLoss: 0.000003\n",
            "Train Epoch: 15 [32640/35339 (92%)]\tLoss: 0.107436\n",
            "Train Epoch: 15 [32960/35339 (93%)]\tLoss: 0.000001\n",
            "Train Epoch: 15 [33280/35339 (94%)]\tLoss: 0.000229\n",
            "Train Epoch: 15 [33600/35339 (95%)]\tLoss: 0.000127\n",
            "Train Epoch: 15 [33920/35339 (96%)]\tLoss: 0.000004\n",
            "Train Epoch: 15 [34240/35339 (97%)]\tLoss: 0.000153\n",
            "Train Epoch: 15 [34560/35339 (98%)]\tLoss: 0.011171\n",
            "Train Epoch: 15 [34880/35339 (99%)]\tLoss: 0.000000\n",
            "Train Epoch: 15 [35200/35339 (100%)]\tLoss: 0.000241\n",
            "\n",
            "Validation set: Average loss: 0.1260, Accuracy: 3784/3870 (98%)\n",
            "\n",
            "\n",
            "Saved model to model_15.pth.\n",
            "Train Epoch: 16 [0/35339 (0%)]\tLoss: 0.000976\n",
            "Train Epoch: 16 [320/35339 (1%)]\tLoss: 0.188549\n",
            "Train Epoch: 16 [640/35339 (2%)]\tLoss: 0.004368\n",
            "Train Epoch: 16 [960/35339 (3%)]\tLoss: 0.000001\n",
            "Train Epoch: 16 [1280/35339 (4%)]\tLoss: 0.069267\n",
            "Train Epoch: 16 [1600/35339 (5%)]\tLoss: 0.015436\n",
            "Train Epoch: 16 [1920/35339 (5%)]\tLoss: 0.004585\n",
            "Train Epoch: 16 [2240/35339 (6%)]\tLoss: 0.000469\n",
            "Train Epoch: 16 [2560/35339 (7%)]\tLoss: 0.000026\n",
            "Train Epoch: 16 [2880/35339 (8%)]\tLoss: 0.064119\n",
            "Train Epoch: 16 [3200/35339 (9%)]\tLoss: 0.000087\n",
            "Train Epoch: 16 [3520/35339 (10%)]\tLoss: 0.080318\n",
            "Train Epoch: 16 [3840/35339 (11%)]\tLoss: 0.001777\n",
            "Train Epoch: 16 [4160/35339 (12%)]\tLoss: 0.000046\n",
            "Train Epoch: 16 [4480/35339 (13%)]\tLoss: 0.001222\n",
            "Train Epoch: 16 [4800/35339 (14%)]\tLoss: 0.000202\n",
            "Train Epoch: 16 [5120/35339 (14%)]\tLoss: 0.000014\n",
            "Train Epoch: 16 [5440/35339 (15%)]\tLoss: 0.000458\n",
            "Train Epoch: 16 [5760/35339 (16%)]\tLoss: 0.000000\n",
            "Train Epoch: 16 [6080/35339 (17%)]\tLoss: 0.000011\n",
            "Train Epoch: 16 [6400/35339 (18%)]\tLoss: 0.000032\n",
            "Train Epoch: 16 [6720/35339 (19%)]\tLoss: 0.000120\n",
            "Train Epoch: 16 [7040/35339 (20%)]\tLoss: 0.009704\n",
            "Train Epoch: 16 [7360/35339 (21%)]\tLoss: 0.000015\n",
            "Train Epoch: 16 [7680/35339 (22%)]\tLoss: 0.006047\n",
            "Train Epoch: 16 [8000/35339 (23%)]\tLoss: 0.005022\n",
            "Train Epoch: 16 [8320/35339 (24%)]\tLoss: 0.000014\n",
            "Train Epoch: 16 [8640/35339 (24%)]\tLoss: 0.000062\n",
            "Train Epoch: 16 [8960/35339 (25%)]\tLoss: 0.000062\n",
            "Train Epoch: 16 [9280/35339 (26%)]\tLoss: 0.000414\n",
            "Train Epoch: 16 [9600/35339 (27%)]\tLoss: 0.001194\n",
            "Train Epoch: 16 [9920/35339 (28%)]\tLoss: 0.019223\n",
            "Train Epoch: 16 [10240/35339 (29%)]\tLoss: 0.000044\n",
            "Train Epoch: 16 [10560/35339 (30%)]\tLoss: 0.000561\n",
            "Train Epoch: 16 [10880/35339 (31%)]\tLoss: 0.000010\n",
            "Train Epoch: 16 [11200/35339 (32%)]\tLoss: 0.000722\n",
            "Train Epoch: 16 [11520/35339 (33%)]\tLoss: 0.045132\n",
            "Train Epoch: 16 [11840/35339 (33%)]\tLoss: 0.001582\n",
            "Train Epoch: 16 [12160/35339 (34%)]\tLoss: 0.000002\n",
            "Train Epoch: 16 [12480/35339 (35%)]\tLoss: 0.000414\n",
            "Train Epoch: 16 [12800/35339 (36%)]\tLoss: 0.000008\n",
            "Train Epoch: 16 [13120/35339 (37%)]\tLoss: 0.006780\n",
            "Train Epoch: 16 [13440/35339 (38%)]\tLoss: 0.000001\n",
            "Train Epoch: 16 [13760/35339 (39%)]\tLoss: 0.003317\n",
            "Train Epoch: 16 [14080/35339 (40%)]\tLoss: 0.031599\n",
            "Train Epoch: 16 [14400/35339 (41%)]\tLoss: 0.021567\n",
            "Train Epoch: 16 [14720/35339 (42%)]\tLoss: 0.000030\n",
            "Train Epoch: 16 [15040/35339 (43%)]\tLoss: 0.002518\n",
            "Train Epoch: 16 [15360/35339 (43%)]\tLoss: 0.000000\n",
            "Train Epoch: 16 [15680/35339 (44%)]\tLoss: 0.000079\n",
            "Train Epoch: 16 [16000/35339 (45%)]\tLoss: 0.000000\n",
            "Train Epoch: 16 [16320/35339 (46%)]\tLoss: 0.000825\n",
            "Train Epoch: 16 [16640/35339 (47%)]\tLoss: 0.310415\n",
            "Train Epoch: 16 [16960/35339 (48%)]\tLoss: 0.370714\n",
            "Train Epoch: 16 [17280/35339 (49%)]\tLoss: 0.000002\n",
            "Train Epoch: 16 [17600/35339 (50%)]\tLoss: 0.000042\n",
            "Train Epoch: 16 [17920/35339 (51%)]\tLoss: 0.000010\n",
            "Train Epoch: 16 [18240/35339 (52%)]\tLoss: 0.021651\n",
            "Train Epoch: 16 [18560/35339 (52%)]\tLoss: 0.000001\n",
            "Train Epoch: 16 [18880/35339 (53%)]\tLoss: 0.000442\n",
            "Train Epoch: 16 [19200/35339 (54%)]\tLoss: 0.001855\n",
            "Train Epoch: 16 [19520/35339 (55%)]\tLoss: 0.004962\n",
            "Train Epoch: 16 [19840/35339 (56%)]\tLoss: 0.000035\n",
            "Train Epoch: 16 [20160/35339 (57%)]\tLoss: 0.000019\n",
            "Train Epoch: 16 [20480/35339 (58%)]\tLoss: 0.009301\n",
            "Train Epoch: 16 [20800/35339 (59%)]\tLoss: 0.000020\n",
            "Train Epoch: 16 [21120/35339 (60%)]\tLoss: 0.000013\n",
            "Train Epoch: 16 [21440/35339 (61%)]\tLoss: 0.000001\n",
            "Train Epoch: 16 [21760/35339 (62%)]\tLoss: 0.001758\n",
            "Train Epoch: 16 [22080/35339 (62%)]\tLoss: 0.000000\n",
            "Train Epoch: 16 [22400/35339 (63%)]\tLoss: 0.018603\n",
            "Train Epoch: 16 [22720/35339 (64%)]\tLoss: 0.000197\n",
            "Train Epoch: 16 [23040/35339 (65%)]\tLoss: 0.000000\n",
            "Train Epoch: 16 [23360/35339 (66%)]\tLoss: 0.000010\n",
            "Train Epoch: 16 [23680/35339 (67%)]\tLoss: 0.000000\n",
            "Train Epoch: 16 [24000/35339 (68%)]\tLoss: 0.001962\n",
            "Train Epoch: 16 [24320/35339 (69%)]\tLoss: 0.015302\n",
            "Train Epoch: 16 [24640/35339 (70%)]\tLoss: 0.000000\n",
            "Train Epoch: 16 [24960/35339 (71%)]\tLoss: 0.000003\n",
            "Train Epoch: 16 [25280/35339 (71%)]\tLoss: 0.009290\n",
            "Train Epoch: 16 [25600/35339 (72%)]\tLoss: 0.000011\n",
            "Train Epoch: 16 [25920/35339 (73%)]\tLoss: 0.000116\n",
            "Train Epoch: 16 [26240/35339 (74%)]\tLoss: 0.000001\n",
            "Train Epoch: 16 [26560/35339 (75%)]\tLoss: 0.000026\n",
            "Train Epoch: 16 [26880/35339 (76%)]\tLoss: 0.093684\n",
            "Train Epoch: 16 [27200/35339 (77%)]\tLoss: 0.000000\n",
            "Train Epoch: 16 [27520/35339 (78%)]\tLoss: 0.000001\n",
            "Train Epoch: 16 [27840/35339 (79%)]\tLoss: 0.028661\n",
            "Train Epoch: 16 [28160/35339 (80%)]\tLoss: 0.064556\n",
            "Train Epoch: 16 [28480/35339 (81%)]\tLoss: 0.000285\n",
            "Train Epoch: 16 [28800/35339 (81%)]\tLoss: 0.002279\n",
            "Train Epoch: 16 [29120/35339 (82%)]\tLoss: 0.000001\n",
            "Train Epoch: 16 [29440/35339 (83%)]\tLoss: 0.000042\n",
            "Train Epoch: 16 [29760/35339 (84%)]\tLoss: 0.006433\n",
            "Train Epoch: 16 [30080/35339 (85%)]\tLoss: 0.000004\n",
            "Train Epoch: 16 [30400/35339 (86%)]\tLoss: 0.000371\n",
            "Train Epoch: 16 [30720/35339 (87%)]\tLoss: 0.076885\n",
            "Train Epoch: 16 [31040/35339 (88%)]\tLoss: 0.001497\n",
            "Train Epoch: 16 [31360/35339 (89%)]\tLoss: 0.002086\n",
            "Train Epoch: 16 [31680/35339 (90%)]\tLoss: 0.000074\n",
            "Train Epoch: 16 [32000/35339 (90%)]\tLoss: 0.000004\n",
            "Train Epoch: 16 [32320/35339 (91%)]\tLoss: 0.000200\n",
            "Train Epoch: 16 [32640/35339 (92%)]\tLoss: 0.001301\n",
            "Train Epoch: 16 [32960/35339 (93%)]\tLoss: 0.000264\n",
            "Train Epoch: 16 [33280/35339 (94%)]\tLoss: 0.000001\n",
            "Train Epoch: 16 [33600/35339 (95%)]\tLoss: 0.000005\n",
            "Train Epoch: 16 [33920/35339 (96%)]\tLoss: 0.008179\n",
            "Train Epoch: 16 [34240/35339 (97%)]\tLoss: 0.000001\n",
            "Train Epoch: 16 [34560/35339 (98%)]\tLoss: 0.001243\n",
            "Train Epoch: 16 [34880/35339 (99%)]\tLoss: 0.000013\n",
            "Train Epoch: 16 [35200/35339 (100%)]\tLoss: 0.000078\n",
            "\n",
            "Validation set: Average loss: 0.1770, Accuracy: 3769/3870 (97%)\n",
            "\n",
            "\n",
            "Saved model to model_16.pth.\n",
            "Train Epoch: 17 [0/35339 (0%)]\tLoss: 0.004234\n",
            "Train Epoch: 17 [320/35339 (1%)]\tLoss: 0.337651\n",
            "Train Epoch: 17 [640/35339 (2%)]\tLoss: 0.103537\n",
            "Train Epoch: 17 [960/35339 (3%)]\tLoss: 0.000003\n",
            "Train Epoch: 17 [1280/35339 (4%)]\tLoss: 0.002326\n",
            "Train Epoch: 17 [1600/35339 (5%)]\tLoss: 0.002149\n",
            "Train Epoch: 17 [1920/35339 (5%)]\tLoss: 0.000026\n",
            "Train Epoch: 17 [2240/35339 (6%)]\tLoss: 0.000062\n",
            "Train Epoch: 17 [2560/35339 (7%)]\tLoss: 0.000002\n",
            "Train Epoch: 17 [2880/35339 (8%)]\tLoss: 0.000078\n",
            "Train Epoch: 17 [3200/35339 (9%)]\tLoss: 0.042176\n",
            "Train Epoch: 17 [3520/35339 (10%)]\tLoss: 0.000145\n",
            "Train Epoch: 17 [3840/35339 (11%)]\tLoss: 0.000308\n",
            "Train Epoch: 17 [4160/35339 (12%)]\tLoss: 0.000378\n",
            "Train Epoch: 17 [4480/35339 (13%)]\tLoss: 0.000005\n",
            "Train Epoch: 17 [4800/35339 (14%)]\tLoss: 0.002178\n",
            "Train Epoch: 17 [5120/35339 (14%)]\tLoss: 0.000001\n",
            "Train Epoch: 17 [5440/35339 (15%)]\tLoss: 0.000009\n",
            "Train Epoch: 17 [5760/35339 (16%)]\tLoss: 0.000004\n",
            "Train Epoch: 17 [6080/35339 (17%)]\tLoss: 0.000000\n",
            "Train Epoch: 17 [6400/35339 (18%)]\tLoss: 0.071216\n",
            "Train Epoch: 17 [6720/35339 (19%)]\tLoss: 0.000097\n",
            "Train Epoch: 17 [7040/35339 (20%)]\tLoss: 0.000001\n",
            "Train Epoch: 17 [7360/35339 (21%)]\tLoss: 0.028079\n",
            "Train Epoch: 17 [7680/35339 (22%)]\tLoss: 0.000149\n",
            "Train Epoch: 17 [8000/35339 (23%)]\tLoss: 0.000014\n",
            "Train Epoch: 17 [8320/35339 (24%)]\tLoss: 0.000559\n",
            "Train Epoch: 17 [8640/35339 (24%)]\tLoss: 0.112016\n",
            "Train Epoch: 17 [8960/35339 (25%)]\tLoss: 0.005333\n",
            "Train Epoch: 17 [9280/35339 (26%)]\tLoss: 0.000000\n",
            "Train Epoch: 17 [9600/35339 (27%)]\tLoss: 0.000002\n",
            "Train Epoch: 17 [9920/35339 (28%)]\tLoss: 0.026306\n",
            "Train Epoch: 17 [10240/35339 (29%)]\tLoss: 0.056110\n",
            "Train Epoch: 17 [10560/35339 (30%)]\tLoss: 0.000058\n",
            "Train Epoch: 17 [10880/35339 (31%)]\tLoss: 0.001147\n",
            "Train Epoch: 17 [11200/35339 (32%)]\tLoss: 0.010168\n",
            "Train Epoch: 17 [11520/35339 (33%)]\tLoss: 0.000030\n",
            "Train Epoch: 17 [11840/35339 (33%)]\tLoss: 0.000159\n",
            "Train Epoch: 17 [12160/35339 (34%)]\tLoss: 0.000013\n",
            "Train Epoch: 17 [12480/35339 (35%)]\tLoss: 0.000642\n",
            "Train Epoch: 17 [12800/35339 (36%)]\tLoss: 0.000021\n",
            "Train Epoch: 17 [13120/35339 (37%)]\tLoss: 0.000006\n",
            "Train Epoch: 17 [13440/35339 (38%)]\tLoss: 0.003341\n",
            "Train Epoch: 17 [13760/35339 (39%)]\tLoss: 0.001709\n",
            "Train Epoch: 17 [14080/35339 (40%)]\tLoss: 0.000023\n",
            "Train Epoch: 17 [14400/35339 (41%)]\tLoss: 0.126995\n",
            "Train Epoch: 17 [14720/35339 (42%)]\tLoss: 0.071717\n",
            "Train Epoch: 17 [15040/35339 (43%)]\tLoss: 0.000000\n",
            "Train Epoch: 17 [15360/35339 (43%)]\tLoss: 0.006347\n",
            "Train Epoch: 17 [15680/35339 (44%)]\tLoss: 0.083150\n",
            "Train Epoch: 17 [16000/35339 (45%)]\tLoss: 0.113333\n",
            "Train Epoch: 17 [16320/35339 (46%)]\tLoss: 0.000905\n",
            "Train Epoch: 17 [16640/35339 (47%)]\tLoss: 0.000003\n",
            "Train Epoch: 17 [16960/35339 (48%)]\tLoss: 0.039635\n",
            "Train Epoch: 17 [17280/35339 (49%)]\tLoss: 0.000006\n",
            "Train Epoch: 17 [17600/35339 (50%)]\tLoss: 0.000827\n",
            "Train Epoch: 17 [17920/35339 (51%)]\tLoss: 0.000025\n",
            "Train Epoch: 17 [18240/35339 (52%)]\tLoss: 0.000001\n",
            "Train Epoch: 17 [18560/35339 (52%)]\tLoss: 0.000001\n",
            "Train Epoch: 17 [18880/35339 (53%)]\tLoss: 0.000000\n",
            "Train Epoch: 17 [19200/35339 (54%)]\tLoss: 0.000000\n",
            "Train Epoch: 17 [19520/35339 (55%)]\tLoss: 0.003525\n",
            "Train Epoch: 17 [19840/35339 (56%)]\tLoss: 0.000782\n",
            "Train Epoch: 17 [20160/35339 (57%)]\tLoss: 0.000095\n",
            "Train Epoch: 17 [20480/35339 (58%)]\tLoss: 0.000018\n",
            "Train Epoch: 17 [20800/35339 (59%)]\tLoss: 0.000001\n",
            "Train Epoch: 17 [21120/35339 (60%)]\tLoss: 0.000539\n",
            "Train Epoch: 17 [21440/35339 (61%)]\tLoss: 0.000002\n",
            "Train Epoch: 17 [21760/35339 (62%)]\tLoss: 0.000909\n",
            "Train Epoch: 17 [22080/35339 (62%)]\tLoss: 0.000000\n",
            "Train Epoch: 17 [22400/35339 (63%)]\tLoss: 0.000043\n",
            "Train Epoch: 17 [22720/35339 (64%)]\tLoss: 0.000156\n",
            "Train Epoch: 17 [23040/35339 (65%)]\tLoss: 0.000019\n",
            "Train Epoch: 17 [23360/35339 (66%)]\tLoss: 0.000000\n",
            "Train Epoch: 17 [23680/35339 (67%)]\tLoss: 0.000022\n",
            "Train Epoch: 17 [24000/35339 (68%)]\tLoss: 0.000140\n",
            "Train Epoch: 17 [24320/35339 (69%)]\tLoss: 0.002363\n",
            "Train Epoch: 17 [24640/35339 (70%)]\tLoss: 0.134535\n",
            "Train Epoch: 17 [24960/35339 (71%)]\tLoss: 0.000003\n",
            "Train Epoch: 17 [25280/35339 (71%)]\tLoss: 0.000305\n",
            "Train Epoch: 17 [25600/35339 (72%)]\tLoss: 0.020951\n",
            "Train Epoch: 17 [25920/35339 (73%)]\tLoss: 0.000000\n",
            "Train Epoch: 17 [26240/35339 (74%)]\tLoss: 0.000008\n",
            "Train Epoch: 17 [26560/35339 (75%)]\tLoss: 0.000006\n",
            "Train Epoch: 17 [26880/35339 (76%)]\tLoss: 0.000173\n",
            "Train Epoch: 17 [27200/35339 (77%)]\tLoss: 0.000117\n",
            "Train Epoch: 17 [27520/35339 (78%)]\tLoss: 0.000000\n",
            "Train Epoch: 17 [27840/35339 (79%)]\tLoss: 0.000002\n",
            "Train Epoch: 17 [28160/35339 (80%)]\tLoss: 0.000127\n",
            "Train Epoch: 17 [28480/35339 (81%)]\tLoss: 0.000001\n",
            "Train Epoch: 17 [28800/35339 (81%)]\tLoss: 0.000002\n",
            "Train Epoch: 17 [29120/35339 (82%)]\tLoss: 0.000004\n",
            "Train Epoch: 17 [29440/35339 (83%)]\tLoss: 0.000511\n",
            "Train Epoch: 17 [29760/35339 (84%)]\tLoss: 0.000055\n",
            "Train Epoch: 17 [30080/35339 (85%)]\tLoss: 0.139894\n",
            "Train Epoch: 17 [30400/35339 (86%)]\tLoss: 0.007194\n",
            "Train Epoch: 17 [30720/35339 (87%)]\tLoss: 0.000007\n",
            "Train Epoch: 17 [31040/35339 (88%)]\tLoss: 0.000228\n",
            "Train Epoch: 17 [31360/35339 (89%)]\tLoss: 0.000029\n",
            "Train Epoch: 17 [31680/35339 (90%)]\tLoss: 0.021296\n",
            "Train Epoch: 17 [32000/35339 (90%)]\tLoss: 0.012545\n",
            "Train Epoch: 17 [32320/35339 (91%)]\tLoss: 0.000006\n",
            "Train Epoch: 17 [32640/35339 (92%)]\tLoss: 0.117474\n",
            "Train Epoch: 17 [32960/35339 (93%)]\tLoss: 0.000026\n",
            "Train Epoch: 17 [33280/35339 (94%)]\tLoss: 0.000025\n",
            "Train Epoch: 17 [33600/35339 (95%)]\tLoss: 0.006502\n",
            "Train Epoch: 17 [33920/35339 (96%)]\tLoss: 0.000140\n",
            "Train Epoch: 17 [34240/35339 (97%)]\tLoss: 0.000680\n",
            "Train Epoch: 17 [34560/35339 (98%)]\tLoss: 0.000001\n",
            "Train Epoch: 17 [34880/35339 (99%)]\tLoss: 0.004011\n",
            "Train Epoch: 17 [35200/35339 (100%)]\tLoss: 0.000001\n",
            "\n",
            "Validation set: Average loss: 0.1248, Accuracy: 3797/3870 (98%)\n",
            "\n",
            "\n",
            "Saved model to model_17.pth.\n",
            "Train Epoch: 18 [0/35339 (0%)]\tLoss: 0.004803\n",
            "Train Epoch: 18 [320/35339 (1%)]\tLoss: 0.000049\n",
            "Train Epoch: 18 [640/35339 (2%)]\tLoss: 0.003722\n",
            "Train Epoch: 18 [960/35339 (3%)]\tLoss: 0.000220\n",
            "Train Epoch: 18 [1280/35339 (4%)]\tLoss: 0.000033\n",
            "Train Epoch: 18 [1600/35339 (5%)]\tLoss: 0.000965\n",
            "Train Epoch: 18 [1920/35339 (5%)]\tLoss: 0.040848\n",
            "Train Epoch: 18 [2240/35339 (6%)]\tLoss: 0.000001\n",
            "Train Epoch: 18 [2560/35339 (7%)]\tLoss: 0.000000\n",
            "Train Epoch: 18 [2880/35339 (8%)]\tLoss: 0.053500\n",
            "Train Epoch: 18 [3200/35339 (9%)]\tLoss: 0.000196\n",
            "Train Epoch: 18 [3520/35339 (10%)]\tLoss: 0.000582\n",
            "Train Epoch: 18 [3840/35339 (11%)]\tLoss: 0.000015\n",
            "Train Epoch: 18 [4160/35339 (12%)]\tLoss: 0.000026\n",
            "Train Epoch: 18 [4480/35339 (13%)]\tLoss: 0.000055\n",
            "Train Epoch: 18 [4800/35339 (14%)]\tLoss: 0.000000\n",
            "Train Epoch: 18 [5120/35339 (14%)]\tLoss: 0.000002\n",
            "Train Epoch: 18 [5440/35339 (15%)]\tLoss: 0.001774\n",
            "Train Epoch: 18 [5760/35339 (16%)]\tLoss: 0.000402\n",
            "Train Epoch: 18 [6080/35339 (17%)]\tLoss: 0.004854\n",
            "Train Epoch: 18 [6400/35339 (18%)]\tLoss: 0.015087\n",
            "Train Epoch: 18 [6720/35339 (19%)]\tLoss: 0.082003\n",
            "Train Epoch: 18 [7040/35339 (20%)]\tLoss: 0.013828\n",
            "Train Epoch: 18 [7360/35339 (21%)]\tLoss: 0.000000\n",
            "Train Epoch: 18 [7680/35339 (22%)]\tLoss: 0.000228\n",
            "Train Epoch: 18 [8000/35339 (23%)]\tLoss: 0.000000\n",
            "Train Epoch: 18 [8320/35339 (24%)]\tLoss: 0.006928\n",
            "Train Epoch: 18 [8640/35339 (24%)]\tLoss: 0.000003\n",
            "Train Epoch: 18 [8960/35339 (25%)]\tLoss: 0.001248\n",
            "Train Epoch: 18 [9280/35339 (26%)]\tLoss: 0.120142\n",
            "Train Epoch: 18 [9600/35339 (27%)]\tLoss: 0.000004\n",
            "Train Epoch: 18 [9920/35339 (28%)]\tLoss: 0.000009\n",
            "Train Epoch: 18 [10240/35339 (29%)]\tLoss: 0.095083\n",
            "Train Epoch: 18 [10560/35339 (30%)]\tLoss: 0.000001\n",
            "Train Epoch: 18 [10880/35339 (31%)]\tLoss: 0.000431\n",
            "Train Epoch: 18 [11200/35339 (32%)]\tLoss: 0.000000\n",
            "Train Epoch: 18 [11520/35339 (33%)]\tLoss: 0.000022\n",
            "Train Epoch: 18 [11840/35339 (33%)]\tLoss: 0.000014\n",
            "Train Epoch: 18 [12160/35339 (34%)]\tLoss: 0.000100\n",
            "Train Epoch: 18 [12480/35339 (35%)]\tLoss: 0.000000\n",
            "Train Epoch: 18 [12800/35339 (36%)]\tLoss: 0.000156\n",
            "Train Epoch: 18 [13120/35339 (37%)]\tLoss: 0.011124\n",
            "Train Epoch: 18 [13440/35339 (38%)]\tLoss: 0.001879\n",
            "Train Epoch: 18 [13760/35339 (39%)]\tLoss: 0.000000\n",
            "Train Epoch: 18 [14080/35339 (40%)]\tLoss: 0.010713\n",
            "Train Epoch: 18 [14400/35339 (41%)]\tLoss: 0.000011\n",
            "Train Epoch: 18 [14720/35339 (42%)]\tLoss: 0.000257\n",
            "Train Epoch: 18 [15040/35339 (43%)]\tLoss: 0.008003\n",
            "Train Epoch: 18 [15360/35339 (43%)]\tLoss: 0.000004\n",
            "Train Epoch: 18 [15680/35339 (44%)]\tLoss: 0.000012\n",
            "Train Epoch: 18 [16000/35339 (45%)]\tLoss: 0.000020\n",
            "Train Epoch: 18 [16320/35339 (46%)]\tLoss: 0.000000\n",
            "Train Epoch: 18 [16640/35339 (47%)]\tLoss: 0.000000\n",
            "Train Epoch: 18 [16960/35339 (48%)]\tLoss: 0.000161\n",
            "Train Epoch: 18 [17280/35339 (49%)]\tLoss: 0.000132\n",
            "Train Epoch: 18 [17600/35339 (50%)]\tLoss: 0.000000\n",
            "Train Epoch: 18 [17920/35339 (51%)]\tLoss: 0.001803\n",
            "Train Epoch: 18 [18240/35339 (52%)]\tLoss: 0.000034\n",
            "Train Epoch: 18 [18560/35339 (52%)]\tLoss: 0.000000\n",
            "Train Epoch: 18 [18880/35339 (53%)]\tLoss: 0.000159\n",
            "Train Epoch: 18 [19200/35339 (54%)]\tLoss: 0.000000\n",
            "Train Epoch: 18 [19520/35339 (55%)]\tLoss: 0.000000\n",
            "Train Epoch: 18 [19840/35339 (56%)]\tLoss: 0.000196\n",
            "Train Epoch: 18 [20160/35339 (57%)]\tLoss: 0.000169\n",
            "Train Epoch: 18 [20480/35339 (58%)]\tLoss: 0.000020\n",
            "Train Epoch: 18 [20800/35339 (59%)]\tLoss: 0.000153\n",
            "Train Epoch: 18 [21120/35339 (60%)]\tLoss: 0.000075\n",
            "Train Epoch: 18 [21440/35339 (61%)]\tLoss: 0.000203\n",
            "Train Epoch: 18 [21760/35339 (62%)]\tLoss: 0.000047\n",
            "Train Epoch: 18 [22080/35339 (62%)]\tLoss: 0.000000\n",
            "Train Epoch: 18 [22400/35339 (63%)]\tLoss: 0.000811\n",
            "Train Epoch: 18 [22720/35339 (64%)]\tLoss: 0.000000\n",
            "Train Epoch: 18 [23040/35339 (65%)]\tLoss: 0.016480\n",
            "Train Epoch: 18 [23360/35339 (66%)]\tLoss: 0.000000\n",
            "Train Epoch: 18 [23680/35339 (67%)]\tLoss: 0.000000\n",
            "Train Epoch: 18 [24000/35339 (68%)]\tLoss: 0.000130\n",
            "Train Epoch: 18 [24320/35339 (69%)]\tLoss: 0.000039\n",
            "Train Epoch: 18 [24640/35339 (70%)]\tLoss: 0.000000\n",
            "Train Epoch: 18 [24960/35339 (71%)]\tLoss: 0.000002\n",
            "Train Epoch: 18 [25280/35339 (71%)]\tLoss: 0.000000\n",
            "Train Epoch: 18 [25600/35339 (72%)]\tLoss: 0.000001\n",
            "Train Epoch: 18 [25920/35339 (73%)]\tLoss: 0.000008\n",
            "Train Epoch: 18 [26240/35339 (74%)]\tLoss: 0.000060\n",
            "Train Epoch: 18 [26560/35339 (75%)]\tLoss: 0.000000\n",
            "Train Epoch: 18 [26880/35339 (76%)]\tLoss: 0.000001\n",
            "Train Epoch: 18 [27200/35339 (77%)]\tLoss: 0.000251\n",
            "Train Epoch: 18 [27520/35339 (78%)]\tLoss: 0.000000\n",
            "Train Epoch: 18 [27840/35339 (79%)]\tLoss: 0.000009\n",
            "Train Epoch: 18 [28160/35339 (80%)]\tLoss: 0.000048\n",
            "Train Epoch: 18 [28480/35339 (81%)]\tLoss: 0.003913\n",
            "Train Epoch: 18 [28800/35339 (81%)]\tLoss: 0.000015\n",
            "Train Epoch: 18 [29120/35339 (82%)]\tLoss: 0.002239\n",
            "Train Epoch: 18 [29440/35339 (83%)]\tLoss: 0.000160\n",
            "Train Epoch: 18 [29760/35339 (84%)]\tLoss: 0.000000\n",
            "Train Epoch: 18 [30080/35339 (85%)]\tLoss: 0.000004\n",
            "Train Epoch: 18 [30400/35339 (86%)]\tLoss: 0.000000\n",
            "Train Epoch: 18 [30720/35339 (87%)]\tLoss: 0.000001\n",
            "Train Epoch: 18 [31040/35339 (88%)]\tLoss: 0.000002\n",
            "Train Epoch: 18 [31360/35339 (89%)]\tLoss: 0.000000\n",
            "Train Epoch: 18 [31680/35339 (90%)]\tLoss: 0.000013\n",
            "Train Epoch: 18 [32000/35339 (90%)]\tLoss: 0.000000\n",
            "Train Epoch: 18 [32320/35339 (91%)]\tLoss: 0.000002\n",
            "Train Epoch: 18 [32640/35339 (92%)]\tLoss: 0.000026\n",
            "Train Epoch: 18 [32960/35339 (93%)]\tLoss: 0.000003\n",
            "Train Epoch: 18 [33280/35339 (94%)]\tLoss: 0.000000\n",
            "Train Epoch: 18 [33600/35339 (95%)]\tLoss: 0.004009\n",
            "Train Epoch: 18 [33920/35339 (96%)]\tLoss: 0.005040\n",
            "Train Epoch: 18 [34240/35339 (97%)]\tLoss: 0.000000\n",
            "Train Epoch: 18 [34560/35339 (98%)]\tLoss: 0.000000\n",
            "Train Epoch: 18 [34880/35339 (99%)]\tLoss: 0.000002\n",
            "Train Epoch: 18 [35200/35339 (100%)]\tLoss: 0.000110\n",
            "\n",
            "Validation set: Average loss: 0.1571, Accuracy: 3777/3870 (98%)\n",
            "\n",
            "\n",
            "Saved model to model_18.pth.\n",
            "Train Epoch: 19 [0/35339 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 19 [320/35339 (1%)]\tLoss: 0.000001\n",
            "Train Epoch: 19 [640/35339 (2%)]\tLoss: 0.001004\n",
            "Train Epoch: 19 [960/35339 (3%)]\tLoss: 0.000451\n",
            "Train Epoch: 19 [1280/35339 (4%)]\tLoss: 0.000035\n",
            "Train Epoch: 19 [1600/35339 (5%)]\tLoss: 0.000082\n",
            "Train Epoch: 19 [1920/35339 (5%)]\tLoss: 0.000116\n",
            "Train Epoch: 19 [2240/35339 (6%)]\tLoss: 0.000010\n",
            "Train Epoch: 19 [2560/35339 (7%)]\tLoss: 0.000000\n",
            "Train Epoch: 19 [2880/35339 (8%)]\tLoss: 0.009641\n",
            "Train Epoch: 19 [3200/35339 (9%)]\tLoss: 0.000000\n",
            "Train Epoch: 19 [3520/35339 (10%)]\tLoss: 0.000000\n",
            "Train Epoch: 19 [3840/35339 (11%)]\tLoss: 0.010328\n",
            "Train Epoch: 19 [4160/35339 (12%)]\tLoss: 0.002792\n",
            "Train Epoch: 19 [4480/35339 (13%)]\tLoss: 0.000653\n",
            "Train Epoch: 19 [4800/35339 (14%)]\tLoss: 0.001346\n",
            "Train Epoch: 19 [5120/35339 (14%)]\tLoss: 0.000018\n",
            "Train Epoch: 19 [5440/35339 (15%)]\tLoss: 0.000000\n",
            "Train Epoch: 19 [5760/35339 (16%)]\tLoss: 0.000000\n",
            "Train Epoch: 19 [6080/35339 (17%)]\tLoss: 0.001841\n",
            "Train Epoch: 19 [6400/35339 (18%)]\tLoss: 0.000013\n",
            "Train Epoch: 19 [6720/35339 (19%)]\tLoss: 0.006456\n",
            "Train Epoch: 19 [7040/35339 (20%)]\tLoss: 0.000162\n",
            "Train Epoch: 19 [7360/35339 (21%)]\tLoss: 0.000002\n",
            "Train Epoch: 19 [7680/35339 (22%)]\tLoss: 0.004239\n",
            "Train Epoch: 19 [8000/35339 (23%)]\tLoss: 0.000482\n",
            "Train Epoch: 19 [8320/35339 (24%)]\tLoss: 0.000051\n",
            "Train Epoch: 19 [8640/35339 (24%)]\tLoss: 0.201666\n",
            "Train Epoch: 19 [8960/35339 (25%)]\tLoss: 0.000004\n",
            "Train Epoch: 19 [9280/35339 (26%)]\tLoss: 0.000000\n",
            "Train Epoch: 19 [9600/35339 (27%)]\tLoss: 0.000252\n",
            "Train Epoch: 19 [9920/35339 (28%)]\tLoss: 0.032809\n",
            "Train Epoch: 19 [10240/35339 (29%)]\tLoss: 0.000004\n",
            "Train Epoch: 19 [10560/35339 (30%)]\tLoss: 0.022900\n",
            "Train Epoch: 19 [10880/35339 (31%)]\tLoss: 0.000933\n",
            "Train Epoch: 19 [11200/35339 (32%)]\tLoss: 0.245317\n",
            "Train Epoch: 19 [11520/35339 (33%)]\tLoss: 0.000000\n",
            "Train Epoch: 19 [11840/35339 (33%)]\tLoss: 0.000000\n",
            "Train Epoch: 19 [12160/35339 (34%)]\tLoss: 0.010330\n",
            "Train Epoch: 19 [12480/35339 (35%)]\tLoss: 0.000068\n",
            "Train Epoch: 19 [12800/35339 (36%)]\tLoss: 0.000095\n",
            "Train Epoch: 19 [13120/35339 (37%)]\tLoss: 0.012054\n",
            "Train Epoch: 19 [13440/35339 (38%)]\tLoss: 0.014382\n",
            "Train Epoch: 19 [13760/35339 (39%)]\tLoss: 0.001577\n",
            "Train Epoch: 19 [14080/35339 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 19 [14400/35339 (41%)]\tLoss: 0.000002\n",
            "Train Epoch: 19 [14720/35339 (42%)]\tLoss: 0.001973\n",
            "Train Epoch: 19 [15040/35339 (43%)]\tLoss: 0.000000\n",
            "Train Epoch: 19 [15360/35339 (43%)]\tLoss: 0.000544\n",
            "Train Epoch: 19 [15680/35339 (44%)]\tLoss: 0.000000\n",
            "Train Epoch: 19 [16000/35339 (45%)]\tLoss: 0.000007\n",
            "Train Epoch: 19 [16320/35339 (46%)]\tLoss: 0.002759\n",
            "Train Epoch: 19 [16640/35339 (47%)]\tLoss: 0.000011\n",
            "Train Epoch: 19 [16960/35339 (48%)]\tLoss: 0.048270\n",
            "Train Epoch: 19 [17280/35339 (49%)]\tLoss: 0.000001\n",
            "Train Epoch: 19 [17600/35339 (50%)]\tLoss: 0.000010\n",
            "Train Epoch: 19 [17920/35339 (51%)]\tLoss: 0.000042\n",
            "Train Epoch: 19 [18240/35339 (52%)]\tLoss: 0.000835\n",
            "Train Epoch: 19 [18560/35339 (52%)]\tLoss: 0.000000\n",
            "Train Epoch: 19 [18880/35339 (53%)]\tLoss: 0.000004\n",
            "Train Epoch: 19 [19200/35339 (54%)]\tLoss: 0.000011\n",
            "Train Epoch: 19 [19520/35339 (55%)]\tLoss: 0.000000\n",
            "Train Epoch: 19 [19840/35339 (56%)]\tLoss: 0.000024\n",
            "Train Epoch: 19 [20160/35339 (57%)]\tLoss: 0.000044\n",
            "Train Epoch: 19 [20480/35339 (58%)]\tLoss: 0.000001\n",
            "Train Epoch: 19 [20800/35339 (59%)]\tLoss: 0.000000\n",
            "Train Epoch: 19 [21120/35339 (60%)]\tLoss: 0.000023\n",
            "Train Epoch: 19 [21440/35339 (61%)]\tLoss: 0.000002\n",
            "Train Epoch: 19 [21760/35339 (62%)]\tLoss: 0.000000\n",
            "Train Epoch: 19 [22080/35339 (62%)]\tLoss: 0.000031\n",
            "Train Epoch: 19 [22400/35339 (63%)]\tLoss: 0.000041\n",
            "Train Epoch: 19 [22720/35339 (64%)]\tLoss: 0.000002\n",
            "Train Epoch: 19 [23040/35339 (65%)]\tLoss: 0.001559\n",
            "Train Epoch: 19 [23360/35339 (66%)]\tLoss: 0.000154\n",
            "Train Epoch: 19 [23680/35339 (67%)]\tLoss: 0.000000\n",
            "Train Epoch: 19 [24000/35339 (68%)]\tLoss: 0.195739\n",
            "Train Epoch: 19 [24320/35339 (69%)]\tLoss: 0.001022\n",
            "Train Epoch: 19 [24640/35339 (70%)]\tLoss: 0.000016\n",
            "Train Epoch: 19 [24960/35339 (71%)]\tLoss: 0.000619\n",
            "Train Epoch: 19 [25280/35339 (71%)]\tLoss: 0.002324\n",
            "Train Epoch: 19 [25600/35339 (72%)]\tLoss: 0.000001\n",
            "Train Epoch: 19 [25920/35339 (73%)]\tLoss: 0.000000\n",
            "Train Epoch: 19 [26240/35339 (74%)]\tLoss: 0.000000\n",
            "Train Epoch: 19 [26560/35339 (75%)]\tLoss: 0.093245\n",
            "Train Epoch: 19 [26880/35339 (76%)]\tLoss: 0.000061\n",
            "Train Epoch: 19 [27200/35339 (77%)]\tLoss: 0.053552\n",
            "Train Epoch: 19 [27520/35339 (78%)]\tLoss: 0.000013\n",
            "Train Epoch: 19 [27840/35339 (79%)]\tLoss: 0.000181\n",
            "Train Epoch: 19 [28160/35339 (80%)]\tLoss: 0.000000\n",
            "Train Epoch: 19 [28480/35339 (81%)]\tLoss: 0.000000\n",
            "Train Epoch: 19 [28800/35339 (81%)]\tLoss: 0.000020\n",
            "Train Epoch: 19 [29120/35339 (82%)]\tLoss: 0.000030\n",
            "Train Epoch: 19 [29440/35339 (83%)]\tLoss: 0.000002\n",
            "Train Epoch: 19 [29760/35339 (84%)]\tLoss: 0.000030\n",
            "Train Epoch: 19 [30080/35339 (85%)]\tLoss: 0.000252\n",
            "Train Epoch: 19 [30400/35339 (86%)]\tLoss: 0.005981\n",
            "Train Epoch: 19 [30720/35339 (87%)]\tLoss: 0.000000\n",
            "Train Epoch: 19 [31040/35339 (88%)]\tLoss: 0.000010\n",
            "Train Epoch: 19 [31360/35339 (89%)]\tLoss: 0.028487\n",
            "Train Epoch: 19 [31680/35339 (90%)]\tLoss: 0.000365\n",
            "Train Epoch: 19 [32000/35339 (90%)]\tLoss: 0.000000\n",
            "Train Epoch: 19 [32320/35339 (91%)]\tLoss: 0.000402\n",
            "Train Epoch: 19 [32640/35339 (92%)]\tLoss: 0.000000\n",
            "Train Epoch: 19 [32960/35339 (93%)]\tLoss: 0.000000\n",
            "Train Epoch: 19 [33280/35339 (94%)]\tLoss: 0.121613\n",
            "Train Epoch: 19 [33600/35339 (95%)]\tLoss: 0.000000\n",
            "Train Epoch: 19 [33920/35339 (96%)]\tLoss: 0.184863\n",
            "Train Epoch: 19 [34240/35339 (97%)]\tLoss: 0.000001\n",
            "Train Epoch: 19 [34560/35339 (98%)]\tLoss: 0.000000\n",
            "Train Epoch: 19 [34880/35339 (99%)]\tLoss: 0.000001\n",
            "Train Epoch: 19 [35200/35339 (100%)]\tLoss: 0.000058\n",
            "\n",
            "Validation set: Average loss: 0.1401, Accuracy: 3783/3870 (98%)\n",
            "\n",
            "\n",
            "Saved model to model_19.pth.\n",
            "Train Epoch: 20 [0/35339 (0%)]\tLoss: 0.000081\n",
            "Train Epoch: 20 [320/35339 (1%)]\tLoss: 0.000000\n",
            "Train Epoch: 20 [640/35339 (2%)]\tLoss: 0.000140\n",
            "Train Epoch: 20 [960/35339 (3%)]\tLoss: 0.000387\n",
            "Train Epoch: 20 [1280/35339 (4%)]\tLoss: 0.000001\n",
            "Train Epoch: 20 [1600/35339 (5%)]\tLoss: 0.000032\n",
            "Train Epoch: 20 [1920/35339 (5%)]\tLoss: 0.000000\n",
            "Train Epoch: 20 [2240/35339 (6%)]\tLoss: 0.002273\n",
            "Train Epoch: 20 [2560/35339 (7%)]\tLoss: 0.000082\n",
            "Train Epoch: 20 [2880/35339 (8%)]\tLoss: 0.002921\n",
            "Train Epoch: 20 [3200/35339 (9%)]\tLoss: 0.040813\n",
            "Train Epoch: 20 [3520/35339 (10%)]\tLoss: 0.039837\n",
            "Train Epoch: 20 [3840/35339 (11%)]\tLoss: 0.116851\n",
            "Train Epoch: 20 [4160/35339 (12%)]\tLoss: 0.000858\n",
            "Train Epoch: 20 [4480/35339 (13%)]\tLoss: 0.000001\n",
            "Train Epoch: 20 [4800/35339 (14%)]\tLoss: 0.000080\n",
            "Train Epoch: 20 [5120/35339 (14%)]\tLoss: 0.012605\n",
            "Train Epoch: 20 [5440/35339 (15%)]\tLoss: 0.329444\n",
            "Train Epoch: 20 [5760/35339 (16%)]\tLoss: 0.001716\n",
            "Train Epoch: 20 [6080/35339 (17%)]\tLoss: 0.000000\n",
            "Train Epoch: 20 [6400/35339 (18%)]\tLoss: 0.000005\n",
            "Train Epoch: 20 [6720/35339 (19%)]\tLoss: 0.000136\n",
            "Train Epoch: 20 [7040/35339 (20%)]\tLoss: 0.000004\n",
            "Train Epoch: 20 [7360/35339 (21%)]\tLoss: 0.000002\n",
            "Train Epoch: 20 [7680/35339 (22%)]\tLoss: 0.031576\n",
            "Train Epoch: 20 [8000/35339 (23%)]\tLoss: 0.006805\n",
            "Train Epoch: 20 [8320/35339 (24%)]\tLoss: 0.001082\n",
            "Train Epoch: 20 [8640/35339 (24%)]\tLoss: 0.000001\n",
            "Train Epoch: 20 [8960/35339 (25%)]\tLoss: 0.019548\n",
            "Train Epoch: 20 [9280/35339 (26%)]\tLoss: 0.000005\n",
            "Train Epoch: 20 [9600/35339 (27%)]\tLoss: 0.000934\n",
            "Train Epoch: 20 [9920/35339 (28%)]\tLoss: 0.009231\n",
            "Train Epoch: 20 [10240/35339 (29%)]\tLoss: 0.000446\n",
            "Train Epoch: 20 [10560/35339 (30%)]\tLoss: 0.000006\n",
            "Train Epoch: 20 [10880/35339 (31%)]\tLoss: 0.000014\n",
            "Train Epoch: 20 [11200/35339 (32%)]\tLoss: 0.000009\n",
            "Train Epoch: 20 [11520/35339 (33%)]\tLoss: 0.000120\n",
            "Train Epoch: 20 [11840/35339 (33%)]\tLoss: 0.246994\n",
            "Train Epoch: 20 [12160/35339 (34%)]\tLoss: 0.001404\n",
            "Train Epoch: 20 [12480/35339 (35%)]\tLoss: 0.001891\n",
            "Train Epoch: 20 [12800/35339 (36%)]\tLoss: 0.005701\n",
            "Train Epoch: 20 [13120/35339 (37%)]\tLoss: 0.000000\n",
            "Train Epoch: 20 [13440/35339 (38%)]\tLoss: 0.086949\n",
            "Train Epoch: 20 [13760/35339 (39%)]\tLoss: 0.000099\n",
            "Train Epoch: 20 [14080/35339 (40%)]\tLoss: 0.008292\n",
            "Train Epoch: 20 [14400/35339 (41%)]\tLoss: 0.000006\n",
            "Train Epoch: 20 [14720/35339 (42%)]\tLoss: 0.000020\n",
            "Train Epoch: 20 [15040/35339 (43%)]\tLoss: 0.000022\n",
            "Train Epoch: 20 [15360/35339 (43%)]\tLoss: 0.090512\n",
            "Train Epoch: 20 [15680/35339 (44%)]\tLoss: 0.008186\n",
            "Train Epoch: 20 [16000/35339 (45%)]\tLoss: 0.211503\n",
            "Train Epoch: 20 [16320/35339 (46%)]\tLoss: 0.001173\n",
            "Train Epoch: 20 [16640/35339 (47%)]\tLoss: 0.000000\n",
            "Train Epoch: 20 [16960/35339 (48%)]\tLoss: 0.000067\n",
            "Train Epoch: 20 [17280/35339 (49%)]\tLoss: 0.000418\n",
            "Train Epoch: 20 [17600/35339 (50%)]\tLoss: 0.000000\n",
            "Train Epoch: 20 [17920/35339 (51%)]\tLoss: 0.000246\n",
            "Train Epoch: 20 [18240/35339 (52%)]\tLoss: 0.000002\n",
            "Train Epoch: 20 [18560/35339 (52%)]\tLoss: 0.000000\n",
            "Train Epoch: 20 [18880/35339 (53%)]\tLoss: 0.000032\n",
            "Train Epoch: 20 [19200/35339 (54%)]\tLoss: 0.001550\n",
            "Train Epoch: 20 [19520/35339 (55%)]\tLoss: 0.000232\n",
            "Train Epoch: 20 [19840/35339 (56%)]\tLoss: 0.000001\n",
            "Train Epoch: 20 [20160/35339 (57%)]\tLoss: 0.000000\n",
            "Train Epoch: 20 [20480/35339 (58%)]\tLoss: 0.001144\n",
            "Train Epoch: 20 [20800/35339 (59%)]\tLoss: 0.000167\n",
            "Train Epoch: 20 [21120/35339 (60%)]\tLoss: 0.000048\n",
            "Train Epoch: 20 [21440/35339 (61%)]\tLoss: 0.020244\n",
            "Train Epoch: 20 [21760/35339 (62%)]\tLoss: 0.000018\n",
            "Train Epoch: 20 [22080/35339 (62%)]\tLoss: 0.000007\n",
            "Train Epoch: 20 [22400/35339 (63%)]\tLoss: 0.000805\n",
            "Train Epoch: 20 [22720/35339 (64%)]\tLoss: 0.000047\n",
            "Train Epoch: 20 [23040/35339 (65%)]\tLoss: 0.001108\n",
            "Train Epoch: 20 [23360/35339 (66%)]\tLoss: 0.000000\n",
            "Train Epoch: 20 [23680/35339 (67%)]\tLoss: 0.000000\n",
            "Train Epoch: 20 [24000/35339 (68%)]\tLoss: 0.000035\n",
            "Train Epoch: 20 [24320/35339 (69%)]\tLoss: 0.000196\n",
            "Train Epoch: 20 [24640/35339 (70%)]\tLoss: 0.005750\n",
            "Train Epoch: 20 [24960/35339 (71%)]\tLoss: 0.027399\n",
            "Train Epoch: 20 [25280/35339 (71%)]\tLoss: 0.000000\n",
            "Train Epoch: 20 [25600/35339 (72%)]\tLoss: 0.001459\n",
            "Train Epoch: 20 [25920/35339 (73%)]\tLoss: 0.000040\n",
            "Train Epoch: 20 [26240/35339 (74%)]\tLoss: 0.170034\n",
            "Train Epoch: 20 [26560/35339 (75%)]\tLoss: 0.000075\n",
            "Train Epoch: 20 [26880/35339 (76%)]\tLoss: 0.000076\n",
            "Train Epoch: 20 [27200/35339 (77%)]\tLoss: 0.000241\n",
            "Train Epoch: 20 [27520/35339 (78%)]\tLoss: 0.002470\n",
            "Train Epoch: 20 [27840/35339 (79%)]\tLoss: 0.001636\n",
            "Train Epoch: 20 [28160/35339 (80%)]\tLoss: 0.000340\n",
            "Train Epoch: 20 [28480/35339 (81%)]\tLoss: 0.000024\n",
            "Train Epoch: 20 [28800/35339 (81%)]\tLoss: 0.000321\n",
            "Train Epoch: 20 [29120/35339 (82%)]\tLoss: 0.000010\n",
            "Train Epoch: 20 [29440/35339 (83%)]\tLoss: 0.000000\n",
            "Train Epoch: 20 [29760/35339 (84%)]\tLoss: 0.121649\n",
            "Train Epoch: 20 [30080/35339 (85%)]\tLoss: 0.000001\n",
            "Train Epoch: 20 [30400/35339 (86%)]\tLoss: 0.000000\n",
            "Train Epoch: 20 [30720/35339 (87%)]\tLoss: 0.001172\n",
            "Train Epoch: 20 [31040/35339 (88%)]\tLoss: 0.004090\n",
            "Train Epoch: 20 [31360/35339 (89%)]\tLoss: 0.000005\n",
            "Train Epoch: 20 [31680/35339 (90%)]\tLoss: 0.000000\n",
            "Train Epoch: 20 [32000/35339 (90%)]\tLoss: 0.000004\n",
            "Train Epoch: 20 [32320/35339 (91%)]\tLoss: 0.000330\n",
            "Train Epoch: 20 [32640/35339 (92%)]\tLoss: 0.000006\n",
            "Train Epoch: 20 [32960/35339 (93%)]\tLoss: 0.000022\n",
            "Train Epoch: 20 [33280/35339 (94%)]\tLoss: 0.000003\n",
            "Train Epoch: 20 [33600/35339 (95%)]\tLoss: 0.000001\n",
            "Train Epoch: 20 [33920/35339 (96%)]\tLoss: 0.000000\n",
            "Train Epoch: 20 [34240/35339 (97%)]\tLoss: 0.005949\n",
            "Train Epoch: 20 [34560/35339 (98%)]\tLoss: 0.000027\n",
            "Train Epoch: 20 [34880/35339 (99%)]\tLoss: 0.000815\n",
            "Train Epoch: 20 [35200/35339 (100%)]\tLoss: 0.000102\n",
            "\n",
            "Validation set: Average loss: 0.1617, Accuracy: 3753/3870 (97%)\n",
            "\n",
            "\n",
            "Saved model to model_20.pth.\n",
            "Train Epoch: 21 [0/35339 (0%)]\tLoss: 0.000002\n",
            "Train Epoch: 21 [320/35339 (1%)]\tLoss: 0.196534\n",
            "Train Epoch: 21 [640/35339 (2%)]\tLoss: 0.108813\n",
            "Train Epoch: 21 [960/35339 (3%)]\tLoss: 0.000007\n",
            "Train Epoch: 21 [1280/35339 (4%)]\tLoss: 0.007797\n",
            "Train Epoch: 21 [1600/35339 (5%)]\tLoss: 0.000209\n",
            "Train Epoch: 21 [1920/35339 (5%)]\tLoss: 0.000005\n",
            "Train Epoch: 21 [2240/35339 (6%)]\tLoss: 0.000035\n",
            "Train Epoch: 21 [2560/35339 (7%)]\tLoss: 0.000035\n",
            "Train Epoch: 21 [2880/35339 (8%)]\tLoss: 0.037345\n",
            "Train Epoch: 21 [3200/35339 (9%)]\tLoss: 0.000510\n",
            "Train Epoch: 21 [3520/35339 (10%)]\tLoss: 0.000292\n",
            "Train Epoch: 21 [3840/35339 (11%)]\tLoss: 0.013118\n",
            "Train Epoch: 21 [4160/35339 (12%)]\tLoss: 0.000000\n",
            "Train Epoch: 21 [4480/35339 (13%)]\tLoss: 0.080989\n",
            "Train Epoch: 21 [4800/35339 (14%)]\tLoss: 0.000486\n",
            "Train Epoch: 21 [5120/35339 (14%)]\tLoss: 0.004257\n",
            "Train Epoch: 21 [5440/35339 (15%)]\tLoss: 0.000008\n",
            "Train Epoch: 21 [5760/35339 (16%)]\tLoss: 0.000000\n",
            "Train Epoch: 21 [6080/35339 (17%)]\tLoss: 0.000070\n",
            "Train Epoch: 21 [6400/35339 (18%)]\tLoss: 0.000089\n",
            "Train Epoch: 21 [6720/35339 (19%)]\tLoss: 0.000000\n",
            "Train Epoch: 21 [7040/35339 (20%)]\tLoss: 0.025659\n",
            "Train Epoch: 21 [7360/35339 (21%)]\tLoss: 0.024864\n",
            "Train Epoch: 21 [7680/35339 (22%)]\tLoss: 0.049057\n",
            "Train Epoch: 21 [8000/35339 (23%)]\tLoss: 0.001521\n",
            "Train Epoch: 21 [8320/35339 (24%)]\tLoss: 0.000549\n",
            "Train Epoch: 21 [8640/35339 (24%)]\tLoss: 0.000057\n",
            "Train Epoch: 21 [8960/35339 (25%)]\tLoss: 0.000055\n",
            "Train Epoch: 21 [9280/35339 (26%)]\tLoss: 0.000104\n",
            "Train Epoch: 21 [9600/35339 (27%)]\tLoss: 0.001402\n",
            "Train Epoch: 21 [9920/35339 (28%)]\tLoss: 0.000003\n",
            "Train Epoch: 21 [10240/35339 (29%)]\tLoss: 0.001392\n",
            "Train Epoch: 21 [10560/35339 (30%)]\tLoss: 0.000559\n",
            "Train Epoch: 21 [10880/35339 (31%)]\tLoss: 0.000525\n",
            "Train Epoch: 21 [11200/35339 (32%)]\tLoss: 0.000179\n",
            "Train Epoch: 21 [11520/35339 (33%)]\tLoss: 0.000659\n",
            "Train Epoch: 21 [11840/35339 (33%)]\tLoss: 0.000001\n",
            "Train Epoch: 21 [12160/35339 (34%)]\tLoss: 0.000022\n",
            "Train Epoch: 21 [12480/35339 (35%)]\tLoss: 0.000001\n",
            "Train Epoch: 21 [12800/35339 (36%)]\tLoss: 0.000053\n",
            "Train Epoch: 21 [13120/35339 (37%)]\tLoss: 0.000000\n",
            "Train Epoch: 21 [13440/35339 (38%)]\tLoss: 0.000076\n",
            "Train Epoch: 21 [13760/35339 (39%)]\tLoss: 0.000000\n",
            "Train Epoch: 21 [14080/35339 (40%)]\tLoss: 0.000002\n",
            "Train Epoch: 21 [14400/35339 (41%)]\tLoss: 0.000018\n",
            "Train Epoch: 21 [14720/35339 (42%)]\tLoss: 0.000000\n",
            "Train Epoch: 21 [15040/35339 (43%)]\tLoss: 0.000222\n",
            "Train Epoch: 21 [15360/35339 (43%)]\tLoss: 0.000054\n",
            "Train Epoch: 21 [15680/35339 (44%)]\tLoss: 0.000269\n",
            "Train Epoch: 21 [16000/35339 (45%)]\tLoss: 0.000033\n",
            "Train Epoch: 21 [16320/35339 (46%)]\tLoss: 0.003493\n",
            "Train Epoch: 21 [16640/35339 (47%)]\tLoss: 0.000354\n",
            "Train Epoch: 21 [16960/35339 (48%)]\tLoss: 0.000000\n",
            "Train Epoch: 21 [17280/35339 (49%)]\tLoss: 0.000000\n",
            "Train Epoch: 21 [17600/35339 (50%)]\tLoss: 0.001862\n",
            "Train Epoch: 21 [17920/35339 (51%)]\tLoss: 0.000001\n",
            "Train Epoch: 21 [18240/35339 (52%)]\tLoss: 0.014744\n",
            "Train Epoch: 21 [18560/35339 (52%)]\tLoss: 0.000000\n",
            "Train Epoch: 21 [18880/35339 (53%)]\tLoss: 0.000006\n",
            "Train Epoch: 21 [19200/35339 (54%)]\tLoss: 0.000002\n",
            "Train Epoch: 21 [19520/35339 (55%)]\tLoss: 0.000000\n",
            "Train Epoch: 21 [19840/35339 (56%)]\tLoss: 0.000780\n",
            "Train Epoch: 21 [20160/35339 (57%)]\tLoss: 0.000000\n",
            "Train Epoch: 21 [20480/35339 (58%)]\tLoss: 0.000000\n",
            "Train Epoch: 21 [20800/35339 (59%)]\tLoss: 0.000000\n",
            "Train Epoch: 21 [21120/35339 (60%)]\tLoss: 0.001139\n",
            "Train Epoch: 21 [21440/35339 (61%)]\tLoss: 0.019898\n",
            "Train Epoch: 21 [21760/35339 (62%)]\tLoss: 0.000003\n",
            "Train Epoch: 21 [22080/35339 (62%)]\tLoss: 0.159880\n",
            "Train Epoch: 21 [22400/35339 (63%)]\tLoss: 0.000000\n",
            "Train Epoch: 21 [22720/35339 (64%)]\tLoss: 0.000000\n",
            "Train Epoch: 21 [23040/35339 (65%)]\tLoss: 0.000000\n",
            "Train Epoch: 21 [23360/35339 (66%)]\tLoss: 0.000000\n",
            "Train Epoch: 21 [23680/35339 (67%)]\tLoss: 0.000000\n",
            "Train Epoch: 21 [24000/35339 (68%)]\tLoss: 0.000000\n",
            "Train Epoch: 21 [24320/35339 (69%)]\tLoss: 0.008131\n",
            "Train Epoch: 21 [24640/35339 (70%)]\tLoss: 0.009372\n",
            "Train Epoch: 21 [24960/35339 (71%)]\tLoss: 0.000012\n",
            "Train Epoch: 21 [25280/35339 (71%)]\tLoss: 0.002603\n",
            "Train Epoch: 21 [25600/35339 (72%)]\tLoss: 0.000000\n",
            "Train Epoch: 21 [25920/35339 (73%)]\tLoss: 0.003416\n",
            "Train Epoch: 21 [26240/35339 (74%)]\tLoss: 0.153259\n",
            "Train Epoch: 21 [26560/35339 (75%)]\tLoss: 0.006278\n",
            "Train Epoch: 21 [26880/35339 (76%)]\tLoss: 0.018617\n",
            "Train Epoch: 21 [27200/35339 (77%)]\tLoss: 0.000102\n",
            "Train Epoch: 21 [27520/35339 (78%)]\tLoss: 0.000016\n",
            "Train Epoch: 21 [27840/35339 (79%)]\tLoss: 0.000069\n",
            "Train Epoch: 21 [28160/35339 (80%)]\tLoss: 0.000005\n",
            "Train Epoch: 21 [28480/35339 (81%)]\tLoss: 0.000206\n",
            "Train Epoch: 21 [28800/35339 (81%)]\tLoss: 0.113469\n",
            "Train Epoch: 21 [29120/35339 (82%)]\tLoss: 0.000570\n",
            "Train Epoch: 21 [29440/35339 (83%)]\tLoss: 0.002386\n",
            "Train Epoch: 21 [29760/35339 (84%)]\tLoss: 0.000000\n",
            "Train Epoch: 21 [30080/35339 (85%)]\tLoss: 0.053776\n",
            "Train Epoch: 21 [30400/35339 (86%)]\tLoss: 0.067255\n",
            "Train Epoch: 21 [30720/35339 (87%)]\tLoss: 0.094393\n",
            "Train Epoch: 21 [31040/35339 (88%)]\tLoss: 0.000000\n",
            "Train Epoch: 21 [31360/35339 (89%)]\tLoss: 0.000000\n",
            "Train Epoch: 21 [31680/35339 (90%)]\tLoss: 0.033964\n",
            "Train Epoch: 21 [32000/35339 (90%)]\tLoss: 0.000666\n",
            "Train Epoch: 21 [32320/35339 (91%)]\tLoss: 0.000004\n",
            "Train Epoch: 21 [32640/35339 (92%)]\tLoss: 0.003923\n",
            "Train Epoch: 21 [32960/35339 (93%)]\tLoss: 0.000001\n",
            "Train Epoch: 21 [33280/35339 (94%)]\tLoss: 0.000176\n",
            "Train Epoch: 21 [33600/35339 (95%)]\tLoss: 0.000657\n",
            "Train Epoch: 21 [33920/35339 (96%)]\tLoss: 0.000000\n",
            "Train Epoch: 21 [34240/35339 (97%)]\tLoss: 0.000023\n",
            "Train Epoch: 21 [34560/35339 (98%)]\tLoss: 0.000027\n",
            "Train Epoch: 21 [34880/35339 (99%)]\tLoss: 0.377763\n",
            "Train Epoch: 21 [35200/35339 (100%)]\tLoss: 0.000108\n",
            "\n",
            "Validation set: Average loss: 0.2020, Accuracy: 3787/3870 (98%)\n",
            "\n",
            "\n",
            "Saved model to model_21.pth.\n",
            "Train Epoch: 22 [0/35339 (0%)]\tLoss: 0.000001\n",
            "Train Epoch: 22 [320/35339 (1%)]\tLoss: 0.000627\n",
            "Train Epoch: 22 [640/35339 (2%)]\tLoss: 0.005176\n",
            "Train Epoch: 22 [960/35339 (3%)]\tLoss: 0.018773\n",
            "Train Epoch: 22 [1280/35339 (4%)]\tLoss: 0.000000\n",
            "Train Epoch: 22 [1600/35339 (5%)]\tLoss: 0.000022\n",
            "Train Epoch: 22 [1920/35339 (5%)]\tLoss: 0.000003\n",
            "Train Epoch: 22 [2240/35339 (6%)]\tLoss: 0.005131\n",
            "Train Epoch: 22 [2560/35339 (7%)]\tLoss: 0.000001\n",
            "Train Epoch: 22 [2880/35339 (8%)]\tLoss: 0.000000\n",
            "Train Epoch: 22 [3200/35339 (9%)]\tLoss: 0.006213\n",
            "Train Epoch: 22 [3520/35339 (10%)]\tLoss: 0.000001\n",
            "Train Epoch: 22 [3840/35339 (11%)]\tLoss: 0.000184\n",
            "Train Epoch: 22 [4160/35339 (12%)]\tLoss: 0.000008\n",
            "Train Epoch: 22 [4480/35339 (13%)]\tLoss: 0.000004\n",
            "Train Epoch: 22 [4800/35339 (14%)]\tLoss: 0.001098\n",
            "Train Epoch: 22 [5120/35339 (14%)]\tLoss: 0.000000\n",
            "Train Epoch: 22 [5440/35339 (15%)]\tLoss: 0.000113\n",
            "Train Epoch: 22 [5760/35339 (16%)]\tLoss: 0.006294\n",
            "Train Epoch: 22 [6080/35339 (17%)]\tLoss: 0.000000\n",
            "Train Epoch: 22 [6400/35339 (18%)]\tLoss: 0.049232\n",
            "Train Epoch: 22 [6720/35339 (19%)]\tLoss: 0.004205\n",
            "Train Epoch: 22 [7040/35339 (20%)]\tLoss: 0.000582\n",
            "Train Epoch: 22 [7360/35339 (21%)]\tLoss: 0.000031\n",
            "Train Epoch: 22 [7680/35339 (22%)]\tLoss: 0.001853\n",
            "Train Epoch: 22 [8000/35339 (23%)]\tLoss: 0.000000\n",
            "Train Epoch: 22 [8320/35339 (24%)]\tLoss: 0.000000\n",
            "Train Epoch: 22 [8640/35339 (24%)]\tLoss: 0.003753\n",
            "Train Epoch: 22 [8960/35339 (25%)]\tLoss: 0.018752\n",
            "Train Epoch: 22 [9280/35339 (26%)]\tLoss: 0.000001\n",
            "Train Epoch: 22 [9600/35339 (27%)]\tLoss: 0.000002\n",
            "Train Epoch: 22 [9920/35339 (28%)]\tLoss: 0.000033\n",
            "Train Epoch: 22 [10240/35339 (29%)]\tLoss: 0.049467\n",
            "Train Epoch: 22 [10560/35339 (30%)]\tLoss: 0.005211\n",
            "Train Epoch: 22 [10880/35339 (31%)]\tLoss: 0.000874\n",
            "Train Epoch: 22 [11200/35339 (32%)]\tLoss: 0.004225\n",
            "Train Epoch: 22 [11520/35339 (33%)]\tLoss: 0.000582\n",
            "Train Epoch: 22 [11840/35339 (33%)]\tLoss: 0.000000\n",
            "Train Epoch: 22 [12160/35339 (34%)]\tLoss: 0.001929\n",
            "Train Epoch: 22 [12480/35339 (35%)]\tLoss: 0.000139\n",
            "Train Epoch: 22 [12800/35339 (36%)]\tLoss: 0.000001\n",
            "Train Epoch: 22 [13120/35339 (37%)]\tLoss: 0.000004\n",
            "Train Epoch: 22 [13440/35339 (38%)]\tLoss: 0.253012\n",
            "Train Epoch: 22 [13760/35339 (39%)]\tLoss: 0.000000\n",
            "Train Epoch: 22 [14080/35339 (40%)]\tLoss: 0.000563\n",
            "Train Epoch: 22 [14400/35339 (41%)]\tLoss: 0.000001\n",
            "Train Epoch: 22 [14720/35339 (42%)]\tLoss: 0.000211\n",
            "Train Epoch: 22 [15040/35339 (43%)]\tLoss: 0.000262\n",
            "Train Epoch: 22 [15360/35339 (43%)]\tLoss: 0.000651\n",
            "Train Epoch: 22 [15680/35339 (44%)]\tLoss: 0.000001\n",
            "Train Epoch: 22 [16000/35339 (45%)]\tLoss: 0.002890\n",
            "Train Epoch: 22 [16320/35339 (46%)]\tLoss: 0.000351\n",
            "Train Epoch: 22 [16640/35339 (47%)]\tLoss: 0.000216\n",
            "Train Epoch: 22 [16960/35339 (48%)]\tLoss: 0.000098\n",
            "Train Epoch: 22 [17280/35339 (49%)]\tLoss: 0.000002\n",
            "Train Epoch: 22 [17600/35339 (50%)]\tLoss: 0.004576\n",
            "Train Epoch: 22 [17920/35339 (51%)]\tLoss: 0.000001\n",
            "Train Epoch: 22 [18240/35339 (52%)]\tLoss: 0.000011\n",
            "Train Epoch: 22 [18560/35339 (52%)]\tLoss: 0.008945\n",
            "Train Epoch: 22 [18880/35339 (53%)]\tLoss: 0.000379\n",
            "Train Epoch: 22 [19200/35339 (54%)]\tLoss: 0.000000\n",
            "Train Epoch: 22 [19520/35339 (55%)]\tLoss: 0.058789\n",
            "Train Epoch: 22 [19840/35339 (56%)]\tLoss: 0.000000\n",
            "Train Epoch: 22 [20160/35339 (57%)]\tLoss: 0.000000\n",
            "Train Epoch: 22 [20480/35339 (58%)]\tLoss: 0.000014\n",
            "Train Epoch: 22 [20800/35339 (59%)]\tLoss: 0.051078\n",
            "Train Epoch: 22 [21120/35339 (60%)]\tLoss: 0.000004\n",
            "Train Epoch: 22 [21440/35339 (61%)]\tLoss: 0.000771\n",
            "Train Epoch: 22 [21760/35339 (62%)]\tLoss: 0.000024\n",
            "Train Epoch: 22 [22080/35339 (62%)]\tLoss: 0.001338\n",
            "Train Epoch: 22 [22400/35339 (63%)]\tLoss: 0.000037\n",
            "Train Epoch: 22 [22720/35339 (64%)]\tLoss: 0.000085\n",
            "Train Epoch: 22 [23040/35339 (65%)]\tLoss: 0.000002\n",
            "Train Epoch: 22 [23360/35339 (66%)]\tLoss: 0.000259\n",
            "Train Epoch: 22 [23680/35339 (67%)]\tLoss: 0.001142\n",
            "Train Epoch: 22 [24000/35339 (68%)]\tLoss: 0.000005\n",
            "Train Epoch: 22 [24320/35339 (69%)]\tLoss: 0.000081\n",
            "Train Epoch: 22 [24640/35339 (70%)]\tLoss: 0.000003\n",
            "Train Epoch: 22 [24960/35339 (71%)]\tLoss: 0.024936\n",
            "Train Epoch: 22 [25280/35339 (71%)]\tLoss: 0.000026\n",
            "Train Epoch: 22 [25600/35339 (72%)]\tLoss: 0.096164\n",
            "Train Epoch: 22 [25920/35339 (73%)]\tLoss: 0.000000\n",
            "Train Epoch: 22 [26240/35339 (74%)]\tLoss: 0.000002\n",
            "Train Epoch: 22 [26560/35339 (75%)]\tLoss: 0.000001\n",
            "Train Epoch: 22 [26880/35339 (76%)]\tLoss: 0.001013\n",
            "Train Epoch: 22 [27200/35339 (77%)]\tLoss: 0.000002\n",
            "Train Epoch: 22 [27520/35339 (78%)]\tLoss: 0.000000\n",
            "Train Epoch: 22 [27840/35339 (79%)]\tLoss: 0.115648\n",
            "Train Epoch: 22 [28160/35339 (80%)]\tLoss: 0.000017\n",
            "Train Epoch: 22 [28480/35339 (81%)]\tLoss: 0.000053\n",
            "Train Epoch: 22 [28800/35339 (81%)]\tLoss: 0.046670\n",
            "Train Epoch: 22 [29120/35339 (82%)]\tLoss: 0.000010\n",
            "Train Epoch: 22 [29440/35339 (83%)]\tLoss: 0.126459\n",
            "Train Epoch: 22 [29760/35339 (84%)]\tLoss: 0.000158\n",
            "Train Epoch: 22 [30080/35339 (85%)]\tLoss: 0.006799\n",
            "Train Epoch: 22 [30400/35339 (86%)]\tLoss: 0.000639\n",
            "Train Epoch: 22 [30720/35339 (87%)]\tLoss: 0.001492\n",
            "Train Epoch: 22 [31040/35339 (88%)]\tLoss: 0.000003\n",
            "Train Epoch: 22 [31360/35339 (89%)]\tLoss: 0.000057\n",
            "Train Epoch: 22 [31680/35339 (90%)]\tLoss: 0.015821\n",
            "Train Epoch: 22 [32000/35339 (90%)]\tLoss: 0.005744\n",
            "Train Epoch: 22 [32320/35339 (91%)]\tLoss: 0.000414\n",
            "Train Epoch: 22 [32640/35339 (92%)]\tLoss: 0.000008\n",
            "Train Epoch: 22 [32960/35339 (93%)]\tLoss: 0.002249\n",
            "Train Epoch: 22 [33280/35339 (94%)]\tLoss: 0.000198\n",
            "Train Epoch: 22 [33600/35339 (95%)]\tLoss: 0.000241\n",
            "Train Epoch: 22 [33920/35339 (96%)]\tLoss: 0.003626\n",
            "Train Epoch: 22 [34240/35339 (97%)]\tLoss: 0.000511\n",
            "Train Epoch: 22 [34560/35339 (98%)]\tLoss: 0.000000\n",
            "Train Epoch: 22 [34880/35339 (99%)]\tLoss: 0.000003\n",
            "Train Epoch: 22 [35200/35339 (100%)]\tLoss: 0.156995\n",
            "\n",
            "Validation set: Average loss: 0.1992, Accuracy: 3771/3870 (97%)\n",
            "\n",
            "\n",
            "Saved model to model_22.pth.\n",
            "Train Epoch: 23 [0/35339 (0%)]\tLoss: 0.000340\n",
            "Train Epoch: 23 [320/35339 (1%)]\tLoss: 0.000102\n",
            "Train Epoch: 23 [640/35339 (2%)]\tLoss: 0.001454\n",
            "Train Epoch: 23 [960/35339 (3%)]\tLoss: 0.001145\n",
            "Train Epoch: 23 [1280/35339 (4%)]\tLoss: 0.000037\n",
            "Train Epoch: 23 [1600/35339 (5%)]\tLoss: 0.000000\n",
            "Train Epoch: 23 [1920/35339 (5%)]\tLoss: 0.000001\n",
            "Train Epoch: 23 [2240/35339 (6%)]\tLoss: 0.000269\n",
            "Train Epoch: 23 [2560/35339 (7%)]\tLoss: 0.000603\n",
            "Train Epoch: 23 [2880/35339 (8%)]\tLoss: 0.000001\n",
            "Train Epoch: 23 [3200/35339 (9%)]\tLoss: 0.001043\n",
            "Train Epoch: 23 [3520/35339 (10%)]\tLoss: 0.000004\n",
            "Train Epoch: 23 [3840/35339 (11%)]\tLoss: 0.001244\n",
            "Train Epoch: 23 [4160/35339 (12%)]\tLoss: 0.017265\n",
            "Train Epoch: 23 [4480/35339 (13%)]\tLoss: 0.000000\n",
            "Train Epoch: 23 [4800/35339 (14%)]\tLoss: 0.000548\n",
            "Train Epoch: 23 [5120/35339 (14%)]\tLoss: 0.000016\n",
            "Train Epoch: 23 [5440/35339 (15%)]\tLoss: 0.000037\n",
            "Train Epoch: 23 [5760/35339 (16%)]\tLoss: 0.081461\n",
            "Train Epoch: 23 [6080/35339 (17%)]\tLoss: 0.011154\n",
            "Train Epoch: 23 [6400/35339 (18%)]\tLoss: 0.372051\n",
            "Train Epoch: 23 [6720/35339 (19%)]\tLoss: 0.000001\n",
            "Train Epoch: 23 [7040/35339 (20%)]\tLoss: 0.000042\n",
            "Train Epoch: 23 [7360/35339 (21%)]\tLoss: 0.001423\n",
            "Train Epoch: 23 [7680/35339 (22%)]\tLoss: 0.010078\n",
            "Train Epoch: 23 [8000/35339 (23%)]\tLoss: 0.206675\n",
            "Train Epoch: 23 [8320/35339 (24%)]\tLoss: 0.021505\n",
            "Train Epoch: 23 [8640/35339 (24%)]\tLoss: 0.145457\n",
            "Train Epoch: 23 [8960/35339 (25%)]\tLoss: 0.000502\n",
            "Train Epoch: 23 [9280/35339 (26%)]\tLoss: 0.000004\n",
            "Train Epoch: 23 [9600/35339 (27%)]\tLoss: 0.000641\n",
            "Train Epoch: 23 [9920/35339 (28%)]\tLoss: 0.000059\n",
            "Train Epoch: 23 [10240/35339 (29%)]\tLoss: 0.000013\n",
            "Train Epoch: 23 [10560/35339 (30%)]\tLoss: 0.000000\n",
            "Train Epoch: 23 [10880/35339 (31%)]\tLoss: 0.000002\n",
            "Train Epoch: 23 [11200/35339 (32%)]\tLoss: 0.338242\n",
            "Train Epoch: 23 [11520/35339 (33%)]\tLoss: 0.000408\n",
            "Train Epoch: 23 [11840/35339 (33%)]\tLoss: 0.000660\n",
            "Train Epoch: 23 [12160/35339 (34%)]\tLoss: 0.000000\n",
            "Train Epoch: 23 [12480/35339 (35%)]\tLoss: 0.000000\n",
            "Train Epoch: 23 [12800/35339 (36%)]\tLoss: 0.000000\n",
            "Train Epoch: 23 [13120/35339 (37%)]\tLoss: 0.008631\n",
            "Train Epoch: 23 [13440/35339 (38%)]\tLoss: 0.000001\n",
            "Train Epoch: 23 [13760/35339 (39%)]\tLoss: 0.027307\n",
            "Train Epoch: 23 [14080/35339 (40%)]\tLoss: 0.000002\n",
            "Train Epoch: 23 [14400/35339 (41%)]\tLoss: 0.091511\n",
            "Train Epoch: 23 [14720/35339 (42%)]\tLoss: 0.000467\n",
            "Train Epoch: 23 [15040/35339 (43%)]\tLoss: 0.000006\n",
            "Train Epoch: 23 [15360/35339 (43%)]\tLoss: 0.001491\n",
            "Train Epoch: 23 [15680/35339 (44%)]\tLoss: 0.000001\n",
            "Train Epoch: 23 [16000/35339 (45%)]\tLoss: 0.000886\n",
            "Train Epoch: 23 [16320/35339 (46%)]\tLoss: 0.000000\n",
            "Train Epoch: 23 [16640/35339 (47%)]\tLoss: 0.000328\n",
            "Train Epoch: 23 [16960/35339 (48%)]\tLoss: 0.000000\n",
            "Train Epoch: 23 [17280/35339 (49%)]\tLoss: 0.000123\n",
            "Train Epoch: 23 [17600/35339 (50%)]\tLoss: 0.000000\n",
            "Train Epoch: 23 [17920/35339 (51%)]\tLoss: 0.000003\n",
            "Train Epoch: 23 [18240/35339 (52%)]\tLoss: 0.075343\n",
            "Train Epoch: 23 [18560/35339 (52%)]\tLoss: 0.000826\n",
            "Train Epoch: 23 [18880/35339 (53%)]\tLoss: 0.133897\n",
            "Train Epoch: 23 [19200/35339 (54%)]\tLoss: 0.000006\n",
            "Train Epoch: 23 [19520/35339 (55%)]\tLoss: 0.043471\n",
            "Train Epoch: 23 [19840/35339 (56%)]\tLoss: 0.222948\n",
            "Train Epoch: 23 [20160/35339 (57%)]\tLoss: 0.024095\n",
            "Train Epoch: 23 [20480/35339 (58%)]\tLoss: 0.000000\n",
            "Train Epoch: 23 [20800/35339 (59%)]\tLoss: 0.000103\n",
            "Train Epoch: 23 [21120/35339 (60%)]\tLoss: 0.000000\n",
            "Train Epoch: 23 [21440/35339 (61%)]\tLoss: 0.000034\n",
            "Train Epoch: 23 [21760/35339 (62%)]\tLoss: 0.000000\n",
            "Train Epoch: 23 [22080/35339 (62%)]\tLoss: 0.000032\n",
            "Train Epoch: 23 [22400/35339 (63%)]\tLoss: 0.224206\n",
            "Train Epoch: 23 [22720/35339 (64%)]\tLoss: 0.143050\n",
            "Train Epoch: 23 [23040/35339 (65%)]\tLoss: 0.000015\n",
            "Train Epoch: 23 [23360/35339 (66%)]\tLoss: 0.000009\n",
            "Train Epoch: 23 [23680/35339 (67%)]\tLoss: 0.000001\n",
            "Train Epoch: 23 [24000/35339 (68%)]\tLoss: 0.000098\n",
            "Train Epoch: 23 [24320/35339 (69%)]\tLoss: 0.000000\n",
            "Train Epoch: 23 [24640/35339 (70%)]\tLoss: 0.000068\n",
            "Train Epoch: 23 [24960/35339 (71%)]\tLoss: 0.015320\n",
            "Train Epoch: 23 [25280/35339 (71%)]\tLoss: 0.000000\n",
            "Train Epoch: 23 [25600/35339 (72%)]\tLoss: 0.000003\n",
            "Train Epoch: 23 [25920/35339 (73%)]\tLoss: 0.000229\n",
            "Train Epoch: 23 [26240/35339 (74%)]\tLoss: 0.005061\n",
            "Train Epoch: 23 [26560/35339 (75%)]\tLoss: 0.000101\n",
            "Train Epoch: 23 [26880/35339 (76%)]\tLoss: 0.000010\n",
            "Train Epoch: 23 [27200/35339 (77%)]\tLoss: 0.004912\n",
            "Train Epoch: 23 [27520/35339 (78%)]\tLoss: 0.000680\n",
            "Train Epoch: 23 [27840/35339 (79%)]\tLoss: 0.000151\n",
            "Train Epoch: 23 [28160/35339 (80%)]\tLoss: 0.000350\n",
            "Train Epoch: 23 [28480/35339 (81%)]\tLoss: 0.000002\n",
            "Train Epoch: 23 [28800/35339 (81%)]\tLoss: 0.000000\n",
            "Train Epoch: 23 [29120/35339 (82%)]\tLoss: 0.176077\n",
            "Train Epoch: 23 [29440/35339 (83%)]\tLoss: 0.000000\n",
            "Train Epoch: 23 [29760/35339 (84%)]\tLoss: 0.000002\n",
            "Train Epoch: 23 [30080/35339 (85%)]\tLoss: 0.000000\n",
            "Train Epoch: 23 [30400/35339 (86%)]\tLoss: 0.000020\n",
            "Train Epoch: 23 [30720/35339 (87%)]\tLoss: 0.000290\n",
            "Train Epoch: 23 [31040/35339 (88%)]\tLoss: 0.000121\n",
            "Train Epoch: 23 [31360/35339 (89%)]\tLoss: 0.000000\n",
            "Train Epoch: 23 [31680/35339 (90%)]\tLoss: 0.000493\n",
            "Train Epoch: 23 [32000/35339 (90%)]\tLoss: 0.000000\n",
            "Train Epoch: 23 [32320/35339 (91%)]\tLoss: 0.000000\n",
            "Train Epoch: 23 [32640/35339 (92%)]\tLoss: 0.000000\n",
            "Train Epoch: 23 [32960/35339 (93%)]\tLoss: 0.000840\n",
            "Train Epoch: 23 [33280/35339 (94%)]\tLoss: 0.000001\n",
            "Train Epoch: 23 [33600/35339 (95%)]\tLoss: 0.000001\n",
            "Train Epoch: 23 [33920/35339 (96%)]\tLoss: 0.001549\n",
            "Train Epoch: 23 [34240/35339 (97%)]\tLoss: 0.000023\n",
            "Train Epoch: 23 [34560/35339 (98%)]\tLoss: 0.000000\n",
            "Train Epoch: 23 [34880/35339 (99%)]\tLoss: 0.000002\n",
            "Train Epoch: 23 [35200/35339 (100%)]\tLoss: 0.000295\n",
            "\n",
            "Validation set: Average loss: 0.2194, Accuracy: 3760/3870 (97%)\n",
            "\n",
            "\n",
            "Saved model to model_23.pth.\n",
            "Train Epoch: 24 [0/35339 (0%)]\tLoss: 0.000031\n",
            "Train Epoch: 24 [320/35339 (1%)]\tLoss: 0.020036\n",
            "Train Epoch: 24 [640/35339 (2%)]\tLoss: 0.000037\n",
            "Train Epoch: 24 [960/35339 (3%)]\tLoss: 0.077145\n",
            "Train Epoch: 24 [1280/35339 (4%)]\tLoss: 0.000001\n",
            "Train Epoch: 24 [1600/35339 (5%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [1920/35339 (5%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [2240/35339 (6%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [2560/35339 (7%)]\tLoss: 0.000069\n",
            "Train Epoch: 24 [2880/35339 (8%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [3200/35339 (9%)]\tLoss: 0.000001\n",
            "Train Epoch: 24 [3520/35339 (10%)]\tLoss: 0.001676\n",
            "Train Epoch: 24 [3840/35339 (11%)]\tLoss: 0.001847\n",
            "Train Epoch: 24 [4160/35339 (12%)]\tLoss: 0.000017\n",
            "Train Epoch: 24 [4480/35339 (13%)]\tLoss: 0.000003\n",
            "Train Epoch: 24 [4800/35339 (14%)]\tLoss: 0.000001\n",
            "Train Epoch: 24 [5120/35339 (14%)]\tLoss: 0.000135\n",
            "Train Epoch: 24 [5440/35339 (15%)]\tLoss: 0.126178\n",
            "Train Epoch: 24 [5760/35339 (16%)]\tLoss: 0.000148\n",
            "Train Epoch: 24 [6080/35339 (17%)]\tLoss: 0.000010\n",
            "Train Epoch: 24 [6400/35339 (18%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [6720/35339 (19%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [7040/35339 (20%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [7360/35339 (21%)]\tLoss: 0.000021\n",
            "Train Epoch: 24 [7680/35339 (22%)]\tLoss: 0.004561\n",
            "Train Epoch: 24 [8000/35339 (23%)]\tLoss: 0.000004\n",
            "Train Epoch: 24 [8320/35339 (24%)]\tLoss: 0.000915\n",
            "Train Epoch: 24 [8640/35339 (24%)]\tLoss: 0.000002\n",
            "Train Epoch: 24 [8960/35339 (25%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [9280/35339 (26%)]\tLoss: 0.000039\n",
            "Train Epoch: 24 [9600/35339 (27%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [9920/35339 (28%)]\tLoss: 0.000003\n",
            "Train Epoch: 24 [10240/35339 (29%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [10560/35339 (30%)]\tLoss: 0.000468\n",
            "Train Epoch: 24 [10880/35339 (31%)]\tLoss: 0.000004\n",
            "Train Epoch: 24 [11200/35339 (32%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [11520/35339 (33%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [11840/35339 (33%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [12160/35339 (34%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [12480/35339 (35%)]\tLoss: 0.000003\n",
            "Train Epoch: 24 [12800/35339 (36%)]\tLoss: 0.000001\n",
            "Train Epoch: 24 [13120/35339 (37%)]\tLoss: 0.000011\n",
            "Train Epoch: 24 [13440/35339 (38%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [13760/35339 (39%)]\tLoss: 0.000027\n",
            "Train Epoch: 24 [14080/35339 (40%)]\tLoss: 0.000004\n",
            "Train Epoch: 24 [14400/35339 (41%)]\tLoss: 0.000129\n",
            "Train Epoch: 24 [14720/35339 (42%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [15040/35339 (43%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [15360/35339 (43%)]\tLoss: 0.000003\n",
            "Train Epoch: 24 [15680/35339 (44%)]\tLoss: 0.000002\n",
            "Train Epoch: 24 [16000/35339 (45%)]\tLoss: 0.000140\n",
            "Train Epoch: 24 [16320/35339 (46%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [16640/35339 (47%)]\tLoss: 0.000074\n",
            "Train Epoch: 24 [16960/35339 (48%)]\tLoss: 0.000200\n",
            "Train Epoch: 24 [17280/35339 (49%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [17600/35339 (50%)]\tLoss: 0.000003\n",
            "Train Epoch: 24 [17920/35339 (51%)]\tLoss: 0.154938\n",
            "Train Epoch: 24 [18240/35339 (52%)]\tLoss: 0.000008\n",
            "Train Epoch: 24 [18560/35339 (52%)]\tLoss: 0.000007\n",
            "Train Epoch: 24 [18880/35339 (53%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [19200/35339 (54%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [19520/35339 (55%)]\tLoss: 0.007133\n",
            "Train Epoch: 24 [19840/35339 (56%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [20160/35339 (57%)]\tLoss: 0.000006\n",
            "Train Epoch: 24 [20480/35339 (58%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [20800/35339 (59%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [21120/35339 (60%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [21440/35339 (61%)]\tLoss: 0.000233\n",
            "Train Epoch: 24 [21760/35339 (62%)]\tLoss: 0.000124\n",
            "Train Epoch: 24 [22080/35339 (62%)]\tLoss: 0.000120\n",
            "Train Epoch: 24 [22400/35339 (63%)]\tLoss: 0.000031\n",
            "Train Epoch: 24 [22720/35339 (64%)]\tLoss: 0.000374\n",
            "Train Epoch: 24 [23040/35339 (65%)]\tLoss: 0.000096\n",
            "Train Epoch: 24 [23360/35339 (66%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [23680/35339 (67%)]\tLoss: 0.000022\n",
            "Train Epoch: 24 [24000/35339 (68%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [24320/35339 (69%)]\tLoss: 0.000005\n",
            "Train Epoch: 24 [24640/35339 (70%)]\tLoss: 0.000046\n",
            "Train Epoch: 24 [24960/35339 (71%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [25280/35339 (71%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [25600/35339 (72%)]\tLoss: 0.000458\n",
            "Train Epoch: 24 [25920/35339 (73%)]\tLoss: 0.000018\n",
            "Train Epoch: 24 [26240/35339 (74%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [26560/35339 (75%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [26880/35339 (76%)]\tLoss: 0.000001\n",
            "Train Epoch: 24 [27200/35339 (77%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [27520/35339 (78%)]\tLoss: 0.000004\n",
            "Train Epoch: 24 [27840/35339 (79%)]\tLoss: 0.001115\n",
            "Train Epoch: 24 [28160/35339 (80%)]\tLoss: 0.000021\n",
            "Train Epoch: 24 [28480/35339 (81%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [28800/35339 (81%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [29120/35339 (82%)]\tLoss: 0.000025\n",
            "Train Epoch: 24 [29440/35339 (83%)]\tLoss: 0.000006\n",
            "Train Epoch: 24 [29760/35339 (84%)]\tLoss: 0.000019\n",
            "Train Epoch: 24 [30080/35339 (85%)]\tLoss: 0.000008\n",
            "Train Epoch: 24 [30400/35339 (86%)]\tLoss: 0.000031\n",
            "Train Epoch: 24 [30720/35339 (87%)]\tLoss: 0.000034\n",
            "Train Epoch: 24 [31040/35339 (88%)]\tLoss: 0.000143\n",
            "Train Epoch: 24 [31360/35339 (89%)]\tLoss: 0.039397\n",
            "Train Epoch: 24 [31680/35339 (90%)]\tLoss: 0.002557\n",
            "Train Epoch: 24 [32000/35339 (90%)]\tLoss: 0.000266\n",
            "Train Epoch: 24 [32320/35339 (91%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [32640/35339 (92%)]\tLoss: 0.000094\n",
            "Train Epoch: 24 [32960/35339 (93%)]\tLoss: 0.272787\n",
            "Train Epoch: 24 [33280/35339 (94%)]\tLoss: 0.000707\n",
            "Train Epoch: 24 [33600/35339 (95%)]\tLoss: 0.000000\n",
            "Train Epoch: 24 [33920/35339 (96%)]\tLoss: 0.000184\n",
            "Train Epoch: 24 [34240/35339 (97%)]\tLoss: 0.000103\n",
            "Train Epoch: 24 [34560/35339 (98%)]\tLoss: 0.000005\n",
            "Train Epoch: 24 [34880/35339 (99%)]\tLoss: 0.000203\n",
            "Train Epoch: 24 [35200/35339 (100%)]\tLoss: 0.034086\n",
            "\n",
            "Validation set: Average loss: 0.2441, Accuracy: 3729/3870 (96%)\n",
            "\n",
            "\n",
            "Saved model to model_24.pth.\n",
            "Train Epoch: 25 [0/35339 (0%)]\tLoss: 0.000046\n",
            "Train Epoch: 25 [320/35339 (1%)]\tLoss: 0.000021\n",
            "Train Epoch: 25 [640/35339 (2%)]\tLoss: 0.062319\n",
            "Train Epoch: 25 [960/35339 (3%)]\tLoss: 0.000000\n",
            "Train Epoch: 25 [1280/35339 (4%)]\tLoss: 0.000002\n",
            "Train Epoch: 25 [1600/35339 (5%)]\tLoss: 0.000004\n",
            "Train Epoch: 25 [1920/35339 (5%)]\tLoss: 0.005564\n",
            "Train Epoch: 25 [2240/35339 (6%)]\tLoss: 0.002686\n",
            "Train Epoch: 25 [2560/35339 (7%)]\tLoss: 0.013038\n",
            "Train Epoch: 25 [2880/35339 (8%)]\tLoss: 0.032409\n",
            "Train Epoch: 25 [3200/35339 (9%)]\tLoss: 0.000000\n",
            "Train Epoch: 25 [3520/35339 (10%)]\tLoss: 0.003192\n",
            "Train Epoch: 25 [3840/35339 (11%)]\tLoss: 0.000133\n",
            "Train Epoch: 25 [4160/35339 (12%)]\tLoss: 0.005780\n",
            "Train Epoch: 25 [4480/35339 (13%)]\tLoss: 0.000010\n",
            "Train Epoch: 25 [4800/35339 (14%)]\tLoss: 0.000097\n",
            "Train Epoch: 25 [5120/35339 (14%)]\tLoss: 0.000034\n",
            "Train Epoch: 25 [5440/35339 (15%)]\tLoss: 0.000001\n",
            "Train Epoch: 25 [5760/35339 (16%)]\tLoss: 0.000000\n",
            "Train Epoch: 25 [6080/35339 (17%)]\tLoss: 0.000000\n",
            "Train Epoch: 25 [6400/35339 (18%)]\tLoss: 0.000000\n",
            "Train Epoch: 25 [6720/35339 (19%)]\tLoss: 0.171379\n",
            "Train Epoch: 25 [7040/35339 (20%)]\tLoss: 0.000001\n",
            "Train Epoch: 25 [7360/35339 (21%)]\tLoss: 0.000021\n",
            "Train Epoch: 25 [7680/35339 (22%)]\tLoss: 0.040199\n",
            "Train Epoch: 25 [8000/35339 (23%)]\tLoss: 0.000000\n",
            "Train Epoch: 25 [8320/35339 (24%)]\tLoss: 0.000000\n",
            "Train Epoch: 25 [8640/35339 (24%)]\tLoss: 0.000000\n",
            "Train Epoch: 25 [8960/35339 (25%)]\tLoss: 0.000110\n",
            "Train Epoch: 25 [9280/35339 (26%)]\tLoss: 0.000814\n",
            "Train Epoch: 25 [9600/35339 (27%)]\tLoss: 0.000006\n",
            "Train Epoch: 25 [9920/35339 (28%)]\tLoss: 0.000000\n",
            "Train Epoch: 25 [10240/35339 (29%)]\tLoss: 0.000018\n",
            "Train Epoch: 25 [10560/35339 (30%)]\tLoss: 0.000132\n",
            "Train Epoch: 25 [10880/35339 (31%)]\tLoss: 0.000000\n",
            "Train Epoch: 25 [11200/35339 (32%)]\tLoss: 0.000008\n",
            "Train Epoch: 25 [11520/35339 (33%)]\tLoss: 0.010475\n",
            "Train Epoch: 25 [11840/35339 (33%)]\tLoss: 0.000007\n",
            "Train Epoch: 25 [12160/35339 (34%)]\tLoss: 0.000036\n",
            "Train Epoch: 25 [12480/35339 (35%)]\tLoss: 0.000000\n",
            "Train Epoch: 25 [12800/35339 (36%)]\tLoss: 0.000112\n",
            "Train Epoch: 25 [13120/35339 (37%)]\tLoss: 0.000002\n",
            "Train Epoch: 25 [13440/35339 (38%)]\tLoss: 0.000080\n",
            "Train Epoch: 25 [13760/35339 (39%)]\tLoss: 0.005989\n",
            "Train Epoch: 25 [14080/35339 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 25 [14400/35339 (41%)]\tLoss: 0.000005\n",
            "Train Epoch: 25 [14720/35339 (42%)]\tLoss: 0.001258\n",
            "Train Epoch: 25 [15040/35339 (43%)]\tLoss: 0.000024\n",
            "Train Epoch: 25 [15360/35339 (43%)]\tLoss: 0.060216\n",
            "Train Epoch: 25 [15680/35339 (44%)]\tLoss: 0.003967\n",
            "Train Epoch: 25 [16000/35339 (45%)]\tLoss: 0.000001\n",
            "Train Epoch: 25 [16320/35339 (46%)]\tLoss: 0.001140\n",
            "Train Epoch: 25 [16640/35339 (47%)]\tLoss: 0.029705\n",
            "Train Epoch: 25 [16960/35339 (48%)]\tLoss: 0.001060\n",
            "Train Epoch: 25 [17280/35339 (49%)]\tLoss: 0.000000\n",
            "Train Epoch: 25 [17600/35339 (50%)]\tLoss: 0.000228\n",
            "Train Epoch: 25 [17920/35339 (51%)]\tLoss: 0.000000\n",
            "Train Epoch: 25 [18240/35339 (52%)]\tLoss: 0.000011\n",
            "Train Epoch: 25 [18560/35339 (52%)]\tLoss: 0.000000\n",
            "Train Epoch: 25 [18880/35339 (53%)]\tLoss: 0.000085\n",
            "Train Epoch: 25 [19200/35339 (54%)]\tLoss: 0.000000\n",
            "Train Epoch: 25 [19520/35339 (55%)]\tLoss: 0.000077\n",
            "Train Epoch: 25 [19840/35339 (56%)]\tLoss: 0.000000\n",
            "Train Epoch: 25 [20160/35339 (57%)]\tLoss: 0.001856\n",
            "Train Epoch: 25 [20480/35339 (58%)]\tLoss: 0.000132\n",
            "Train Epoch: 25 [20800/35339 (59%)]\tLoss: 0.000000\n",
            "Train Epoch: 25 [21120/35339 (60%)]\tLoss: 0.000000\n",
            "Train Epoch: 25 [21440/35339 (61%)]\tLoss: 0.001177\n",
            "Train Epoch: 25 [21760/35339 (62%)]\tLoss: 0.001616\n",
            "Train Epoch: 25 [22080/35339 (62%)]\tLoss: 0.000010\n",
            "Train Epoch: 25 [22400/35339 (63%)]\tLoss: 0.000000\n",
            "Train Epoch: 25 [22720/35339 (64%)]\tLoss: 0.000000\n",
            "Train Epoch: 25 [23040/35339 (65%)]\tLoss: 0.000000\n",
            "Train Epoch: 25 [23360/35339 (66%)]\tLoss: 0.070981\n",
            "Train Epoch: 25 [23680/35339 (67%)]\tLoss: 0.000014\n",
            "Train Epoch: 25 [24000/35339 (68%)]\tLoss: 0.000870\n",
            "Train Epoch: 25 [24320/35339 (69%)]\tLoss: 0.000291\n",
            "Train Epoch: 25 [24640/35339 (70%)]\tLoss: 0.000001\n",
            "Train Epoch: 25 [24960/35339 (71%)]\tLoss: 0.000010\n",
            "Train Epoch: 25 [25280/35339 (71%)]\tLoss: 0.000102\n",
            "Train Epoch: 25 [25600/35339 (72%)]\tLoss: 0.000000\n",
            "Train Epoch: 25 [25920/35339 (73%)]\tLoss: 0.000000\n",
            "Train Epoch: 25 [26240/35339 (74%)]\tLoss: 0.140323\n",
            "Train Epoch: 25 [26560/35339 (75%)]\tLoss: 0.000629\n",
            "Train Epoch: 25 [26880/35339 (76%)]\tLoss: 0.000002\n",
            "Train Epoch: 25 [27200/35339 (77%)]\tLoss: 0.000007\n",
            "Train Epoch: 25 [27520/35339 (78%)]\tLoss: 0.000000\n",
            "Train Epoch: 25 [27840/35339 (79%)]\tLoss: 0.000134\n",
            "Train Epoch: 25 [28160/35339 (80%)]\tLoss: 0.000019\n",
            "Train Epoch: 25 [28480/35339 (81%)]\tLoss: 0.021898\n",
            "Train Epoch: 25 [28800/35339 (81%)]\tLoss: 0.000000\n",
            "Train Epoch: 25 [29120/35339 (82%)]\tLoss: 0.000000\n",
            "Train Epoch: 25 [29440/35339 (83%)]\tLoss: 0.000003\n",
            "Train Epoch: 25 [29760/35339 (84%)]\tLoss: 0.000000\n",
            "Train Epoch: 25 [30080/35339 (85%)]\tLoss: 0.000000\n",
            "Train Epoch: 25 [30400/35339 (86%)]\tLoss: 0.000084\n",
            "Train Epoch: 25 [30720/35339 (87%)]\tLoss: 0.000000\n",
            "Train Epoch: 25 [31040/35339 (88%)]\tLoss: 0.017205\n",
            "Train Epoch: 25 [31360/35339 (89%)]\tLoss: 0.000002\n",
            "Train Epoch: 25 [31680/35339 (90%)]\tLoss: 0.000001\n",
            "Train Epoch: 25 [32000/35339 (90%)]\tLoss: 0.004034\n",
            "Train Epoch: 25 [32320/35339 (91%)]\tLoss: 0.001575\n",
            "Train Epoch: 25 [32640/35339 (92%)]\tLoss: 0.007135\n",
            "Train Epoch: 25 [32960/35339 (93%)]\tLoss: 0.000005\n",
            "Train Epoch: 25 [33280/35339 (94%)]\tLoss: 0.000000\n",
            "Train Epoch: 25 [33600/35339 (95%)]\tLoss: 0.001576\n",
            "Train Epoch: 25 [33920/35339 (96%)]\tLoss: 0.000000\n",
            "Train Epoch: 25 [34240/35339 (97%)]\tLoss: 0.000014\n",
            "Train Epoch: 25 [34560/35339 (98%)]\tLoss: 0.106875\n",
            "Train Epoch: 25 [34880/35339 (99%)]\tLoss: 0.000002\n",
            "Train Epoch: 25 [35200/35339 (100%)]\tLoss: 0.000001\n",
            "\n",
            "Validation set: Average loss: 0.1722, Accuracy: 3775/3870 (98%)\n",
            "\n",
            "\n",
            "Saved model to model_25.pth.\n",
            "Train Epoch: 26 [0/35339 (0%)]\tLoss: 0.000001\n",
            "Train Epoch: 26 [320/35339 (1%)]\tLoss: 0.000000\n",
            "Train Epoch: 26 [640/35339 (2%)]\tLoss: 0.000000\n",
            "Train Epoch: 26 [960/35339 (3%)]\tLoss: 0.000000\n",
            "Train Epoch: 26 [1280/35339 (4%)]\tLoss: 0.035025\n",
            "Train Epoch: 26 [1600/35339 (5%)]\tLoss: 0.017141\n",
            "Train Epoch: 26 [1920/35339 (5%)]\tLoss: 0.000049\n",
            "Train Epoch: 26 [2240/35339 (6%)]\tLoss: 0.004463\n",
            "Train Epoch: 26 [2560/35339 (7%)]\tLoss: 0.000106\n",
            "Train Epoch: 26 [2880/35339 (8%)]\tLoss: 0.051200\n",
            "Train Epoch: 26 [3200/35339 (9%)]\tLoss: 0.002147\n",
            "Train Epoch: 26 [3520/35339 (10%)]\tLoss: 0.007075\n",
            "Train Epoch: 26 [3840/35339 (11%)]\tLoss: 0.012509\n",
            "Train Epoch: 26 [4160/35339 (12%)]\tLoss: 0.000000\n",
            "Train Epoch: 26 [4480/35339 (13%)]\tLoss: 0.002436\n",
            "Train Epoch: 26 [4800/35339 (14%)]\tLoss: 0.000700\n",
            "Train Epoch: 26 [5120/35339 (14%)]\tLoss: 0.000000\n",
            "Train Epoch: 26 [5440/35339 (15%)]\tLoss: 0.023432\n",
            "Train Epoch: 26 [5760/35339 (16%)]\tLoss: 0.000164\n",
            "Train Epoch: 26 [6080/35339 (17%)]\tLoss: 0.000001\n",
            "Train Epoch: 26 [6400/35339 (18%)]\tLoss: 0.000173\n",
            "Train Epoch: 26 [6720/35339 (19%)]\tLoss: 0.015813\n",
            "Train Epoch: 26 [7040/35339 (20%)]\tLoss: 0.000467\n",
            "Train Epoch: 26 [7360/35339 (21%)]\tLoss: 0.000003\n",
            "Train Epoch: 26 [7680/35339 (22%)]\tLoss: 0.000002\n",
            "Train Epoch: 26 [8000/35339 (23%)]\tLoss: 0.000002\n",
            "Train Epoch: 26 [8320/35339 (24%)]\tLoss: 0.000391\n",
            "Train Epoch: 26 [8640/35339 (24%)]\tLoss: 0.000000\n",
            "Train Epoch: 26 [8960/35339 (25%)]\tLoss: 0.000001\n",
            "Train Epoch: 26 [9280/35339 (26%)]\tLoss: 0.101635\n",
            "Train Epoch: 26 [9600/35339 (27%)]\tLoss: 0.000021\n",
            "Train Epoch: 26 [9920/35339 (28%)]\tLoss: 0.000003\n",
            "Train Epoch: 26 [10240/35339 (29%)]\tLoss: 0.000239\n",
            "Train Epoch: 26 [10560/35339 (30%)]\tLoss: 0.000445\n",
            "Train Epoch: 26 [10880/35339 (31%)]\tLoss: 0.027066\n",
            "Train Epoch: 26 [11200/35339 (32%)]\tLoss: 0.019094\n",
            "Train Epoch: 26 [11520/35339 (33%)]\tLoss: 0.007716\n",
            "Train Epoch: 26 [11840/35339 (33%)]\tLoss: 0.004230\n",
            "Train Epoch: 26 [12160/35339 (34%)]\tLoss: 0.000000\n",
            "Train Epoch: 26 [12480/35339 (35%)]\tLoss: 0.000000\n",
            "Train Epoch: 26 [12800/35339 (36%)]\tLoss: 0.000001\n",
            "Train Epoch: 26 [13120/35339 (37%)]\tLoss: 0.000000\n",
            "Train Epoch: 26 [13440/35339 (38%)]\tLoss: 0.104823\n",
            "Train Epoch: 26 [13760/35339 (39%)]\tLoss: 0.000170\n",
            "Train Epoch: 26 [14080/35339 (40%)]\tLoss: 0.000539\n",
            "Train Epoch: 26 [14400/35339 (41%)]\tLoss: 0.000015\n",
            "Train Epoch: 26 [14720/35339 (42%)]\tLoss: 0.000000\n",
            "Train Epoch: 26 [15040/35339 (43%)]\tLoss: 0.000000\n",
            "Train Epoch: 26 [15360/35339 (43%)]\tLoss: 0.000004\n",
            "Train Epoch: 26 [15680/35339 (44%)]\tLoss: 0.069003\n",
            "Train Epoch: 26 [16000/35339 (45%)]\tLoss: 0.000006\n",
            "Train Epoch: 26 [16320/35339 (46%)]\tLoss: 0.000023\n",
            "Train Epoch: 26 [16640/35339 (47%)]\tLoss: 0.000013\n",
            "Train Epoch: 26 [16960/35339 (48%)]\tLoss: 0.007308\n",
            "Train Epoch: 26 [17280/35339 (49%)]\tLoss: 0.000150\n",
            "Train Epoch: 26 [17600/35339 (50%)]\tLoss: 0.256014\n",
            "Train Epoch: 26 [17920/35339 (51%)]\tLoss: 0.000001\n",
            "Train Epoch: 26 [18240/35339 (52%)]\tLoss: 0.017871\n",
            "Train Epoch: 26 [18560/35339 (52%)]\tLoss: 0.002428\n",
            "Train Epoch: 26 [18880/35339 (53%)]\tLoss: 0.024245\n",
            "Train Epoch: 26 [19200/35339 (54%)]\tLoss: 0.000000\n",
            "Train Epoch: 26 [19520/35339 (55%)]\tLoss: 0.000147\n",
            "Train Epoch: 26 [19840/35339 (56%)]\tLoss: 0.000011\n",
            "Train Epoch: 26 [20160/35339 (57%)]\tLoss: 0.000001\n",
            "Train Epoch: 26 [20480/35339 (58%)]\tLoss: 0.000001\n",
            "Train Epoch: 26 [20800/35339 (59%)]\tLoss: 0.000005\n",
            "Train Epoch: 26 [21120/35339 (60%)]\tLoss: 0.000003\n",
            "Train Epoch: 26 [21440/35339 (61%)]\tLoss: 0.056287\n",
            "Train Epoch: 26 [21760/35339 (62%)]\tLoss: 0.000000\n",
            "Train Epoch: 26 [22080/35339 (62%)]\tLoss: 0.000001\n",
            "Train Epoch: 26 [22400/35339 (63%)]\tLoss: 0.000000\n",
            "Train Epoch: 26 [22720/35339 (64%)]\tLoss: 0.000006\n",
            "Train Epoch: 26 [23040/35339 (65%)]\tLoss: 0.000000\n",
            "Train Epoch: 26 [23360/35339 (66%)]\tLoss: 0.000000\n",
            "Train Epoch: 26 [23680/35339 (67%)]\tLoss: 0.000066\n",
            "Train Epoch: 26 [24000/35339 (68%)]\tLoss: 0.000002\n",
            "Train Epoch: 26 [24320/35339 (69%)]\tLoss: 0.124760\n",
            "Train Epoch: 26 [24640/35339 (70%)]\tLoss: 0.000002\n",
            "Train Epoch: 26 [24960/35339 (71%)]\tLoss: 0.000291\n",
            "Train Epoch: 26 [25280/35339 (71%)]\tLoss: 0.000009\n",
            "Train Epoch: 26 [25600/35339 (72%)]\tLoss: 0.000000\n",
            "Train Epoch: 26 [25920/35339 (73%)]\tLoss: 0.000077\n",
            "Train Epoch: 26 [26240/35339 (74%)]\tLoss: 0.000000\n",
            "Train Epoch: 26 [26560/35339 (75%)]\tLoss: 0.000000\n",
            "Train Epoch: 26 [26880/35339 (76%)]\tLoss: 0.000001\n",
            "Train Epoch: 26 [27200/35339 (77%)]\tLoss: 0.000117\n",
            "Train Epoch: 26 [27520/35339 (78%)]\tLoss: 0.000003\n",
            "Train Epoch: 26 [27840/35339 (79%)]\tLoss: 0.000085\n",
            "Train Epoch: 26 [28160/35339 (80%)]\tLoss: 0.000137\n",
            "Train Epoch: 26 [28480/35339 (81%)]\tLoss: 0.000000\n",
            "Train Epoch: 26 [28800/35339 (81%)]\tLoss: 0.000051\n",
            "Train Epoch: 26 [29120/35339 (82%)]\tLoss: 0.001267\n",
            "Train Epoch: 26 [29440/35339 (83%)]\tLoss: 0.000001\n",
            "Train Epoch: 26 [29760/35339 (84%)]\tLoss: 0.000001\n",
            "Train Epoch: 26 [30080/35339 (85%)]\tLoss: 0.004931\n",
            "Train Epoch: 26 [30400/35339 (86%)]\tLoss: 0.000008\n",
            "Train Epoch: 26 [30720/35339 (87%)]\tLoss: 0.000006\n",
            "Train Epoch: 26 [31040/35339 (88%)]\tLoss: 0.000000\n",
            "Train Epoch: 26 [31360/35339 (89%)]\tLoss: 0.000286\n",
            "Train Epoch: 26 [31680/35339 (90%)]\tLoss: 0.000000\n",
            "Train Epoch: 26 [32000/35339 (90%)]\tLoss: 1.067591\n",
            "Train Epoch: 26 [32320/35339 (91%)]\tLoss: 0.000005\n",
            "Train Epoch: 26 [32640/35339 (92%)]\tLoss: 0.000069\n",
            "Train Epoch: 26 [32960/35339 (93%)]\tLoss: 0.000001\n",
            "Train Epoch: 26 [33280/35339 (94%)]\tLoss: 0.000754\n",
            "Train Epoch: 26 [33600/35339 (95%)]\tLoss: 0.000000\n",
            "Train Epoch: 26 [33920/35339 (96%)]\tLoss: 0.000000\n",
            "Train Epoch: 26 [34240/35339 (97%)]\tLoss: 0.000162\n",
            "Train Epoch: 26 [34560/35339 (98%)]\tLoss: 0.000001\n",
            "Train Epoch: 26 [34880/35339 (99%)]\tLoss: 0.000037\n",
            "Train Epoch: 26 [35200/35339 (100%)]\tLoss: 0.059473\n",
            "\n",
            "Validation set: Average loss: 0.2734, Accuracy: 3746/3870 (97%)\n",
            "\n",
            "\n",
            "Saved model to model_26.pth.\n",
            "Train Epoch: 27 [0/35339 (0%)]\tLoss: 0.001528\n",
            "Train Epoch: 27 [320/35339 (1%)]\tLoss: 0.083056\n",
            "Train Epoch: 27 [640/35339 (2%)]\tLoss: 0.000510\n",
            "Train Epoch: 27 [960/35339 (3%)]\tLoss: 0.507869\n",
            "Train Epoch: 27 [1280/35339 (4%)]\tLoss: 0.000005\n",
            "Train Epoch: 27 [1600/35339 (5%)]\tLoss: 0.000004\n",
            "Train Epoch: 27 [1920/35339 (5%)]\tLoss: 0.000004\n",
            "Train Epoch: 27 [2240/35339 (6%)]\tLoss: 0.000103\n",
            "Train Epoch: 27 [2560/35339 (7%)]\tLoss: 0.000004\n",
            "Train Epoch: 27 [2880/35339 (8%)]\tLoss: 0.000000\n",
            "Train Epoch: 27 [3200/35339 (9%)]\tLoss: 0.000009\n",
            "Train Epoch: 27 [3520/35339 (10%)]\tLoss: 0.000005\n",
            "Train Epoch: 27 [3840/35339 (11%)]\tLoss: 0.016874\n",
            "Train Epoch: 27 [4160/35339 (12%)]\tLoss: 0.001519\n",
            "Train Epoch: 27 [4480/35339 (13%)]\tLoss: 0.000001\n",
            "Train Epoch: 27 [4800/35339 (14%)]\tLoss: 0.000001\n",
            "Train Epoch: 27 [5120/35339 (14%)]\tLoss: 0.000001\n",
            "Train Epoch: 27 [5440/35339 (15%)]\tLoss: 0.000000\n",
            "Train Epoch: 27 [5760/35339 (16%)]\tLoss: 0.000004\n",
            "Train Epoch: 27 [6080/35339 (17%)]\tLoss: 0.006950\n",
            "Train Epoch: 27 [6400/35339 (18%)]\tLoss: 0.000025\n",
            "Train Epoch: 27 [6720/35339 (19%)]\tLoss: 0.000000\n",
            "Train Epoch: 27 [7040/35339 (20%)]\tLoss: 0.000000\n",
            "Train Epoch: 27 [7360/35339 (21%)]\tLoss: 0.000001\n",
            "Train Epoch: 27 [7680/35339 (22%)]\tLoss: 0.000122\n",
            "Train Epoch: 27 [8000/35339 (23%)]\tLoss: 0.000000\n",
            "Train Epoch: 27 [8320/35339 (24%)]\tLoss: 0.043192\n",
            "Train Epoch: 27 [8640/35339 (24%)]\tLoss: 0.000064\n",
            "Train Epoch: 27 [8960/35339 (25%)]\tLoss: 0.061184\n",
            "Train Epoch: 27 [9280/35339 (26%)]\tLoss: 0.000001\n",
            "Train Epoch: 27 [9600/35339 (27%)]\tLoss: 0.000012\n",
            "Train Epoch: 27 [9920/35339 (28%)]\tLoss: 0.000001\n",
            "Train Epoch: 27 [10240/35339 (29%)]\tLoss: 0.002238\n",
            "Train Epoch: 27 [10560/35339 (30%)]\tLoss: 0.000000\n",
            "Train Epoch: 27 [10880/35339 (31%)]\tLoss: 0.001045\n",
            "Train Epoch: 27 [11200/35339 (32%)]\tLoss: 0.023275\n",
            "Train Epoch: 27 [11520/35339 (33%)]\tLoss: 0.000000\n",
            "Train Epoch: 27 [11840/35339 (33%)]\tLoss: 0.000145\n",
            "Train Epoch: 27 [12160/35339 (34%)]\tLoss: 0.064730\n",
            "Train Epoch: 27 [12480/35339 (35%)]\tLoss: 0.000000\n",
            "Train Epoch: 27 [12800/35339 (36%)]\tLoss: 0.000000\n",
            "Train Epoch: 27 [13120/35339 (37%)]\tLoss: 0.171773\n",
            "Train Epoch: 27 [13440/35339 (38%)]\tLoss: 0.000001\n",
            "Train Epoch: 27 [13760/35339 (39%)]\tLoss: 0.000003\n",
            "Train Epoch: 27 [14080/35339 (40%)]\tLoss: 0.004301\n",
            "Train Epoch: 27 [14400/35339 (41%)]\tLoss: 0.074468\n",
            "Train Epoch: 27 [14720/35339 (42%)]\tLoss: 0.000000\n",
            "Train Epoch: 27 [15040/35339 (43%)]\tLoss: 0.000498\n",
            "Train Epoch: 27 [15360/35339 (43%)]\tLoss: 0.118820\n",
            "Train Epoch: 27 [15680/35339 (44%)]\tLoss: 0.000001\n",
            "Train Epoch: 27 [16000/35339 (45%)]\tLoss: 0.000015\n",
            "Train Epoch: 27 [16320/35339 (46%)]\tLoss: 0.000371\n",
            "Train Epoch: 27 [16640/35339 (47%)]\tLoss: 0.000000\n",
            "Train Epoch: 27 [16960/35339 (48%)]\tLoss: 0.000001\n",
            "Train Epoch: 27 [17280/35339 (49%)]\tLoss: 0.002280\n",
            "Train Epoch: 27 [17600/35339 (50%)]\tLoss: 0.009657\n",
            "Train Epoch: 27 [17920/35339 (51%)]\tLoss: 0.000058\n",
            "Train Epoch: 27 [18240/35339 (52%)]\tLoss: 0.000007\n",
            "Train Epoch: 27 [18560/35339 (52%)]\tLoss: 0.000003\n",
            "Train Epoch: 27 [18880/35339 (53%)]\tLoss: 0.000005\n",
            "Train Epoch: 27 [19200/35339 (54%)]\tLoss: 0.000212\n",
            "Train Epoch: 27 [19520/35339 (55%)]\tLoss: 0.000088\n",
            "Train Epoch: 27 [19840/35339 (56%)]\tLoss: 0.000001\n",
            "Train Epoch: 27 [20160/35339 (57%)]\tLoss: 0.000000\n",
            "Train Epoch: 27 [20480/35339 (58%)]\tLoss: 0.000071\n",
            "Train Epoch: 27 [20800/35339 (59%)]\tLoss: 0.000885\n",
            "Train Epoch: 27 [21120/35339 (60%)]\tLoss: 0.000002\n",
            "Train Epoch: 27 [21440/35339 (61%)]\tLoss: 0.000000\n",
            "Train Epoch: 27 [21760/35339 (62%)]\tLoss: 0.001656\n",
            "Train Epoch: 27 [22080/35339 (62%)]\tLoss: 0.000046\n",
            "Train Epoch: 27 [22400/35339 (63%)]\tLoss: 0.000001\n",
            "Train Epoch: 27 [22720/35339 (64%)]\tLoss: 0.000005\n",
            "Train Epoch: 27 [23040/35339 (65%)]\tLoss: 0.233765\n",
            "Train Epoch: 27 [23360/35339 (66%)]\tLoss: 0.000090\n",
            "Train Epoch: 27 [23680/35339 (67%)]\tLoss: 0.000000\n",
            "Train Epoch: 27 [24000/35339 (68%)]\tLoss: 0.000041\n",
            "Train Epoch: 27 [24320/35339 (69%)]\tLoss: 0.073474\n",
            "Train Epoch: 27 [24640/35339 (70%)]\tLoss: 0.000000\n",
            "Train Epoch: 27 [24960/35339 (71%)]\tLoss: 0.000000\n",
            "Train Epoch: 27 [25280/35339 (71%)]\tLoss: 0.000000\n",
            "Train Epoch: 27 [25600/35339 (72%)]\tLoss: 0.000129\n",
            "Train Epoch: 27 [25920/35339 (73%)]\tLoss: 0.001475\n",
            "Train Epoch: 27 [26240/35339 (74%)]\tLoss: 0.000000\n",
            "Train Epoch: 27 [26560/35339 (75%)]\tLoss: 0.000012\n",
            "Train Epoch: 27 [26880/35339 (76%)]\tLoss: 0.000001\n",
            "Train Epoch: 27 [27200/35339 (77%)]\tLoss: 0.001250\n",
            "Train Epoch: 27 [27520/35339 (78%)]\tLoss: 0.000002\n",
            "Train Epoch: 27 [27840/35339 (79%)]\tLoss: 0.002501\n",
            "Train Epoch: 27 [28160/35339 (80%)]\tLoss: 0.000001\n",
            "Train Epoch: 27 [28480/35339 (81%)]\tLoss: 0.127650\n",
            "Train Epoch: 27 [28800/35339 (81%)]\tLoss: 0.000000\n",
            "Train Epoch: 27 [29120/35339 (82%)]\tLoss: 0.000000\n",
            "Train Epoch: 27 [29440/35339 (83%)]\tLoss: 0.000116\n",
            "Train Epoch: 27 [29760/35339 (84%)]\tLoss: 0.000056\n",
            "Train Epoch: 27 [30080/35339 (85%)]\tLoss: 0.000432\n",
            "Train Epoch: 27 [30400/35339 (86%)]\tLoss: 0.000054\n",
            "Train Epoch: 27 [30720/35339 (87%)]\tLoss: 0.000384\n",
            "Train Epoch: 27 [31040/35339 (88%)]\tLoss: 0.029468\n",
            "Train Epoch: 27 [31360/35339 (89%)]\tLoss: 0.000006\n",
            "Train Epoch: 27 [31680/35339 (90%)]\tLoss: 0.000254\n",
            "Train Epoch: 27 [32000/35339 (90%)]\tLoss: 0.000076\n",
            "Train Epoch: 27 [32320/35339 (91%)]\tLoss: 0.005997\n",
            "Train Epoch: 27 [32640/35339 (92%)]\tLoss: 0.022899\n",
            "Train Epoch: 27 [32960/35339 (93%)]\tLoss: 0.000000\n",
            "Train Epoch: 27 [33280/35339 (94%)]\tLoss: 0.000000\n",
            "Train Epoch: 27 [33600/35339 (95%)]\tLoss: 0.003425\n",
            "Train Epoch: 27 [33920/35339 (96%)]\tLoss: 0.000328\n",
            "Train Epoch: 27 [34240/35339 (97%)]\tLoss: 0.000008\n",
            "Train Epoch: 27 [34560/35339 (98%)]\tLoss: 0.000045\n",
            "Train Epoch: 27 [34880/35339 (99%)]\tLoss: 0.000001\n",
            "Train Epoch: 27 [35200/35339 (100%)]\tLoss: 0.000023\n",
            "\n",
            "Validation set: Average loss: 0.2153, Accuracy: 3749/3870 (97%)\n",
            "\n",
            "\n",
            "Saved model to model_27.pth.\n",
            "Train Epoch: 28 [0/35339 (0%)]\tLoss: 0.000042\n",
            "Train Epoch: 28 [320/35339 (1%)]\tLoss: 0.000000\n",
            "Train Epoch: 28 [640/35339 (2%)]\tLoss: 0.000000\n",
            "Train Epoch: 28 [960/35339 (3%)]\tLoss: 0.000000\n",
            "Train Epoch: 28 [1280/35339 (4%)]\tLoss: 0.000000\n",
            "Train Epoch: 28 [1600/35339 (5%)]\tLoss: 0.010965\n",
            "Train Epoch: 28 [1920/35339 (5%)]\tLoss: 0.000223\n",
            "Train Epoch: 28 [2240/35339 (6%)]\tLoss: 0.010852\n",
            "Train Epoch: 28 [2560/35339 (7%)]\tLoss: 0.000064\n",
            "Train Epoch: 28 [2880/35339 (8%)]\tLoss: 0.001541\n",
            "Train Epoch: 28 [3200/35339 (9%)]\tLoss: 0.000169\n",
            "Train Epoch: 28 [3520/35339 (10%)]\tLoss: 0.000000\n",
            "Train Epoch: 28 [3840/35339 (11%)]\tLoss: 0.000017\n",
            "Train Epoch: 28 [4160/35339 (12%)]\tLoss: 0.000246\n",
            "Train Epoch: 28 [4480/35339 (13%)]\tLoss: 0.000000\n",
            "Train Epoch: 28 [4800/35339 (14%)]\tLoss: 0.000000\n",
            "Train Epoch: 28 [5120/35339 (14%)]\tLoss: 0.000114\n",
            "Train Epoch: 28 [5440/35339 (15%)]\tLoss: 0.000003\n",
            "Train Epoch: 28 [5760/35339 (16%)]\tLoss: 0.000000\n",
            "Train Epoch: 28 [6080/35339 (17%)]\tLoss: 0.000000\n",
            "Train Epoch: 28 [6400/35339 (18%)]\tLoss: 0.000000\n",
            "Train Epoch: 28 [6720/35339 (19%)]\tLoss: 0.561070\n",
            "Train Epoch: 28 [7040/35339 (20%)]\tLoss: 0.001149\n",
            "Train Epoch: 28 [7360/35339 (21%)]\tLoss: 0.000034\n",
            "Train Epoch: 28 [7680/35339 (22%)]\tLoss: 0.000000\n",
            "Train Epoch: 28 [8000/35339 (23%)]\tLoss: 0.000216\n",
            "Train Epoch: 28 [8320/35339 (24%)]\tLoss: 0.000033\n",
            "Train Epoch: 28 [8640/35339 (24%)]\tLoss: 0.000027\n",
            "Train Epoch: 28 [8960/35339 (25%)]\tLoss: 0.007837\n",
            "Train Epoch: 28 [9280/35339 (26%)]\tLoss: 0.000011\n",
            "Train Epoch: 28 [9600/35339 (27%)]\tLoss: 0.000009\n",
            "Train Epoch: 28 [9920/35339 (28%)]\tLoss: 0.000000\n",
            "Train Epoch: 28 [10240/35339 (29%)]\tLoss: 0.000000\n",
            "Train Epoch: 28 [10560/35339 (30%)]\tLoss: 0.000000\n",
            "Train Epoch: 28 [10880/35339 (31%)]\tLoss: 0.222633\n",
            "Train Epoch: 28 [11200/35339 (32%)]\tLoss: 0.000000\n",
            "Train Epoch: 28 [11520/35339 (33%)]\tLoss: 0.000000\n",
            "Train Epoch: 28 [11840/35339 (33%)]\tLoss: 0.000012\n",
            "Train Epoch: 28 [12160/35339 (34%)]\tLoss: 0.001232\n",
            "Train Epoch: 28 [12480/35339 (35%)]\tLoss: 0.002799\n",
            "Train Epoch: 28 [12800/35339 (36%)]\tLoss: 0.000000\n",
            "Train Epoch: 28 [13120/35339 (37%)]\tLoss: 0.000000\n",
            "Train Epoch: 28 [13440/35339 (38%)]\tLoss: 0.000000\n",
            "Train Epoch: 28 [13760/35339 (39%)]\tLoss: 0.000469\n",
            "Train Epoch: 28 [14080/35339 (40%)]\tLoss: 0.000001\n",
            "Train Epoch: 28 [14400/35339 (41%)]\tLoss: 0.000004\n",
            "Train Epoch: 28 [14720/35339 (42%)]\tLoss: 0.000001\n",
            "Train Epoch: 28 [15040/35339 (43%)]\tLoss: 0.000009\n",
            "Train Epoch: 28 [15360/35339 (43%)]\tLoss: 0.000000\n",
            "Train Epoch: 28 [15680/35339 (44%)]\tLoss: 0.000006\n",
            "Train Epoch: 28 [16000/35339 (45%)]\tLoss: 0.000017\n",
            "Train Epoch: 28 [16320/35339 (46%)]\tLoss: 0.000087\n",
            "Train Epoch: 28 [16640/35339 (47%)]\tLoss: 0.000044\n",
            "Train Epoch: 28 [16960/35339 (48%)]\tLoss: 0.000000\n",
            "Train Epoch: 28 [17280/35339 (49%)]\tLoss: 0.006774\n",
            "Train Epoch: 28 [17600/35339 (50%)]\tLoss: 0.000583\n",
            "Train Epoch: 28 [17920/35339 (51%)]\tLoss: 0.007239\n",
            "Train Epoch: 28 [18240/35339 (52%)]\tLoss: 0.000012\n",
            "Train Epoch: 28 [18560/35339 (52%)]\tLoss: 0.282616\n",
            "Train Epoch: 28 [18880/35339 (53%)]\tLoss: 0.000001\n",
            "Train Epoch: 28 [19200/35339 (54%)]\tLoss: 0.000001\n",
            "Train Epoch: 28 [19520/35339 (55%)]\tLoss: 0.000437\n",
            "Train Epoch: 28 [19840/35339 (56%)]\tLoss: 0.002428\n",
            "Train Epoch: 28 [20160/35339 (57%)]\tLoss: 0.000025\n",
            "Train Epoch: 28 [20480/35339 (58%)]\tLoss: 0.000014\n",
            "Train Epoch: 28 [20800/35339 (59%)]\tLoss: 0.000020\n",
            "Train Epoch: 28 [21120/35339 (60%)]\tLoss: 0.000000\n",
            "Train Epoch: 28 [21440/35339 (61%)]\tLoss: 0.000014\n",
            "Train Epoch: 28 [21760/35339 (62%)]\tLoss: 0.004615\n",
            "Train Epoch: 28 [22080/35339 (62%)]\tLoss: 0.000241\n",
            "Train Epoch: 28 [22400/35339 (63%)]\tLoss: 0.075356\n",
            "Train Epoch: 28 [22720/35339 (64%)]\tLoss: 0.000163\n",
            "Train Epoch: 28 [23040/35339 (65%)]\tLoss: 0.000553\n",
            "Train Epoch: 28 [23360/35339 (66%)]\tLoss: 0.043757\n",
            "Train Epoch: 28 [23680/35339 (67%)]\tLoss: 0.001301\n",
            "Train Epoch: 28 [24000/35339 (68%)]\tLoss: 0.000002\n",
            "Train Epoch: 28 [24320/35339 (69%)]\tLoss: 0.000029\n",
            "Train Epoch: 28 [24640/35339 (70%)]\tLoss: 0.000082\n",
            "Train Epoch: 28 [24960/35339 (71%)]\tLoss: 0.011076\n",
            "Train Epoch: 28 [25280/35339 (71%)]\tLoss: 0.000019\n",
            "Train Epoch: 28 [25600/35339 (72%)]\tLoss: 0.000000\n",
            "Train Epoch: 28 [25920/35339 (73%)]\tLoss: 0.000000\n",
            "Train Epoch: 28 [26240/35339 (74%)]\tLoss: 0.002556\n",
            "Train Epoch: 28 [26560/35339 (75%)]\tLoss: 0.000016\n",
            "Train Epoch: 28 [26880/35339 (76%)]\tLoss: 0.000002\n",
            "Train Epoch: 28 [27200/35339 (77%)]\tLoss: 0.000080\n",
            "Train Epoch: 28 [27520/35339 (78%)]\tLoss: 0.000002\n",
            "Train Epoch: 28 [27840/35339 (79%)]\tLoss: 0.000004\n",
            "Train Epoch: 28 [28160/35339 (80%)]\tLoss: 0.000000\n",
            "Train Epoch: 28 [28480/35339 (81%)]\tLoss: 0.000001\n",
            "Train Epoch: 28 [28800/35339 (81%)]\tLoss: 0.217528\n",
            "Train Epoch: 28 [29120/35339 (82%)]\tLoss: 0.000011\n",
            "Train Epoch: 28 [29440/35339 (83%)]\tLoss: 0.000852\n",
            "Train Epoch: 28 [29760/35339 (84%)]\tLoss: 0.000000\n",
            "Train Epoch: 28 [30080/35339 (85%)]\tLoss: 0.000000\n",
            "Train Epoch: 28 [30400/35339 (86%)]\tLoss: 0.000001\n",
            "Train Epoch: 28 [30720/35339 (87%)]\tLoss: 0.000116\n",
            "Train Epoch: 28 [31040/35339 (88%)]\tLoss: 0.000708\n",
            "Train Epoch: 28 [31360/35339 (89%)]\tLoss: 0.000000\n",
            "Train Epoch: 28 [31680/35339 (90%)]\tLoss: 0.000021\n",
            "Train Epoch: 28 [32000/35339 (90%)]\tLoss: 0.000054\n",
            "Train Epoch: 28 [32320/35339 (91%)]\tLoss: 0.000020\n",
            "Train Epoch: 28 [32640/35339 (92%)]\tLoss: 0.000012\n",
            "Train Epoch: 28 [32960/35339 (93%)]\tLoss: 0.000003\n",
            "Train Epoch: 28 [33280/35339 (94%)]\tLoss: 0.020728\n",
            "Train Epoch: 28 [33600/35339 (95%)]\tLoss: 0.000188\n",
            "Train Epoch: 28 [33920/35339 (96%)]\tLoss: 0.098898\n",
            "Train Epoch: 28 [34240/35339 (97%)]\tLoss: 0.000024\n",
            "Train Epoch: 28 [34560/35339 (98%)]\tLoss: 0.000016\n",
            "Train Epoch: 28 [34880/35339 (99%)]\tLoss: 0.001086\n",
            "Train Epoch: 28 [35200/35339 (100%)]\tLoss: 0.152598\n",
            "\n",
            "Validation set: Average loss: 0.1467, Accuracy: 3765/3870 (97%)\n",
            "\n",
            "\n",
            "Saved model to model_28.pth.\n",
            "Train Epoch: 29 [0/35339 (0%)]\tLoss: 0.000017\n",
            "Train Epoch: 29 [320/35339 (1%)]\tLoss: 0.003560\n",
            "Train Epoch: 29 [640/35339 (2%)]\tLoss: 0.000000\n",
            "Train Epoch: 29 [960/35339 (3%)]\tLoss: 0.016094\n",
            "Train Epoch: 29 [1280/35339 (4%)]\tLoss: 0.000026\n",
            "Train Epoch: 29 [1600/35339 (5%)]\tLoss: 0.000325\n",
            "Train Epoch: 29 [1920/35339 (5%)]\tLoss: 0.001359\n",
            "Train Epoch: 29 [2240/35339 (6%)]\tLoss: 0.000816\n",
            "Train Epoch: 29 [2560/35339 (7%)]\tLoss: 0.000075\n",
            "Train Epoch: 29 [2880/35339 (8%)]\tLoss: 0.000587\n",
            "Train Epoch: 29 [3200/35339 (9%)]\tLoss: 0.000035\n",
            "Train Epoch: 29 [3520/35339 (10%)]\tLoss: 0.000012\n",
            "Train Epoch: 29 [3840/35339 (11%)]\tLoss: 0.000000\n",
            "Train Epoch: 29 [4160/35339 (12%)]\tLoss: 0.000718\n",
            "Train Epoch: 29 [4480/35339 (13%)]\tLoss: 0.000269\n",
            "Train Epoch: 29 [4800/35339 (14%)]\tLoss: 0.000000\n",
            "Train Epoch: 29 [5120/35339 (14%)]\tLoss: 0.001464\n",
            "Train Epoch: 29 [5440/35339 (15%)]\tLoss: 0.000002\n",
            "Train Epoch: 29 [5760/35339 (16%)]\tLoss: 0.000002\n",
            "Train Epoch: 29 [6080/35339 (17%)]\tLoss: 0.000109\n",
            "Train Epoch: 29 [6400/35339 (18%)]\tLoss: 0.000013\n",
            "Train Epoch: 29 [6720/35339 (19%)]\tLoss: 0.000001\n",
            "Train Epoch: 29 [7040/35339 (20%)]\tLoss: 0.001381\n",
            "Train Epoch: 29 [7360/35339 (21%)]\tLoss: 0.000013\n",
            "Train Epoch: 29 [7680/35339 (22%)]\tLoss: 0.000000\n",
            "Train Epoch: 29 [8000/35339 (23%)]\tLoss: 0.000057\n",
            "Train Epoch: 29 [8320/35339 (24%)]\tLoss: 0.002723\n",
            "Train Epoch: 29 [8640/35339 (24%)]\tLoss: 0.000001\n",
            "Train Epoch: 29 [8960/35339 (25%)]\tLoss: 0.000000\n",
            "Train Epoch: 29 [9280/35339 (26%)]\tLoss: 0.006249\n",
            "Train Epoch: 29 [9600/35339 (27%)]\tLoss: 0.000058\n",
            "Train Epoch: 29 [9920/35339 (28%)]\tLoss: 0.000001\n",
            "Train Epoch: 29 [10240/35339 (29%)]\tLoss: 0.000821\n",
            "Train Epoch: 29 [10560/35339 (30%)]\tLoss: 0.000004\n",
            "Train Epoch: 29 [10880/35339 (31%)]\tLoss: 0.000001\n",
            "Train Epoch: 29 [11200/35339 (32%)]\tLoss: 0.000001\n",
            "Train Epoch: 29 [11520/35339 (33%)]\tLoss: 0.000005\n",
            "Train Epoch: 29 [11840/35339 (33%)]\tLoss: 0.000273\n",
            "Train Epoch: 29 [12160/35339 (34%)]\tLoss: 0.000000\n",
            "Train Epoch: 29 [12480/35339 (35%)]\tLoss: 0.000011\n",
            "Train Epoch: 29 [12800/35339 (36%)]\tLoss: 0.000005\n",
            "Train Epoch: 29 [13120/35339 (37%)]\tLoss: 0.014230\n",
            "Train Epoch: 29 [13440/35339 (38%)]\tLoss: 0.000710\n",
            "Train Epoch: 29 [13760/35339 (39%)]\tLoss: 0.000000\n",
            "Train Epoch: 29 [14080/35339 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 29 [14400/35339 (41%)]\tLoss: 0.004541\n",
            "Train Epoch: 29 [14720/35339 (42%)]\tLoss: 0.000009\n",
            "Train Epoch: 29 [15040/35339 (43%)]\tLoss: 0.021208\n",
            "Train Epoch: 29 [15360/35339 (43%)]\tLoss: 0.000040\n",
            "Train Epoch: 29 [15680/35339 (44%)]\tLoss: 0.000014\n",
            "Train Epoch: 29 [16000/35339 (45%)]\tLoss: 0.147082\n",
            "Train Epoch: 29 [16320/35339 (46%)]\tLoss: 0.000027\n",
            "Train Epoch: 29 [16640/35339 (47%)]\tLoss: 0.000000\n",
            "Train Epoch: 29 [16960/35339 (48%)]\tLoss: 0.000000\n",
            "Train Epoch: 29 [17280/35339 (49%)]\tLoss: 0.000191\n",
            "Train Epoch: 29 [17600/35339 (50%)]\tLoss: 0.000000\n",
            "Train Epoch: 29 [17920/35339 (51%)]\tLoss: 0.000000\n",
            "Train Epoch: 29 [18240/35339 (52%)]\tLoss: 0.000028\n",
            "Train Epoch: 29 [18560/35339 (52%)]\tLoss: 0.000000\n",
            "Train Epoch: 29 [18880/35339 (53%)]\tLoss: 0.000000\n",
            "Train Epoch: 29 [19200/35339 (54%)]\tLoss: 0.000092\n",
            "Train Epoch: 29 [19520/35339 (55%)]\tLoss: 0.003713\n",
            "Train Epoch: 29 [19840/35339 (56%)]\tLoss: 0.003044\n",
            "Train Epoch: 29 [20160/35339 (57%)]\tLoss: 0.000939\n",
            "Train Epoch: 29 [20480/35339 (58%)]\tLoss: 0.000000\n",
            "Train Epoch: 29 [20800/35339 (59%)]\tLoss: 0.000029\n",
            "Train Epoch: 29 [21120/35339 (60%)]\tLoss: 0.000006\n",
            "Train Epoch: 29 [21440/35339 (61%)]\tLoss: 0.000003\n",
            "Train Epoch: 29 [21760/35339 (62%)]\tLoss: 0.000000\n",
            "Train Epoch: 29 [22080/35339 (62%)]\tLoss: 0.299879\n",
            "Train Epoch: 29 [22400/35339 (63%)]\tLoss: 0.000000\n",
            "Train Epoch: 29 [22720/35339 (64%)]\tLoss: 0.000171\n",
            "Train Epoch: 29 [23040/35339 (65%)]\tLoss: 0.000000\n",
            "Train Epoch: 29 [23360/35339 (66%)]\tLoss: 0.000211\n",
            "Train Epoch: 29 [23680/35339 (67%)]\tLoss: 0.078755\n",
            "Train Epoch: 29 [24000/35339 (68%)]\tLoss: 0.000053\n",
            "Train Epoch: 29 [24320/35339 (69%)]\tLoss: 0.000000\n",
            "Train Epoch: 29 [24640/35339 (70%)]\tLoss: 0.000204\n",
            "Train Epoch: 29 [24960/35339 (71%)]\tLoss: 0.000000\n",
            "Train Epoch: 29 [25280/35339 (71%)]\tLoss: 0.000163\n",
            "Train Epoch: 29 [25600/35339 (72%)]\tLoss: 0.000002\n",
            "Train Epoch: 29 [25920/35339 (73%)]\tLoss: 0.000001\n",
            "Train Epoch: 29 [26240/35339 (74%)]\tLoss: 0.000024\n",
            "Train Epoch: 29 [26560/35339 (75%)]\tLoss: 0.000681\n",
            "Train Epoch: 29 [26880/35339 (76%)]\tLoss: 0.000000\n",
            "Train Epoch: 29 [27200/35339 (77%)]\tLoss: 0.000001\n",
            "Train Epoch: 29 [27520/35339 (78%)]\tLoss: 0.000000\n",
            "Train Epoch: 29 [27840/35339 (79%)]\tLoss: 0.000000\n",
            "Train Epoch: 29 [28160/35339 (80%)]\tLoss: 0.019319\n",
            "Train Epoch: 29 [28480/35339 (81%)]\tLoss: 0.000184\n",
            "Train Epoch: 29 [28800/35339 (81%)]\tLoss: 0.000000\n",
            "Train Epoch: 29 [29120/35339 (82%)]\tLoss: 0.000000\n",
            "Train Epoch: 29 [29440/35339 (83%)]\tLoss: 0.000000\n",
            "Train Epoch: 29 [29760/35339 (84%)]\tLoss: 0.019557\n",
            "Train Epoch: 29 [30080/35339 (85%)]\tLoss: 0.002739\n",
            "Train Epoch: 29 [30400/35339 (86%)]\tLoss: 0.000005\n",
            "Train Epoch: 29 [30720/35339 (87%)]\tLoss: 0.000002\n",
            "Train Epoch: 29 [31040/35339 (88%)]\tLoss: 0.000001\n",
            "Train Epoch: 29 [31360/35339 (89%)]\tLoss: 0.000054\n",
            "Train Epoch: 29 [31680/35339 (90%)]\tLoss: 0.000002\n",
            "Train Epoch: 29 [32000/35339 (90%)]\tLoss: 0.000027\n",
            "Train Epoch: 29 [32320/35339 (91%)]\tLoss: 0.000832\n",
            "Train Epoch: 29 [32640/35339 (92%)]\tLoss: 0.000052\n",
            "Train Epoch: 29 [32960/35339 (93%)]\tLoss: 0.000000\n",
            "Train Epoch: 29 [33280/35339 (94%)]\tLoss: 0.000000\n",
            "Train Epoch: 29 [33600/35339 (95%)]\tLoss: 0.000083\n",
            "Train Epoch: 29 [33920/35339 (96%)]\tLoss: 0.000000\n",
            "Train Epoch: 29 [34240/35339 (97%)]\tLoss: 0.000253\n",
            "Train Epoch: 29 [34560/35339 (98%)]\tLoss: 0.000008\n",
            "Train Epoch: 29 [34880/35339 (99%)]\tLoss: 0.000000\n",
            "Train Epoch: 29 [35200/35339 (100%)]\tLoss: 0.096885\n",
            "\n",
            "Validation set: Average loss: 0.2678, Accuracy: 3765/3870 (97%)\n",
            "\n",
            "\n",
            "Saved model to model_29.pth.\n",
            "Train Epoch: 30 [0/35339 (0%)]\tLoss: 0.000001\n",
            "Train Epoch: 30 [320/35339 (1%)]\tLoss: 0.000000\n",
            "Train Epoch: 30 [640/35339 (2%)]\tLoss: 0.007307\n",
            "Train Epoch: 30 [960/35339 (3%)]\tLoss: 0.053178\n",
            "Train Epoch: 30 [1280/35339 (4%)]\tLoss: 0.000646\n",
            "Train Epoch: 30 [1600/35339 (5%)]\tLoss: 0.000011\n",
            "Train Epoch: 30 [1920/35339 (5%)]\tLoss: 0.074785\n",
            "Train Epoch: 30 [2240/35339 (6%)]\tLoss: 0.000027\n",
            "Train Epoch: 30 [2560/35339 (7%)]\tLoss: 0.036884\n",
            "Train Epoch: 30 [2880/35339 (8%)]\tLoss: 0.030424\n",
            "Train Epoch: 30 [3200/35339 (9%)]\tLoss: 0.004216\n",
            "Train Epoch: 30 [3520/35339 (10%)]\tLoss: 0.004574\n",
            "Train Epoch: 30 [3840/35339 (11%)]\tLoss: 0.000001\n",
            "Train Epoch: 30 [4160/35339 (12%)]\tLoss: 0.000000\n",
            "Train Epoch: 30 [4480/35339 (13%)]\tLoss: 0.001435\n",
            "Train Epoch: 30 [4800/35339 (14%)]\tLoss: 0.000021\n",
            "Train Epoch: 30 [5120/35339 (14%)]\tLoss: 0.000232\n",
            "Train Epoch: 30 [5440/35339 (15%)]\tLoss: 0.000001\n",
            "Train Epoch: 30 [5760/35339 (16%)]\tLoss: 0.004080\n",
            "Train Epoch: 30 [6080/35339 (17%)]\tLoss: 0.000000\n",
            "Train Epoch: 30 [6400/35339 (18%)]\tLoss: 0.035777\n",
            "Train Epoch: 30 [6720/35339 (19%)]\tLoss: 0.000012\n",
            "Train Epoch: 30 [7040/35339 (20%)]\tLoss: 0.000000\n",
            "Train Epoch: 30 [7360/35339 (21%)]\tLoss: 0.001414\n",
            "Train Epoch: 30 [7680/35339 (22%)]\tLoss: 0.001915\n",
            "Train Epoch: 30 [8000/35339 (23%)]\tLoss: 0.000000\n",
            "Train Epoch: 30 [8320/35339 (24%)]\tLoss: 0.000002\n",
            "Train Epoch: 30 [8640/35339 (24%)]\tLoss: 0.066439\n",
            "Train Epoch: 30 [8960/35339 (25%)]\tLoss: 0.000022\n",
            "Train Epoch: 30 [9280/35339 (26%)]\tLoss: 0.000002\n",
            "Train Epoch: 30 [9600/35339 (27%)]\tLoss: 0.074652\n",
            "Train Epoch: 30 [9920/35339 (28%)]\tLoss: 0.000157\n",
            "Train Epoch: 30 [10240/35339 (29%)]\tLoss: 0.000001\n",
            "Train Epoch: 30 [10560/35339 (30%)]\tLoss: 0.000000\n",
            "Train Epoch: 30 [10880/35339 (31%)]\tLoss: 0.000191\n",
            "Train Epoch: 30 [11200/35339 (32%)]\tLoss: 0.000011\n",
            "Train Epoch: 30 [11520/35339 (33%)]\tLoss: 0.000000\n",
            "Train Epoch: 30 [11840/35339 (33%)]\tLoss: 0.000000\n",
            "Train Epoch: 30 [12160/35339 (34%)]\tLoss: 0.000011\n",
            "Train Epoch: 30 [12480/35339 (35%)]\tLoss: 0.000000\n",
            "Train Epoch: 30 [12800/35339 (36%)]\tLoss: 0.000000\n",
            "Train Epoch: 30 [13120/35339 (37%)]\tLoss: 0.000002\n",
            "Train Epoch: 30 [13440/35339 (38%)]\tLoss: 0.000000\n",
            "Train Epoch: 30 [13760/35339 (39%)]\tLoss: 0.000000\n",
            "Train Epoch: 30 [14080/35339 (40%)]\tLoss: 0.000000\n",
            "Train Epoch: 30 [14400/35339 (41%)]\tLoss: 0.000004\n",
            "Train Epoch: 30 [14720/35339 (42%)]\tLoss: 0.000009\n",
            "Train Epoch: 30 [15040/35339 (43%)]\tLoss: 0.001351\n",
            "Train Epoch: 30 [15360/35339 (43%)]\tLoss: 0.113042\n",
            "Train Epoch: 30 [15680/35339 (44%)]\tLoss: 0.000537\n",
            "Train Epoch: 30 [16000/35339 (45%)]\tLoss: 0.000016\n",
            "Train Epoch: 30 [16320/35339 (46%)]\tLoss: 0.015927\n",
            "Train Epoch: 30 [16640/35339 (47%)]\tLoss: 0.000000\n",
            "Train Epoch: 30 [16960/35339 (48%)]\tLoss: 0.000008\n",
            "Train Epoch: 30 [17280/35339 (49%)]\tLoss: 0.001043\n",
            "Train Epoch: 30 [17600/35339 (50%)]\tLoss: 0.107515\n",
            "Train Epoch: 30 [17920/35339 (51%)]\tLoss: 0.000000\n",
            "Train Epoch: 30 [18240/35339 (52%)]\tLoss: 0.001175\n",
            "Train Epoch: 30 [18560/35339 (52%)]\tLoss: 0.000134\n",
            "Train Epoch: 30 [18880/35339 (53%)]\tLoss: 0.000001\n",
            "Train Epoch: 30 [19200/35339 (54%)]\tLoss: 0.000000\n",
            "Train Epoch: 30 [19520/35339 (55%)]\tLoss: 0.000049\n",
            "Train Epoch: 30 [19840/35339 (56%)]\tLoss: 0.000000\n",
            "Train Epoch: 30 [20160/35339 (57%)]\tLoss: 0.007581\n",
            "Train Epoch: 30 [20480/35339 (58%)]\tLoss: 0.000000\n",
            "Train Epoch: 30 [20800/35339 (59%)]\tLoss: 0.000411\n",
            "Train Epoch: 30 [21120/35339 (60%)]\tLoss: 0.006050\n",
            "Train Epoch: 30 [21440/35339 (61%)]\tLoss: 0.000009\n",
            "Train Epoch: 30 [21760/35339 (62%)]\tLoss: 0.000002\n",
            "Train Epoch: 30 [22080/35339 (62%)]\tLoss: 0.000057\n",
            "Train Epoch: 30 [22400/35339 (63%)]\tLoss: 0.000142\n",
            "Train Epoch: 30 [22720/35339 (64%)]\tLoss: 0.000607\n",
            "Train Epoch: 30 [23040/35339 (65%)]\tLoss: 0.000000\n",
            "Train Epoch: 30 [23360/35339 (66%)]\tLoss: 0.000000\n",
            "Train Epoch: 30 [23680/35339 (67%)]\tLoss: 0.008959\n",
            "Train Epoch: 30 [24000/35339 (68%)]\tLoss: 0.000033\n",
            "Train Epoch: 30 [24320/35339 (69%)]\tLoss: 0.000001\n",
            "Train Epoch: 30 [24640/35339 (70%)]\tLoss: 0.000029\n",
            "Train Epoch: 30 [24960/35339 (71%)]\tLoss: 0.000014\n",
            "Train Epoch: 30 [25280/35339 (71%)]\tLoss: 0.000006\n",
            "Train Epoch: 30 [25600/35339 (72%)]\tLoss: 0.131054\n",
            "Train Epoch: 30 [25920/35339 (73%)]\tLoss: 0.000004\n",
            "Train Epoch: 30 [26240/35339 (74%)]\tLoss: 0.000170\n",
            "Train Epoch: 30 [26560/35339 (75%)]\tLoss: 0.294981\n",
            "Train Epoch: 30 [26880/35339 (76%)]\tLoss: 0.000412\n",
            "Train Epoch: 30 [27200/35339 (77%)]\tLoss: 0.000006\n",
            "Train Epoch: 30 [27520/35339 (78%)]\tLoss: 0.008263\n",
            "Train Epoch: 30 [27840/35339 (79%)]\tLoss: 0.000049\n",
            "Train Epoch: 30 [28160/35339 (80%)]\tLoss: 0.003001\n",
            "Train Epoch: 30 [28480/35339 (81%)]\tLoss: 0.002287\n",
            "Train Epoch: 30 [28800/35339 (81%)]\tLoss: 0.016581\n",
            "Train Epoch: 30 [29120/35339 (82%)]\tLoss: 0.000104\n",
            "Train Epoch: 30 [29440/35339 (83%)]\tLoss: 0.000000\n",
            "Train Epoch: 30 [29760/35339 (84%)]\tLoss: 0.001018\n",
            "Train Epoch: 30 [30080/35339 (85%)]\tLoss: 0.000000\n",
            "Train Epoch: 30 [30400/35339 (86%)]\tLoss: 0.000000\n",
            "Train Epoch: 30 [30720/35339 (87%)]\tLoss: 0.000179\n",
            "Train Epoch: 30 [31040/35339 (88%)]\tLoss: 0.000000\n",
            "Train Epoch: 30 [31360/35339 (89%)]\tLoss: 0.000000\n",
            "Train Epoch: 30 [31680/35339 (90%)]\tLoss: 0.000113\n",
            "Train Epoch: 30 [32000/35339 (90%)]\tLoss: 0.000000\n",
            "Train Epoch: 30 [32320/35339 (91%)]\tLoss: 0.000002\n",
            "Train Epoch: 30 [32640/35339 (92%)]\tLoss: 0.000008\n",
            "Train Epoch: 30 [32960/35339 (93%)]\tLoss: 0.000000\n",
            "Train Epoch: 30 [33280/35339 (94%)]\tLoss: 0.000105\n",
            "Train Epoch: 30 [33600/35339 (95%)]\tLoss: 0.000000\n",
            "Train Epoch: 30 [33920/35339 (96%)]\tLoss: 0.000001\n",
            "Train Epoch: 30 [34240/35339 (97%)]\tLoss: 0.000050\n",
            "Train Epoch: 30 [34560/35339 (98%)]\tLoss: 0.033932\n",
            "Train Epoch: 30 [34880/35339 (99%)]\tLoss: 0.000000\n",
            "Train Epoch: 30 [35200/35339 (100%)]\tLoss: 0.000000\n",
            "\n",
            "Validation set: Average loss: 0.1444, Accuracy: 3789/3870 (98%)\n",
            "\n",
            "\n",
            "Saved model to model_30.pth.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djkC3ABURJOv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "4418d349-073e-4c6c-f952-349f79d835e6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams.update({'font.size': 14})\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.grid(True)\n",
        "plt.plot(train_losses,'-o')\n",
        "plt.plot(valid_losses,'-o')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('losses')\n",
        "plt.legend(['Train Loss','Valid loss'])\n",
        "plt.title('Train vs Valid Losses')\n",
        " \n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "cFUJuH6eH8zw",
        "outputId": "66bbe397-af60-4067-cdf7-7fa0193dc708"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(train_accuracies)\n",
        "plt.plot(valid_accuracies)\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'], loc='right')\n",
        "plt.ylabel(u'Accuracy')\n",
        "plt.xlabel(u'Epoch')\n",
        "plt.title('Train vs Valid Accuracies')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVN1f1p7w59X"
      },
      "source": [
        "# Evaluate and Submit to Kaggle\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BM5qP64w5zB",
        "outputId": "0da22d90-6da4-487c-f103-c247b193b2bc"
      },
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "outfile = 'gtsrb_kaggle_4_conv_2linear.csv'\n",
        "\n",
        "output_file = open(outfile, \"w\")\n",
        "dataframe_dict = {\"Filename\" : [], \"ClassId\": []}\n",
        "\n",
        "test_data = torch.load('testing/test.pt')\n",
        "file_ids = pickle.load(open('testing/file_ids.pkl', 'rb'))\n",
        "\n",
        "model_file = \"model_30.pth\"\n",
        "model = Net()\n",
        "model.load_state_dict(torch.load(model_file))\n",
        "model.eval()\n",
        "for i, data in enumerate(test_data):\n",
        "    data = data.unsqueeze(0)\n",
        "\n",
        "    output = model(data)\n",
        "    pred = output.data.max(1, keepdim=True)[1].item()\n",
        "    file_id = file_ids[i][0:5]\n",
        "    dataframe_dict['Filename'].append(file_id)\n",
        "    dataframe_dict['ClassId'].append(pred)\n",
        "\n",
        "df = pd.DataFrame(data=dataframe_dict)\n",
        "df.to_csv(outfile, index=False)\n",
        "print(\"Written to csv file {}\".format(outfile))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Written to csv file gtsrb_kaggle_4_conv_2linear.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3i3QF4Urvq_P",
        "outputId": "59c71730-69f8-4d07-da6b-8c72314cbf90"
      },
      "source": [
        "# taking the lowest val loss model\n",
        "outfile = 'best_model.csv'\n",
        "\n",
        "output_file = open(outfile, \"w\")\n",
        "dataframe_dict = {\"Filename\" : [], \"ClassId\": []}\n",
        "\n",
        "test_data = torch.load('testing/test.pt')\n",
        "file_ids = pickle.load(open('testing/file_ids.pkl', 'rb'))\n",
        "\n",
        "model_file = \"model_16.pth\"\n",
        "model = Net()\n",
        "model.load_state_dict(torch.load(model_file))\n",
        "model.eval()\n",
        "for i, data in enumerate(test_data):\n",
        "    data = data.unsqueeze(0)\n",
        "\n",
        "    output = model(data)\n",
        "    pred = output.data.max(1, keepdim=True)[1].item()\n",
        "    file_id = file_ids[i][0:5]\n",
        "    dataframe_dict['Filename'].append(file_id)\n",
        "    dataframe_dict['ClassId'].append(pred)\n",
        "\n",
        "df = pd.DataFrame(data=dataframe_dict)\n",
        "df.to_csv(outfile, index=False)\n",
        "print(\"Written to csv file {}\".format(outfile))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Written to csv file best_model.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1QJabxfbOSp",
        "outputId": "6aeed87e-262e-4895-a732-35d8781f4158"
      },
      "source": [
        "print(\"was able to submit it\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "was able to submit it\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhSl_4kn6sox"
      },
      "source": [
        "# Submitting to Kaggle\n",
        "\n",
        "Now take this csv file, download it from your Google drive and then submit it to Kaggle to check performance of your model."
      ]
    }
  ]
}